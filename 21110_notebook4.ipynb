{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "711f8ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage import transform\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rescale\n",
    "import cv2\n",
    "import glob\n",
    "import random as ra\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "def process(X,Y,file,aug):\n",
    "    img=cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n",
    "    X.append(img)\n",
    "    #write your code\n",
    "    if \"virus\" in file:\n",
    "        Y.append(\"0\")\n",
    "    elif \"bacteria\" in file:\n",
    "        Y.append(\"1\")\n",
    "    else:\n",
    "        Y.append(\"2\")\n",
    "    if aug:\n",
    "        augmentation(X,Y)\n",
    "\n",
    "def normalize(dataset):\n",
    "    dataset=asarray(dataset).astype('float32')\n",
    "    dataset=dataset/255.0\n",
    "    return dataset\n",
    "    \n",
    "def create_dataset(directory):\n",
    "    #before work\n",
    "    files=glob.glob(directory+'/*.jpeg')\n",
    "    ra.shuffle(files)\n",
    "    X_train=[]\n",
    "    Y_train=[]\n",
    "    X_test=[]\n",
    "    Y_test=[]\n",
    "    for file in files[0:int(len(files)*0.8)]:\n",
    "        process(X_train,Y_train,file,True)\n",
    "    for file in files[int(len(files)*0.8):]:\n",
    "        process(X_test,Y_test,file,False)        \n",
    "    from numpy import asarray\n",
    "    X_train=normalize(X_train)\n",
    "    X_test=normalize(X_test)\n",
    "    return X_train,X_test,Y_train,Y_test\n",
    "\n",
    "def augmentation(dataset,labels):\n",
    "    last=len(labels)-1\n",
    "    scale_out = skimage.transform.rescale(dataset[last], scale=2.0, mode='constant')\n",
    "    scale_out=skimage.transform.resize(scale_out,(100,100))\n",
    "    scale_in = skimage.transform.rescale(dataset[last], scale=0.5, mode='constant')\n",
    "    scale_in=skimage.transform.resize(scale_in,(100,100))\n",
    "    dataset.append(scale_out)\n",
    "    labels.append(labels[last])\n",
    "    dataset.append(scale_in)\n",
    "    labels.append(labels[last])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a718a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import utils\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "import math\n",
    "X_train,X_test,Y_train,Y_test=create_dataset('chest_xray_lower_dim2')\n",
    "X_train=X_train.reshape(-1,100,100,1)\n",
    "X_test=X_test.reshape(-1,100,100,1)\n",
    "Y_train= keras.utils.to_categorical(Y_train,3)\n",
    "Y_test = keras.utils.to_categorical(Y_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ceda2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "next time\n",
    "penalty 0.01\n",
    "penalty last 0.001\n",
    "reverse\n",
    "\"\"\"\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    #X_train,XX,Y_train,YY=train_test_split(\n",
    "    #dataset, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=100*100\n",
    "        w=math.sqrt(inputs)\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation='relu',kernel_regularizer=regularizers.L2(0.01))(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=30\n",
    "            w=math.sqrt(inputs)\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation='softmax')(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4,mode='min')\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.2,epochs=epochs_num,batch_size=batch_len,verbose=2,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6262036f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "57/57 - 92s - loss: 1.6702 - accuracy: 0.4745 - val_loss: 1.3908 - val_accuracy: 0.4952 - 92s/epoch - 2s/step\n",
      "Epoch 2/60\n",
      "57/57 - 86s - loss: 1.3199 - accuracy: 0.4745 - val_loss: 1.2350 - val_accuracy: 0.4952 - 86s/epoch - 2s/step\n",
      "Epoch 3/60\n",
      "57/57 - 86s - loss: 1.2011 - accuracy: 0.4745 - val_loss: 1.1462 - val_accuracy: 0.4952 - 86s/epoch - 2s/step\n",
      "Epoch 4/60\n",
      "57/57 - 87s - loss: 1.1116 - accuracy: 0.4873 - val_loss: 1.0390 - val_accuracy: 0.5543 - 87s/epoch - 2s/step\n",
      "Epoch 5/60\n",
      "57/57 - 86s - loss: 1.0162 - accuracy: 0.5331 - val_loss: 0.9562 - val_accuracy: 0.5603 - 86s/epoch - 2s/step\n",
      "Epoch 6/60\n",
      "57/57 - 86s - loss: 0.9390 - accuracy: 0.5586 - val_loss: 0.8636 - val_accuracy: 0.6845 - 86s/epoch - 2s/step\n",
      "Epoch 7/60\n",
      "57/57 - 85s - loss: 0.7891 - accuracy: 0.6757 - val_loss: 0.7296 - val_accuracy: 0.6962 - 85s/epoch - 1s/step\n",
      "Epoch 8/60\n",
      "57/57 - 88s - loss: 0.7143 - accuracy: 0.7009 - val_loss: 0.6746 - val_accuracy: 0.7335 - 88s/epoch - 2s/step\n",
      "Epoch 9/60\n",
      "57/57 - 85s - loss: 0.6815 - accuracy: 0.7192 - val_loss: 0.6490 - val_accuracy: 0.7257 - 85s/epoch - 1s/step\n",
      "Epoch 10/60\n",
      "57/57 - 85s - loss: 0.6651 - accuracy: 0.7241 - val_loss: 0.7011 - val_accuracy: 0.7182 - 85s/epoch - 1s/step\n",
      "Epoch 11/60\n",
      "57/57 - 85s - loss: 0.6515 - accuracy: 0.7353 - val_loss: 0.6160 - val_accuracy: 0.7631 - 85s/epoch - 1s/step\n",
      "Epoch 12/60\n",
      "57/57 - 85s - loss: 0.6360 - accuracy: 0.7489 - val_loss: 0.6245 - val_accuracy: 0.7602 - 85s/epoch - 1s/step\n",
      "Epoch 13/60\n",
      "57/57 - 85s - loss: 0.6259 - accuracy: 0.7529 - val_loss: 0.6094 - val_accuracy: 0.7613 - 85s/epoch - 1s/step\n",
      "Epoch 14/60\n",
      "57/57 - 85s - loss: 0.6118 - accuracy: 0.7653 - val_loss: 0.5687 - val_accuracy: 0.7826 - 85s/epoch - 1s/step\n",
      "Epoch 15/60\n",
      "57/57 - 86s - loss: 0.5918 - accuracy: 0.7732 - val_loss: 0.5656 - val_accuracy: 0.7834 - 86s/epoch - 2s/step\n",
      "Epoch 16/60\n",
      "57/57 - 85s - loss: 0.5876 - accuracy: 0.7739 - val_loss: 0.5952 - val_accuracy: 0.7584 - 85s/epoch - 1s/step\n",
      "Epoch 17/60\n",
      "57/57 - 85s - loss: 0.5809 - accuracy: 0.7731 - val_loss: 0.5586 - val_accuracy: 0.7901 - 85s/epoch - 1s/step\n",
      "Epoch 18/60\n",
      "57/57 - 86s - loss: 0.5636 - accuracy: 0.7853 - val_loss: 0.5552 - val_accuracy: 0.7933 - 86s/epoch - 2s/step\n",
      "Epoch 19/60\n",
      "57/57 - 87s - loss: 0.5859 - accuracy: 0.7745 - val_loss: 0.5479 - val_accuracy: 0.7926 - 87s/epoch - 2s/step\n",
      "Epoch 20/60\n",
      "57/57 - 86s - loss: 0.5640 - accuracy: 0.7799 - val_loss: 0.5757 - val_accuracy: 0.7823 - 86s/epoch - 2s/step\n",
      "Epoch 21/60\n",
      "57/57 - 98s - loss: 0.5581 - accuracy: 0.7816 - val_loss: 0.6022 - val_accuracy: 0.7777 - 98s/epoch - 2s/step\n",
      "Epoch 22/60\n",
      "57/57 - 107s - loss: 0.5691 - accuracy: 0.7811 - val_loss: 0.5394 - val_accuracy: 0.8043 - 107s/epoch - 2s/step\n",
      "Epoch 23/60\n",
      "57/57 - 92s - loss: 0.5530 - accuracy: 0.7880 - val_loss: 0.5254 - val_accuracy: 0.8004 - 92s/epoch - 2s/step\n",
      "Epoch 24/60\n",
      "57/57 - 93s - loss: 0.5390 - accuracy: 0.7917 - val_loss: 0.5296 - val_accuracy: 0.8040 - 93s/epoch - 2s/step\n",
      "Epoch 25/60\n",
      "57/57 - 88s - loss: 0.5355 - accuracy: 0.7942 - val_loss: 0.5211 - val_accuracy: 0.8079 - 88s/epoch - 2s/step\n",
      "Epoch 26/60\n",
      "57/57 - 87s - loss: 0.5250 - accuracy: 0.7959 - val_loss: 0.5274 - val_accuracy: 0.8040 - 87s/epoch - 2s/step\n",
      "Epoch 27/60\n",
      "57/57 - 96s - loss: 0.5281 - accuracy: 0.7980 - val_loss: 0.5354 - val_accuracy: 0.8026 - 96s/epoch - 2s/step\n",
      "Epoch 28/60\n",
      "57/57 - 91s - loss: 0.5179 - accuracy: 0.8017 - val_loss: 0.5297 - val_accuracy: 0.8011 - 91s/epoch - 2s/step\n",
      "Epoch 29/60\n",
      "57/57 - 89s - loss: 0.5147 - accuracy: 0.8024 - val_loss: 0.5085 - val_accuracy: 0.8132 - 89s/epoch - 2s/step\n",
      "Epoch 30/60\n",
      "57/57 - 87s - loss: 0.5104 - accuracy: 0.8046 - val_loss: 0.5237 - val_accuracy: 0.8068 - 87s/epoch - 2s/step\n",
      "Epoch 31/60\n",
      "57/57 - 86s - loss: 0.5062 - accuracy: 0.8048 - val_loss: 0.5280 - val_accuracy: 0.7958 - 86s/epoch - 2s/step\n",
      "Epoch 32/60\n",
      "57/57 - 86s - loss: 0.5083 - accuracy: 0.8078 - val_loss: 0.5389 - val_accuracy: 0.7898 - 86s/epoch - 2s/step\n",
      "Epoch 33/60\n",
      "57/57 - 86s - loss: 0.5055 - accuracy: 0.8039 - val_loss: 0.5156 - val_accuracy: 0.8040 - 86s/epoch - 2s/step\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 49, 49, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5715711712837219\n",
      "Test accuracy: 0.7815699577331543\n"
     ]
    }
   ],
   "source": [
    "train(60,200,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5449ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w,maxval=1/w, seed=None)\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    X_trainR,XX,Y_trainR,YY=train_test_split(\n",
    "    X_train,Y_train, test_size=0.05, random_state=20)\n",
    "\n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=2560\n",
    "        w=math.sqrt(inputs)\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w,maxval=1/w, seed=None),kernel_regularizer=regularizers.L2(0.01))(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=inputs*30\n",
    "            w=math.sqrt(inputs)\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation='softmax',kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w,maxval=1/w, seed=None))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4,mode='min')\n",
    "    model=mlp_model()\n",
    "    model.fit(X_trainR,Y_trainR,validation_split=0.2,epochs=epochs_num,batch_size=batch_len,verbose=2,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8950827d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "54/54 - 106s - loss: 1.1004 - accuracy: 0.4707 - val_loss: 1.0750 - val_accuracy: 0.4734 - 106s/epoch - 2s/step\n",
      "Epoch 2/60\n",
      "54/54 - 81s - loss: 1.0625 - accuracy: 0.4750 - val_loss: 1.0581 - val_accuracy: 0.4734 - 81s/epoch - 2s/step\n",
      "Epoch 3/60\n",
      "54/54 - 82s - loss: 1.0565 - accuracy: 0.4750 - val_loss: 1.0569 - val_accuracy: 0.4734 - 82s/epoch - 2s/step\n",
      "Epoch 4/60\n",
      "54/54 - 81s - loss: 1.0558 - accuracy: 0.4750 - val_loss: 1.0568 - val_accuracy: 0.4734 - 81s/epoch - 1s/step\n",
      "Epoch 5/60\n",
      "54/54 - 81s - loss: 1.0557 - accuracy: 0.4750 - val_loss: 1.0569 - val_accuracy: 0.4734 - 81s/epoch - 1s/step\n",
      "Epoch 6/60\n",
      "54/54 - 82s - loss: 1.0558 - accuracy: 0.4750 - val_loss: 1.0568 - val_accuracy: 0.4734 - 82s/epoch - 2s/step\n",
      "Epoch 7/60\n",
      "54/54 - 81s - loss: 1.0557 - accuracy: 0.4750 - val_loss: 1.0569 - val_accuracy: 0.4734 - 81s/epoch - 1s/step\n",
      "Epoch 8/60\n",
      "54/54 - 81s - loss: 1.0558 - accuracy: 0.4750 - val_loss: 1.0570 - val_accuracy: 0.4734 - 81s/epoch - 1s/step\n",
      "Epoch 9/60\n",
      "54/54 - 81s - loss: 1.0557 - accuracy: 0.4750 - val_loss: 1.0568 - val_accuracy: 0.4734 - 81s/epoch - 1s/step\n",
      "Epoch 10/60\n",
      "54/54 - 81s - loss: 1.0558 - accuracy: 0.4750 - val_loss: 1.0568 - val_accuracy: 0.4734 - 81s/epoch - 1s/step\n",
      "Epoch 11/60\n",
      "54/54 - 80s - loss: 1.0558 - accuracy: 0.4750 - val_loss: 1.0569 - val_accuracy: 0.4734 - 80s/epoch - 1s/step\n",
      "Epoch 12/60\n",
      "54/54 - 82s - loss: 1.0558 - accuracy: 0.4750 - val_loss: 1.0569 - val_accuracy: 0.4734 - 82s/epoch - 2s/step\n",
      "Epoch 13/60\n",
      "54/54 - 81s - loss: 1.0558 - accuracy: 0.4750 - val_loss: 1.0569 - val_accuracy: 0.4734 - 81s/epoch - 1s/step\n",
      "Epoch 14/60\n",
      "54/54 - 80s - loss: 1.0557 - accuracy: 0.4750 - val_loss: 1.0569 - val_accuracy: 0.4734 - 80s/epoch - 1s/step\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 49, 49, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 1.0568903684616089\n",
      "Test accuracy: 0.47184300422668457\n"
     ]
    }
   ],
   "source": [
    "train(60,200,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b7be5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "next time\n",
    "penalty 0.01\n",
    "penalty last 0.001\n",
    "reverse\n",
    "\"\"\"\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    #X_train,XX,Y_train,YY=train_test_split(\n",
    "    #dataset, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=100*100\n",
    "        w=math.sqrt(inputs)\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation='relu')(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=30\n",
    "            w=math.sqrt(inputs)\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation='softmax')(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4,mode='min')\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.33,epochs=epochs_num,batch_size=batch_len,verbose=2,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10843b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "63/63 - 71s - loss: 1.0663 - accuracy: 0.4666 - val_loss: 1.0583 - val_accuracy: 0.4696 - 71s/epoch - 1s/step\n",
      "Epoch 2/60\n",
      "63/63 - 72s - loss: 1.0267 - accuracy: 0.4924 - val_loss: 0.9574 - val_accuracy: 0.5330 - 72s/epoch - 1s/step\n",
      "Epoch 3/60\n",
      "63/63 - 72s - loss: 0.9480 - accuracy: 0.5405 - val_loss: 0.9385 - val_accuracy: 0.5448 - 72s/epoch - 1s/step\n",
      "Epoch 4/60\n",
      "63/63 - 71s - loss: 0.9325 - accuracy: 0.5484 - val_loss: 0.9346 - val_accuracy: 0.5496 - 71s/epoch - 1s/step\n",
      "Epoch 5/60\n",
      "63/63 - 71s - loss: 0.9196 - accuracy: 0.5533 - val_loss: 0.9114 - val_accuracy: 0.5563 - 71s/epoch - 1s/step\n",
      "Epoch 6/60\n",
      "63/63 - 72s - loss: 0.9095 - accuracy: 0.5582 - val_loss: 0.9048 - val_accuracy: 0.5625 - 72s/epoch - 1s/step\n",
      "Epoch 7/60\n",
      "63/63 - 72s - loss: 0.9019 - accuracy: 0.5604 - val_loss: 0.9151 - val_accuracy: 0.5614 - 72s/epoch - 1s/step\n",
      "Epoch 8/60\n",
      "63/63 - 71s - loss: 0.9050 - accuracy: 0.5621 - val_loss: 0.8936 - val_accuracy: 0.5649 - 71s/epoch - 1s/step\n",
      "Epoch 9/60\n",
      "63/63 - 71s - loss: 0.8936 - accuracy: 0.5650 - val_loss: 0.8893 - val_accuracy: 0.5690 - 71s/epoch - 1s/step\n",
      "Epoch 10/60\n",
      "63/63 - 72s - loss: 0.8896 - accuracy: 0.5669 - val_loss: 0.8870 - val_accuracy: 0.5707 - 72s/epoch - 1s/step\n",
      "Epoch 11/60\n",
      "63/63 - 71s - loss: 0.8863 - accuracy: 0.5686 - val_loss: 0.8841 - val_accuracy: 0.5688 - 71s/epoch - 1s/step\n",
      "Epoch 12/60\n",
      "63/63 - 72s - loss: 0.8808 - accuracy: 0.5723 - val_loss: 0.8866 - val_accuracy: 0.5668 - 72s/epoch - 1s/step\n",
      "Epoch 13/60\n",
      "63/63 - 72s - loss: 0.8771 - accuracy: 0.5760 - val_loss: 0.8836 - val_accuracy: 0.5712 - 72s/epoch - 1s/step\n",
      "Epoch 14/60\n",
      "63/63 - 72s - loss: 0.8732 - accuracy: 0.5743 - val_loss: 0.8782 - val_accuracy: 0.5744 - 72s/epoch - 1s/step\n",
      "Epoch 15/60\n",
      "63/63 - 72s - loss: 0.8731 - accuracy: 0.5761 - val_loss: 0.8760 - val_accuracy: 0.5759 - 72s/epoch - 1s/step\n",
      "Epoch 16/60\n",
      "63/63 - 72s - loss: 0.8678 - accuracy: 0.5782 - val_loss: 0.8788 - val_accuracy: 0.5746 - 72s/epoch - 1s/step\n",
      "Epoch 17/60\n",
      "63/63 - 71s - loss: 0.8672 - accuracy: 0.5781 - val_loss: 0.8775 - val_accuracy: 0.5733 - 71s/epoch - 1s/step\n",
      "Epoch 18/60\n",
      "63/63 - 71s - loss: 0.8613 - accuracy: 0.5802 - val_loss: 0.8775 - val_accuracy: 0.5744 - 71s/epoch - 1s/step\n",
      "Epoch 19/60\n",
      "63/63 - 72s - loss: 0.8613 - accuracy: 0.5801 - val_loss: 0.8785 - val_accuracy: 0.5733 - 72s/epoch - 1s/step\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 49, 49, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 23, 23, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 10, 10, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5004476308822632\n",
      "Test accuracy: 0.7807167172431946\n"
     ]
    }
   ],
   "source": [
    "train(60,150,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "572d3220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14460/3171476587.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14460/772398948.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epochs_num, batch_len, conv_layers, neur_layers)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mcallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmlp_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.33\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs_num\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[1;31m#model.load_weights(\"weights.hdf5\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1418\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1419\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1420\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1421\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1714\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1715\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1716\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1717\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1718\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 954\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    955\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(60,300,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aba768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(60,500,3,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
