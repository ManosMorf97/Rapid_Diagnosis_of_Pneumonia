{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "711f8ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage import transform\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rescale\n",
    "import cv2\n",
    "import glob\n",
    "import random as ra\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "def process(X,Y,file,aug):\n",
    "    img=cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n",
    "    X.append(img)\n",
    "    #write your code\n",
    "    if \"virus\" in file:\n",
    "        Y.append(\"0\")\n",
    "    elif \"bacteria\" in file:\n",
    "        Y.append(\"1\")\n",
    "    else:\n",
    "        Y.append(\"2\")\n",
    "    if aug:\n",
    "        augmentation(X,Y)\n",
    "\n",
    "def normalize(dataset):\n",
    "    dataset=asarray(dataset).astype('float32')\n",
    "    dataset=dataset/255.0\n",
    "    return dataset\n",
    "    \n",
    "def create_dataset(directory):\n",
    "    #before work\n",
    "    files=glob.glob(directory+'/*.jpeg')\n",
    "    ra.shuffle(files)\n",
    "    X_train=[]\n",
    "    Y_train=[]\n",
    "    X_test=[]\n",
    "    Y_test=[]\n",
    "    for file in files[0:int(len(files)*0.8)]:\n",
    "        process(X_train,Y_train,file,True)\n",
    "    for file in files[int(len(files)*0.8):]:\n",
    "        process(X_test,Y_test,file,False)        \n",
    "    from numpy import asarray\n",
    "    X_train=normalize(X_train)\n",
    "    X_test=normalize(X_test)\n",
    "    return X_train,X_test,Y_train,Y_test\n",
    "\n",
    "def augmentation(dataset,labels):\n",
    "    last=len(labels)-1\n",
    "    scale_out = skimage.transform.rescale(dataset[last], scale=2.0, mode='constant')\n",
    "    scale_out=skimage.transform.resize(scale_out,(100,100))\n",
    "    scale_in = skimage.transform.rescale(dataset[last], scale=0.5, mode='constant')\n",
    "    scale_in=skimage.transform.resize(scale_in,(100,100))\n",
    "    dataset.append(scale_out)\n",
    "    labels.append(labels[last])\n",
    "    dataset.append(scale_in)\n",
    "    labels.append(labels[last])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a718a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers#aa##\n",
    "from keras import utils\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "import math\n",
    "X_train,X_test,Y_train,Y_test=create_dataset('chest_xray_lower_dim2')\n",
    "X_train=X_train.reshape(-1,100,100,1)\n",
    "X_test=X_test.reshape(-1,100,100,1)\n",
    "Y_train= keras.utils.to_categorical(Y_train,3)\n",
    "Y_test = keras.utils.to_categorical(Y_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ceda2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "next time\n",
    "penalty 0.01\n",
    "penalty last 0.001\n",
    "reverse\n",
    "\"\"\"\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    #X_train,XX,Y_train,YY=train_test_split(\n",
    "    #dataset, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=100*100\n",
    "        w=math.sqrt(inputs)\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation='relu',kernel_regularizer=regularizers.L2(0.01))(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=30\n",
    "            w=math.sqrt(inputs)\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation='softmax')(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4,mode='min')\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.2,epochs=epochs_num,batch_size=batch_len,verbose=2,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6262036f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "57/57 - 92s - loss: 1.6702 - accuracy: 0.4745 - val_loss: 1.3908 - val_accuracy: 0.4952 - 92s/epoch - 2s/step\n",
      "Epoch 2/60\n",
      "57/57 - 86s - loss: 1.3199 - accuracy: 0.4745 - val_loss: 1.2350 - val_accuracy: 0.4952 - 86s/epoch - 2s/step\n",
      "Epoch 3/60\n",
      "57/57 - 86s - loss: 1.2011 - accuracy: 0.4745 - val_loss: 1.1462 - val_accuracy: 0.4952 - 86s/epoch - 2s/step\n",
      "Epoch 4/60\n",
      "57/57 - 87s - loss: 1.1116 - accuracy: 0.4873 - val_loss: 1.0390 - val_accuracy: 0.5543 - 87s/epoch - 2s/step\n",
      "Epoch 5/60\n",
      "57/57 - 86s - loss: 1.0162 - accuracy: 0.5331 - val_loss: 0.9562 - val_accuracy: 0.5603 - 86s/epoch - 2s/step\n",
      "Epoch 6/60\n",
      "57/57 - 86s - loss: 0.9390 - accuracy: 0.5586 - val_loss: 0.8636 - val_accuracy: 0.6845 - 86s/epoch - 2s/step\n",
      "Epoch 7/60\n",
      "57/57 - 85s - loss: 0.7891 - accuracy: 0.6757 - val_loss: 0.7296 - val_accuracy: 0.6962 - 85s/epoch - 1s/step\n",
      "Epoch 8/60\n",
      "57/57 - 88s - loss: 0.7143 - accuracy: 0.7009 - val_loss: 0.6746 - val_accuracy: 0.7335 - 88s/epoch - 2s/step\n",
      "Epoch 9/60\n",
      "57/57 - 85s - loss: 0.6815 - accuracy: 0.7192 - val_loss: 0.6490 - val_accuracy: 0.7257 - 85s/epoch - 1s/step\n",
      "Epoch 10/60\n",
      "57/57 - 85s - loss: 0.6651 - accuracy: 0.7241 - val_loss: 0.7011 - val_accuracy: 0.7182 - 85s/epoch - 1s/step\n",
      "Epoch 11/60\n",
      "57/57 - 85s - loss: 0.6515 - accuracy: 0.7353 - val_loss: 0.6160 - val_accuracy: 0.7631 - 85s/epoch - 1s/step\n",
      "Epoch 12/60\n",
      "57/57 - 85s - loss: 0.6360 - accuracy: 0.7489 - val_loss: 0.6245 - val_accuracy: 0.7602 - 85s/epoch - 1s/step\n",
      "Epoch 13/60\n",
      "57/57 - 85s - loss: 0.6259 - accuracy: 0.7529 - val_loss: 0.6094 - val_accuracy: 0.7613 - 85s/epoch - 1s/step\n",
      "Epoch 14/60\n",
      "57/57 - 85s - loss: 0.6118 - accuracy: 0.7653 - val_loss: 0.5687 - val_accuracy: 0.7826 - 85s/epoch - 1s/step\n",
      "Epoch 15/60\n",
      "57/57 - 86s - loss: 0.5918 - accuracy: 0.7732 - val_loss: 0.5656 - val_accuracy: 0.7834 - 86s/epoch - 2s/step\n",
      "Epoch 16/60\n",
      "57/57 - 85s - loss: 0.5876 - accuracy: 0.7739 - val_loss: 0.5952 - val_accuracy: 0.7584 - 85s/epoch - 1s/step\n",
      "Epoch 17/60\n",
      "57/57 - 85s - loss: 0.5809 - accuracy: 0.7731 - val_loss: 0.5586 - val_accuracy: 0.7901 - 85s/epoch - 1s/step\n",
      "Epoch 18/60\n",
      "57/57 - 86s - loss: 0.5636 - accuracy: 0.7853 - val_loss: 0.5552 - val_accuracy: 0.7933 - 86s/epoch - 2s/step\n",
      "Epoch 19/60\n",
      "57/57 - 87s - loss: 0.5859 - accuracy: 0.7745 - val_loss: 0.5479 - val_accuracy: 0.7926 - 87s/epoch - 2s/step\n",
      "Epoch 20/60\n",
      "57/57 - 86s - loss: 0.5640 - accuracy: 0.7799 - val_loss: 0.5757 - val_accuracy: 0.7823 - 86s/epoch - 2s/step\n",
      "Epoch 21/60\n",
      "57/57 - 98s - loss: 0.5581 - accuracy: 0.7816 - val_loss: 0.6022 - val_accuracy: 0.7777 - 98s/epoch - 2s/step\n",
      "Epoch 22/60\n",
      "57/57 - 107s - loss: 0.5691 - accuracy: 0.7811 - val_loss: 0.5394 - val_accuracy: 0.8043 - 107s/epoch - 2s/step\n",
      "Epoch 23/60\n",
      "57/57 - 92s - loss: 0.5530 - accuracy: 0.7880 - val_loss: 0.5254 - val_accuracy: 0.8004 - 92s/epoch - 2s/step\n",
      "Epoch 24/60\n",
      "57/57 - 93s - loss: 0.5390 - accuracy: 0.7917 - val_loss: 0.5296 - val_accuracy: 0.8040 - 93s/epoch - 2s/step\n",
      "Epoch 25/60\n",
      "57/57 - 88s - loss: 0.5355 - accuracy: 0.7942 - val_loss: 0.5211 - val_accuracy: 0.8079 - 88s/epoch - 2s/step\n",
      "Epoch 26/60\n",
      "57/57 - 87s - loss: 0.5250 - accuracy: 0.7959 - val_loss: 0.5274 - val_accuracy: 0.8040 - 87s/epoch - 2s/step\n",
      "Epoch 27/60\n",
      "57/57 - 96s - loss: 0.5281 - accuracy: 0.7980 - val_loss: 0.5354 - val_accuracy: 0.8026 - 96s/epoch - 2s/step\n",
      "Epoch 28/60\n",
      "57/57 - 91s - loss: 0.5179 - accuracy: 0.8017 - val_loss: 0.5297 - val_accuracy: 0.8011 - 91s/epoch - 2s/step\n",
      "Epoch 29/60\n",
      "57/57 - 89s - loss: 0.5147 - accuracy: 0.8024 - val_loss: 0.5085 - val_accuracy: 0.8132 - 89s/epoch - 2s/step\n",
      "Epoch 30/60\n",
      "57/57 - 87s - loss: 0.5104 - accuracy: 0.8046 - val_loss: 0.5237 - val_accuracy: 0.8068 - 87s/epoch - 2s/step\n",
      "Epoch 31/60\n",
      "57/57 - 86s - loss: 0.5062 - accuracy: 0.8048 - val_loss: 0.5280 - val_accuracy: 0.7958 - 86s/epoch - 2s/step\n",
      "Epoch 32/60\n",
      "57/57 - 86s - loss: 0.5083 - accuracy: 0.8078 - val_loss: 0.5389 - val_accuracy: 0.7898 - 86s/epoch - 2s/step\n",
      "Epoch 33/60\n",
      "57/57 - 86s - loss: 0.5055 - accuracy: 0.8039 - val_loss: 0.5156 - val_accuracy: 0.8040 - 86s/epoch - 2s/step\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 49, 49, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5715711712837219\n",
      "Test accuracy: 0.7815699577331543\n"
     ]
    }
   ],
   "source": [
    "train(60,200,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5449ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w,maxval=1/w, seed=None)\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    X_trainR,XX,Y_trainR,YY=train_test_split(\n",
    "    X_train,Y_train, test_size=0.05, random_state=20)\n",
    "\n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=2560\n",
    "        w=math.sqrt(inputs)\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w,maxval=1/w, seed=None),kernel_regularizer=regularizers.L2(0.01))(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=inputs*30\n",
    "            w=math.sqrt(inputs)\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation='softmax',kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w,maxval=1/w, seed=None))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4,mode='min')\n",
    "    model=mlp_model()\n",
    "    model.fit(X_trainR,Y_trainR,validation_split=0.2,epochs=epochs_num,batch_size=batch_len,verbose=2,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8950827d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "54/54 - 106s - loss: 1.1004 - accuracy: 0.4707 - val_loss: 1.0750 - val_accuracy: 0.4734 - 106s/epoch - 2s/step\n",
      "Epoch 2/60\n",
      "54/54 - 81s - loss: 1.0625 - accuracy: 0.4750 - val_loss: 1.0581 - val_accuracy: 0.4734 - 81s/epoch - 2s/step\n",
      "Epoch 3/60\n",
      "54/54 - 82s - loss: 1.0565 - accuracy: 0.4750 - val_loss: 1.0569 - val_accuracy: 0.4734 - 82s/epoch - 2s/step\n",
      "Epoch 4/60\n",
      "54/54 - 81s - loss: 1.0558 - accuracy: 0.4750 - val_loss: 1.0568 - val_accuracy: 0.4734 - 81s/epoch - 1s/step\n",
      "Epoch 5/60\n",
      "54/54 - 81s - loss: 1.0557 - accuracy: 0.4750 - val_loss: 1.0569 - val_accuracy: 0.4734 - 81s/epoch - 1s/step\n",
      "Epoch 6/60\n",
      "54/54 - 82s - loss: 1.0558 - accuracy: 0.4750 - val_loss: 1.0568 - val_accuracy: 0.4734 - 82s/epoch - 2s/step\n",
      "Epoch 7/60\n",
      "54/54 - 81s - loss: 1.0557 - accuracy: 0.4750 - val_loss: 1.0569 - val_accuracy: 0.4734 - 81s/epoch - 1s/step\n",
      "Epoch 8/60\n",
      "54/54 - 81s - loss: 1.0558 - accuracy: 0.4750 - val_loss: 1.0570 - val_accuracy: 0.4734 - 81s/epoch - 1s/step\n",
      "Epoch 9/60\n",
      "54/54 - 81s - loss: 1.0557 - accuracy: 0.4750 - val_loss: 1.0568 - val_accuracy: 0.4734 - 81s/epoch - 1s/step\n",
      "Epoch 10/60\n",
      "54/54 - 81s - loss: 1.0558 - accuracy: 0.4750 - val_loss: 1.0568 - val_accuracy: 0.4734 - 81s/epoch - 1s/step\n",
      "Epoch 11/60\n",
      "54/54 - 80s - loss: 1.0558 - accuracy: 0.4750 - val_loss: 1.0569 - val_accuracy: 0.4734 - 80s/epoch - 1s/step\n",
      "Epoch 12/60\n",
      "54/54 - 82s - loss: 1.0558 - accuracy: 0.4750 - val_loss: 1.0569 - val_accuracy: 0.4734 - 82s/epoch - 2s/step\n",
      "Epoch 13/60\n",
      "54/54 - 81s - loss: 1.0558 - accuracy: 0.4750 - val_loss: 1.0569 - val_accuracy: 0.4734 - 81s/epoch - 1s/step\n",
      "Epoch 14/60\n",
      "54/54 - 80s - loss: 1.0557 - accuracy: 0.4750 - val_loss: 1.0569 - val_accuracy: 0.4734 - 80s/epoch - 1s/step\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 49, 49, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 1.0568903684616089\n",
      "Test accuracy: 0.47184300422668457\n"
     ]
    }
   ],
   "source": [
    "train(60,200,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b7be5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "next time\n",
    "penalty 0.01\n",
    "penalty last 0.001\n",
    "reverse\n",
    "\"\"\"\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    #X_train,XX,Y_train,YY=train_test_split(\n",
    "    #dataset, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=100*100\n",
    "        w=math.sqrt(inputs)\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation='relu')(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=30\n",
    "            w=math.sqrt(inputs)\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation='softmax')(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4,mode='min')\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.33,epochs=epochs_num,batch_size=batch_len,verbose=2,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10843b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "63/63 - 71s - loss: 1.0663 - accuracy: 0.4666 - val_loss: 1.0583 - val_accuracy: 0.4696 - 71s/epoch - 1s/step\n",
      "Epoch 2/60\n",
      "63/63 - 72s - loss: 1.0267 - accuracy: 0.4924 - val_loss: 0.9574 - val_accuracy: 0.5330 - 72s/epoch - 1s/step\n",
      "Epoch 3/60\n",
      "63/63 - 72s - loss: 0.9480 - accuracy: 0.5405 - val_loss: 0.9385 - val_accuracy: 0.5448 - 72s/epoch - 1s/step\n",
      "Epoch 4/60\n",
      "63/63 - 71s - loss: 0.9325 - accuracy: 0.5484 - val_loss: 0.9346 - val_accuracy: 0.5496 - 71s/epoch - 1s/step\n",
      "Epoch 5/60\n",
      "63/63 - 71s - loss: 0.9196 - accuracy: 0.5533 - val_loss: 0.9114 - val_accuracy: 0.5563 - 71s/epoch - 1s/step\n",
      "Epoch 6/60\n",
      "63/63 - 72s - loss: 0.9095 - accuracy: 0.5582 - val_loss: 0.9048 - val_accuracy: 0.5625 - 72s/epoch - 1s/step\n",
      "Epoch 7/60\n",
      "63/63 - 72s - loss: 0.9019 - accuracy: 0.5604 - val_loss: 0.9151 - val_accuracy: 0.5614 - 72s/epoch - 1s/step\n",
      "Epoch 8/60\n",
      "63/63 - 71s - loss: 0.9050 - accuracy: 0.5621 - val_loss: 0.8936 - val_accuracy: 0.5649 - 71s/epoch - 1s/step\n",
      "Epoch 9/60\n",
      "63/63 - 71s - loss: 0.8936 - accuracy: 0.5650 - val_loss: 0.8893 - val_accuracy: 0.5690 - 71s/epoch - 1s/step\n",
      "Epoch 10/60\n",
      "63/63 - 72s - loss: 0.8896 - accuracy: 0.5669 - val_loss: 0.8870 - val_accuracy: 0.5707 - 72s/epoch - 1s/step\n",
      "Epoch 11/60\n",
      "63/63 - 71s - loss: 0.8863 - accuracy: 0.5686 - val_loss: 0.8841 - val_accuracy: 0.5688 - 71s/epoch - 1s/step\n",
      "Epoch 12/60\n",
      "63/63 - 72s - loss: 0.8808 - accuracy: 0.5723 - val_loss: 0.8866 - val_accuracy: 0.5668 - 72s/epoch - 1s/step\n",
      "Epoch 13/60\n",
      "63/63 - 72s - loss: 0.8771 - accuracy: 0.5760 - val_loss: 0.8836 - val_accuracy: 0.5712 - 72s/epoch - 1s/step\n",
      "Epoch 14/60\n",
      "63/63 - 72s - loss: 0.8732 - accuracy: 0.5743 - val_loss: 0.8782 - val_accuracy: 0.5744 - 72s/epoch - 1s/step\n",
      "Epoch 15/60\n",
      "63/63 - 72s - loss: 0.8731 - accuracy: 0.5761 - val_loss: 0.8760 - val_accuracy: 0.5759 - 72s/epoch - 1s/step\n",
      "Epoch 16/60\n",
      "63/63 - 72s - loss: 0.8678 - accuracy: 0.5782 - val_loss: 0.8788 - val_accuracy: 0.5746 - 72s/epoch - 1s/step\n",
      "Epoch 17/60\n",
      "63/63 - 71s - loss: 0.8672 - accuracy: 0.5781 - val_loss: 0.8775 - val_accuracy: 0.5733 - 71s/epoch - 1s/step\n",
      "Epoch 18/60\n",
      "63/63 - 71s - loss: 0.8613 - accuracy: 0.5802 - val_loss: 0.8775 - val_accuracy: 0.5744 - 71s/epoch - 1s/step\n",
      "Epoch 19/60\n",
      "63/63 - 72s - loss: 0.8613 - accuracy: 0.5801 - val_loss: 0.8785 - val_accuracy: 0.5733 - 72s/epoch - 1s/step\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 49, 49, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 23, 23, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 10, 10, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5004476308822632\n",
      "Test accuracy: 0.7807167172431946\n"
     ]
    }
   ],
   "source": [
    "train(60,150,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "572d3220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14460/3171476587.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14460/772398948.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epochs_num, batch_len, conv_layers, neur_layers)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mcallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmlp_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.33\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs_num\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m     \u001b[1;31m#model.load_weights(\"weights.hdf5\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1418\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1419\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[1;32m-> 1420\u001b[1;33m           val_logs = self.evaluate(\n\u001b[0m\u001b[0;32m   1421\u001b[0m               \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1422\u001b[0m               \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1714\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1715\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1716\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1717\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1718\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    952\u001b[0m       \u001b[1;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    953\u001b[0m       \u001b[1;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 954\u001b[1;33m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    955\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(60,300,3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0475e42",
   "metadata": {},
   "source": [
    "#### Let's try with 200x200\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9aba768c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "63/63 - 379s - loss: 1.0642 - accuracy: 0.4740 - val_loss: 1.0557 - val_accuracy: 0.4787 - 379s/epoch - 6s/step\n",
      "Epoch 2/60\n",
      "63/63 - 366s - loss: 1.0432 - accuracy: 0.4914 - val_loss: 0.9698 - val_accuracy: 0.5392 - 366s/epoch - 6s/step\n",
      "Epoch 3/60\n",
      "63/63 - 369s - loss: 0.9513 - accuracy: 0.5412 - val_loss: 0.9269 - val_accuracy: 0.5464 - 369s/epoch - 6s/step\n",
      "Epoch 4/60\n",
      "63/63 - 394s - loss: 0.7875 - accuracy: 0.6397 - val_loss: 0.7058 - val_accuracy: 0.6779 - 394s/epoch - 6s/step\n",
      "Epoch 5/60\n",
      "63/63 - 374s - loss: 0.6438 - accuracy: 0.7117 - val_loss: 0.6233 - val_accuracy: 0.7066 - 374s/epoch - 6s/step\n",
      "Epoch 6/60\n",
      "63/63 - 370s - loss: 0.6050 - accuracy: 0.7266 - val_loss: 0.6027 - val_accuracy: 0.7245 - 370s/epoch - 6s/step\n",
      "Epoch 7/60\n",
      "63/63 - 357s - loss: 0.5864 - accuracy: 0.7444 - val_loss: 0.5890 - val_accuracy: 0.7413 - 357s/epoch - 6s/step\n",
      "Epoch 8/60\n",
      "63/63 - 368s - loss: 0.5598 - accuracy: 0.7624 - val_loss: 0.5680 - val_accuracy: 0.7605 - 368s/epoch - 6s/step\n",
      "Epoch 9/60\n",
      "63/63 - 472s - loss: 0.5418 - accuracy: 0.7686 - val_loss: 0.5582 - val_accuracy: 0.7697 - 472s/epoch - 7s/step\n",
      "Epoch 10/60\n",
      "63/63 - 382s - loss: 0.5246 - accuracy: 0.7769 - val_loss: 0.5449 - val_accuracy: 0.7699 - 382s/epoch - 6s/step\n",
      "Epoch 11/60\n",
      "63/63 - 349s - loss: 0.5091 - accuracy: 0.7836 - val_loss: 0.5370 - val_accuracy: 0.7725 - 349s/epoch - 6s/step\n",
      "Epoch 12/60\n",
      "63/63 - 366s - loss: 0.5013 - accuracy: 0.7853 - val_loss: 0.5534 - val_accuracy: 0.7624 - 366s/epoch - 6s/step\n",
      "Epoch 13/60\n",
      "63/63 - 360s - loss: 0.4968 - accuracy: 0.7874 - val_loss: 0.5289 - val_accuracy: 0.7859 - 360s/epoch - 6s/step\n",
      "Epoch 14/60\n",
      "63/63 - 359s - loss: 0.4821 - accuracy: 0.7960 - val_loss: 0.5571 - val_accuracy: 0.7658 - 359s/epoch - 6s/step\n",
      "Epoch 15/60\n",
      "63/63 - 385s - loss: 0.4767 - accuracy: 0.7941 - val_loss: 0.5383 - val_accuracy: 0.7805 - 385s/epoch - 6s/step\n",
      "Epoch 16/60\n",
      "63/63 - 461s - loss: 0.4697 - accuracy: 0.8011 - val_loss: 0.5439 - val_accuracy: 0.7697 - 461s/epoch - 7s/step\n",
      "Epoch 17/60\n",
      "63/63 - 420s - loss: 0.4514 - accuracy: 0.8047 - val_loss: 0.5465 - val_accuracy: 0.7695 - 420s/epoch - 7s/step\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 200, 200, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 198, 198, 40)      400       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 99, 99, 40)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 97, 97, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 48, 48, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 46, 46, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 23, 23, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 10, 10, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2560)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136,943\n",
      "Trainable params: 136,943\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5280725955963135\n",
      "Test accuracy: 0.7679181098937988\n",
      "---------\n",
      "Epoch 1/60\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5480/3713521550.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"---------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"---------\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5480/3713521550.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epochs_num, batch_len, conv_layers, neur_layers)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[0mcallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpatience\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'min'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmlp_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.33\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs_num\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_len\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m     \u001b[1;31m#model.load_weights(\"weights.hdf5\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "from skimage import transform\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rescale\n",
    "import cv2\n",
    "import glob\n",
    "import random as ra\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "def process(X,Y,file,aug):\n",
    "    img=cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n",
    "    X.append(img)\n",
    "    #write your code\n",
    "    if \"virus\" in file:\n",
    "        Y.append(\"0\")\n",
    "    elif \"bacteria\" in file:\n",
    "        Y.append(\"1\")\n",
    "    else:\n",
    "        Y.append(\"2\")\n",
    "    if aug:\n",
    "        augmentation(X,Y)\n",
    "\n",
    "def normalize(dataset):\n",
    "    dataset=asarray(dataset).astype('float32')\n",
    "    dataset=dataset/255.0\n",
    "    return dataset\n",
    "    \n",
    "def create_dataset(directory):\n",
    "    #before work\n",
    "    files=glob.glob(directory+'/*.jpeg')\n",
    "    ra.shuffle(files)\n",
    "    X_train=[]\n",
    "    Y_train=[]\n",
    "    X_test=[]\n",
    "    Y_test=[]\n",
    "    for file in files[0:int(len(files)*0.8)]:\n",
    "        process(X_train,Y_train,file,True)\n",
    "    for file in files[int(len(files)*0.8):]:\n",
    "        process(X_test,Y_test,file,False)        \n",
    "    from numpy import asarray\n",
    "    X_train=normalize(X_train)\n",
    "    X_test=normalize(X_test)\n",
    "    return X_train,X_test,Y_train,Y_test\n",
    "\n",
    "def augmentation(dataset,labels):\n",
    "    last=len(labels)-1\n",
    "    scale_out = skimage.transform.rescale(dataset[last], scale=2.0, mode='constant')\n",
    "    scale_out=skimage.transform.resize(scale_out,(200,200))\n",
    "    scale_in = skimage.transform.rescale(dataset[last], scale=0.5, mode='constant')\n",
    "    scale_in=skimage.transform.resize(scale_in,(200,200))\n",
    "    dataset.append(scale_out)\n",
    "    labels.append(labels[last])\n",
    "    dataset.append(scale_in)\n",
    "    labels.append(labels[last])\n",
    "    \n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import utils\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "import math\n",
    "X_train,X_test,Y_train,Y_test=create_dataset('chest_xray_lower_dim200x200')\n",
    "X_train=X_train.reshape(-1,200,200,1)\n",
    "X_test=X_test.reshape(-1,200,200,1)\n",
    "Y_train= keras.utils.to_categorical(Y_train,3)\n",
    "Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "\n",
    "\"\"\"\n",
    "next time\n",
    "penalty 0.01\n",
    "penalty last 0.001\n",
    "reverse\n",
    "\"\"\"\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    #X_train,XX,Y_train,YY=train_test_split(\n",
    "    #dataset, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(200,200,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=200*200\n",
    "        w=math.sqrt(inputs)\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation='relu')(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=30\n",
    "            w=math.sqrt(inputs)\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation='softmax')(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4,mode='min')\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.33,epochs=epochs_num,batch_size=batch_len,verbose=2,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])\n",
    "    \n",
    "train(60,150,4,3)\n",
    "print(\"---------\")\n",
    "train(60,300,4,3)\n",
    "print(\"---------\")\n",
    "train(60,500,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1db5bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "next time\n",
    "penalty 0.01\n",
    "penalty last 0.001\n",
    "reverse\n",
    "\"\"\"\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    #X_train,XX,Y_train,YY=train_test_split(\n",
    "    #dataset, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(200,200,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=200*200\n",
    "        w=math.sqrt(inputs)\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation='relu')(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=30\n",
    "            w=math.sqrt(inputs)\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation='softmax')(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4,mode='min')\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.5,epochs=epochs_num,batch_size=batch_len,verbose=2,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])\n",
    "    \n",
    "train(60,200,4,3)\n",
    "\n",
    "#The score was 79.1%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c51733",
   "metadata": {},
   "source": [
    "#### We would try with bigger batches but the memory can't handle it with this power we return 100x100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b7ac8a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "32/32 [==============================] - 78s 2s/step - loss: 1.0671 - accuracy: 0.4681 - val_loss: 1.0637 - val_accuracy: 0.4560\n",
      "Epoch 2/60\n",
      "32/32 [==============================] - 72s 2s/step - loss: 1.0227 - accuracy: 0.5062 - val_loss: 0.9804 - val_accuracy: 0.5248\n",
      "Epoch 3/60\n",
      "32/32 [==============================] - 74s 2s/step - loss: 0.9510 - accuracy: 0.5431 - val_loss: 0.9376 - val_accuracy: 0.5382\n",
      "Epoch 4/60\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.9293 - accuracy: 0.5499 - val_loss: 0.9270 - val_accuracy: 0.5423\n",
      "Epoch 5/60\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.9140 - accuracy: 0.5559 - val_loss: 0.9210 - val_accuracy: 0.5492\n",
      "Epoch 6/60\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.9065 - accuracy: 0.5604 - val_loss: 0.9165 - val_accuracy: 0.5474\n",
      "Epoch 7/60\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.9033 - accuracy: 0.5631 - val_loss: 0.9044 - val_accuracy: 0.5543\n",
      "Epoch 8/60\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.8942 - accuracy: 0.5683 - val_loss: 0.8988 - val_accuracy: 0.5591\n",
      "Epoch 9/60\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.8922 - accuracy: 0.5701 - val_loss: 0.8991 - val_accuracy: 0.5574\n",
      "Epoch 10/60\n",
      "32/32 [==============================] - 75s 2s/step - loss: 0.8884 - accuracy: 0.5730 - val_loss: 0.8925 - val_accuracy: 0.5597\n",
      "Epoch 11/60\n",
      "32/32 [==============================] - 74s 2s/step - loss: 0.8751 - accuracy: 0.5747 - val_loss: 0.8867 - val_accuracy: 0.5643\n",
      "Epoch 12/60\n",
      "32/32 [==============================] - 74s 2s/step - loss: 0.8662 - accuracy: 0.5782 - val_loss: 0.8598 - val_accuracy: 0.6063\n",
      "Epoch 13/60\n",
      "32/32 [==============================] - 74s 2s/step - loss: 0.7606 - accuracy: 0.6579 - val_loss: 0.6687 - val_accuracy: 0.6960\n",
      "Epoch 14/60\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.6228 - accuracy: 0.7307 - val_loss: 0.6485 - val_accuracy: 0.7130\n",
      "Epoch 15/60\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.5877 - accuracy: 0.7460 - val_loss: 0.5785 - val_accuracy: 0.7626\n",
      "Epoch 16/60\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.5565 - accuracy: 0.7660 - val_loss: 0.6185 - val_accuracy: 0.7499\n",
      "Epoch 17/60\n",
      "32/32 [==============================] - 81s 3s/step - loss: 0.5409 - accuracy: 0.7656 - val_loss: 0.5640 - val_accuracy: 0.7637\n",
      "Epoch 18/60\n",
      "32/32 [==============================] - 97s 3s/step - loss: 0.5308 - accuracy: 0.7735 - val_loss: 0.5618 - val_accuracy: 0.7648\n",
      "Epoch 19/60\n",
      "32/32 [==============================] - 76s 2s/step - loss: 0.5274 - accuracy: 0.7736 - val_loss: 0.5479 - val_accuracy: 0.7719\n",
      "Epoch 20/60\n",
      "32/32 [==============================] - 81s 3s/step - loss: 0.5119 - accuracy: 0.7796 - val_loss: 0.5379 - val_accuracy: 0.7816\n",
      "Epoch 21/60\n",
      "32/32 [==============================] - 90s 3s/step - loss: 0.4924 - accuracy: 0.7851 - val_loss: 0.5286 - val_accuracy: 0.7809\n",
      "Epoch 22/60\n",
      "32/32 [==============================] - 87s 3s/step - loss: 0.4850 - accuracy: 0.7887 - val_loss: 0.5319 - val_accuracy: 0.7818\n",
      "Epoch 23/60\n",
      "32/32 [==============================] - 87s 3s/step - loss: 0.4841 - accuracy: 0.7911 - val_loss: 0.5288 - val_accuracy: 0.7842\n",
      "Epoch 24/60\n",
      "32/32 [==============================] - 89s 3s/step - loss: 0.4739 - accuracy: 0.7924 - val_loss: 0.5872 - val_accuracy: 0.7613\n",
      "Epoch 25/60\n",
      "32/32 [==============================] - 81s 3s/step - loss: 0.4723 - accuracy: 0.7924 - val_loss: 0.5201 - val_accuracy: 0.7749\n",
      "Epoch 26/60\n",
      "32/32 [==============================] - 90s 3s/step - loss: 0.4678 - accuracy: 0.7992 - val_loss: 0.5118 - val_accuracy: 0.7909\n",
      "Epoch 27/60\n",
      "32/32 [==============================] - 90s 3s/step - loss: 0.4568 - accuracy: 0.8009 - val_loss: 0.5160 - val_accuracy: 0.7801\n",
      "Epoch 28/60\n",
      "32/32 [==============================] - 90s 3s/step - loss: 0.4478 - accuracy: 0.8072 - val_loss: 0.5282 - val_accuracy: 0.7844\n",
      "Epoch 29/60\n",
      "32/32 [==============================] - 76s 2s/step - loss: 0.4426 - accuracy: 0.8091 - val_loss: 0.5304 - val_accuracy: 0.7794\n",
      "Epoch 30/60\n",
      "32/32 [==============================] - 75s 2s/step - loss: 0.4344 - accuracy: 0.8127 - val_loss: 0.5550 - val_accuracy: 0.7784\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 49, 49, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5179892778396606\n",
      "Test accuracy: 0.7781569957733154\n",
      "---------\n",
      "Epoch 1/60\n",
      "19/19 [==============================] - 85s 4s/step - loss: 1.0668 - accuracy: 0.4798 - val_loss: 1.0661 - val_accuracy: 0.4560\n",
      "Epoch 2/60\n",
      "19/19 [==============================] - 87s 5s/step - loss: 1.0380 - accuracy: 0.4903 - val_loss: 1.0053 - val_accuracy: 0.5170\n",
      "Epoch 3/60\n",
      "19/19 [==============================] - 95s 5s/step - loss: 0.9623 - accuracy: 0.5365 - val_loss: 0.9790 - val_accuracy: 0.5179\n",
      "Epoch 4/60\n",
      "19/19 [==============================] - 87s 5s/step - loss: 0.9409 - accuracy: 0.5459 - val_loss: 0.9628 - val_accuracy: 0.5224\n",
      "Epoch 5/60\n",
      "19/19 [==============================] - 82s 4s/step - loss: 0.9276 - accuracy: 0.5509 - val_loss: 0.9417 - val_accuracy: 0.5289\n",
      "Epoch 6/60\n",
      "19/19 [==============================] - 86s 5s/step - loss: 0.9170 - accuracy: 0.5525 - val_loss: 0.9199 - val_accuracy: 0.5416\n",
      "Epoch 7/60\n",
      "19/19 [==============================] - 81s 4s/step - loss: 0.8986 - accuracy: 0.5621 - val_loss: 0.8996 - val_accuracy: 0.5505\n",
      "Epoch 8/60\n",
      "19/19 [==============================] - 81s 4s/step - loss: 0.8651 - accuracy: 0.5678 - val_loss: 0.8426 - val_accuracy: 0.5774\n",
      "Epoch 9/60\n",
      "19/19 [==============================] - 80s 4s/step - loss: 0.7737 - accuracy: 0.6644 - val_loss: 0.7395 - val_accuracy: 0.6953\n",
      "Epoch 10/60\n",
      "19/19 [==============================] - 81s 4s/step - loss: 0.6912 - accuracy: 0.6996 - val_loss: 0.6767 - val_accuracy: 0.7040\n",
      "Epoch 11/60\n",
      "19/19 [==============================] - 80s 4s/step - loss: 0.6483 - accuracy: 0.7164 - val_loss: 0.6399 - val_accuracy: 0.7199\n",
      "Epoch 12/60\n",
      "19/19 [==============================] - 80s 4s/step - loss: 0.6158 - accuracy: 0.7336 - val_loss: 0.6131 - val_accuracy: 0.7432\n",
      "Epoch 13/60\n",
      "19/19 [==============================] - 79s 4s/step - loss: 0.5969 - accuracy: 0.7383 - val_loss: 0.6208 - val_accuracy: 0.7268\n",
      "Epoch 14/60\n",
      "19/19 [==============================] - 79s 4s/step - loss: 0.5865 - accuracy: 0.7475 - val_loss: 0.5913 - val_accuracy: 0.7546\n",
      "Epoch 15/60\n",
      "19/19 [==============================] - 81s 4s/step - loss: 0.5643 - accuracy: 0.7556 - val_loss: 0.5869 - val_accuracy: 0.7499\n",
      "Epoch 16/60\n",
      "19/19 [==============================] - 82s 4s/step - loss: 0.5583 - accuracy: 0.7630 - val_loss: 0.5688 - val_accuracy: 0.7667\n",
      "Epoch 17/60\n",
      "19/19 [==============================] - 79s 4s/step - loss: 0.5487 - accuracy: 0.7685 - val_loss: 0.5627 - val_accuracy: 0.7697\n",
      "Epoch 18/60\n",
      "19/19 [==============================] - 80s 4s/step - loss: 0.5380 - accuracy: 0.7698 - val_loss: 0.5527 - val_accuracy: 0.7693\n",
      "Epoch 19/60\n",
      "19/19 [==============================] - 80s 4s/step - loss: 0.5261 - accuracy: 0.7754 - val_loss: 0.5425 - val_accuracy: 0.7749\n",
      "Epoch 20/60\n",
      "19/19 [==============================] - 78s 4s/step - loss: 0.5186 - accuracy: 0.7805 - val_loss: 0.5404 - val_accuracy: 0.7749\n",
      "Epoch 21/60\n",
      "19/19 [==============================] - 84s 4s/step - loss: 0.5138 - accuracy: 0.7802 - val_loss: 0.5356 - val_accuracy: 0.7779\n",
      "Epoch 22/60\n",
      "19/19 [==============================] - 80s 4s/step - loss: 0.5133 - accuracy: 0.7804 - val_loss: 0.5537 - val_accuracy: 0.7745\n",
      "Epoch 23/60\n",
      "19/19 [==============================] - 79s 4s/step - loss: 0.5105 - accuracy: 0.7814 - val_loss: 0.5440 - val_accuracy: 0.7781\n",
      "Epoch 24/60\n",
      "19/19 [==============================] - 80s 4s/step - loss: 0.4968 - accuracy: 0.7870 - val_loss: 0.5280 - val_accuracy: 0.7812\n",
      "Epoch 25/60\n",
      "19/19 [==============================] - 90s 5s/step - loss: 0.4943 - accuracy: 0.7877 - val_loss: 0.5355 - val_accuracy: 0.7773\n",
      "Epoch 26/60\n",
      "19/19 [==============================] - 83s 4s/step - loss: 0.4922 - accuracy: 0.7896 - val_loss: 0.5253 - val_accuracy: 0.7781\n",
      "Epoch 27/60\n",
      "19/19 [==============================] - 95s 5s/step - loss: 0.4823 - accuracy: 0.7918 - val_loss: 0.5263 - val_accuracy: 0.7796\n",
      "Epoch 28/60\n",
      "19/19 [==============================] - 85s 4s/step - loss: 0.4874 - accuracy: 0.7879 - val_loss: 0.5267 - val_accuracy: 0.7827\n",
      "Epoch 29/60\n",
      "19/19 [==============================] - 80s 4s/step - loss: 0.4759 - accuracy: 0.7895 - val_loss: 0.5246 - val_accuracy: 0.7807\n",
      "Epoch 30/60\n",
      "19/19 [==============================] - 79s 4s/step - loss: 0.4648 - accuracy: 0.7992 - val_loss: 0.5226 - val_accuracy: 0.7723\n",
      "Epoch 31/60\n",
      "19/19 [==============================] - 85s 4s/step - loss: 0.4676 - accuracy: 0.7970 - val_loss: 0.5366 - val_accuracy: 0.7792\n",
      "Epoch 32/60\n",
      "19/19 [==============================] - 94s 5s/step - loss: 0.4715 - accuracy: 0.7925 - val_loss: 0.5330 - val_accuracy: 0.7859\n",
      "Epoch 33/60\n",
      "19/19 [==============================] - 87s 5s/step - loss: 0.4639 - accuracy: 0.7991 - val_loss: 0.5163 - val_accuracy: 0.7850\n",
      "Epoch 34/60\n",
      "19/19 [==============================] - 90s 5s/step - loss: 0.4581 - accuracy: 0.8034 - val_loss: 0.5247 - val_accuracy: 0.7857\n",
      "Epoch 35/60\n",
      "19/19 [==============================] - 85s 5s/step - loss: 0.4498 - accuracy: 0.8017 - val_loss: 0.5341 - val_accuracy: 0.7896\n",
      "Epoch 36/60\n",
      "19/19 [==============================] - 80s 4s/step - loss: 0.4438 - accuracy: 0.8065 - val_loss: 0.5237 - val_accuracy: 0.7939\n",
      "Epoch 37/60\n",
      "19/19 [==============================] - 80s 4s/step - loss: 0.4409 - accuracy: 0.8092 - val_loss: 0.5155 - val_accuracy: 0.7850\n",
      "Epoch 38/60\n",
      "19/19 [==============================] - 85s 4s/step - loss: 0.4414 - accuracy: 0.8070 - val_loss: 0.5317 - val_accuracy: 0.7809\n",
      "Epoch 39/60\n",
      "19/19 [==============================] - 84s 4s/step - loss: 0.4448 - accuracy: 0.8065 - val_loss: 0.5120 - val_accuracy: 0.7881\n",
      "Epoch 40/60\n",
      "19/19 [==============================] - 106s 6s/step - loss: 0.4367 - accuracy: 0.8111 - val_loss: 0.5205 - val_accuracy: 0.7874\n",
      "Epoch 41/60\n",
      "19/19 [==============================] - 99s 5s/step - loss: 0.4395 - accuracy: 0.8094 - val_loss: 0.5350 - val_accuracy: 0.7891\n",
      "Epoch 42/60\n",
      "19/19 [==============================] - 94s 5s/step - loss: 0.4279 - accuracy: 0.8110 - val_loss: 0.5250 - val_accuracy: 0.7812\n",
      "Epoch 43/60\n",
      "19/19 [==============================] - 96s 5s/step - loss: 0.4308 - accuracy: 0.8112 - val_loss: 0.5183 - val_accuracy: 0.7870\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 49, 49, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5188986659049988\n",
      "Test accuracy: 0.7679181098937988\n"
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "from skimage import transform\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rescale\n",
    "import cv2\n",
    "import glob\n",
    "import random as ra\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "def process(X,Y,file,aug):\n",
    "    img=cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n",
    "    X.append(img)\n",
    "    #write your code\n",
    "    if \"virus\" in file:\n",
    "        Y.append(\"0\")\n",
    "    elif \"bacteria\" in file:\n",
    "        Y.append(\"1\")\n",
    "    else:\n",
    "        Y.append(\"2\")\n",
    "    if aug:\n",
    "        augmentation(X,Y)\n",
    "\n",
    "def normalize(dataset):\n",
    "    dataset=asarray(dataset).astype('float32')\n",
    "    dataset=dataset/255.0\n",
    "    return dataset\n",
    "    \n",
    "def create_dataset(directory):\n",
    "    #before work\n",
    "    files=glob.glob(directory+'/*.jpeg')\n",
    "    ra.shuffle(files)\n",
    "    X_train=[]\n",
    "    Y_train=[]\n",
    "    X_test=[]\n",
    "    Y_test=[]\n",
    "    for file in files[0:int(len(files)*0.8)]:\n",
    "        process(X_train,Y_train,file,True)\n",
    "    for file in files[int(len(files)*0.8):]:\n",
    "        process(X_test,Y_test,file,False)        \n",
    "    from numpy import asarray\n",
    "    X_train=normalize(X_train)\n",
    "    X_test=normalize(X_test)\n",
    "    return X_train,X_test,Y_train,Y_test\n",
    "\n",
    "def augmentation(dataset,labels):\n",
    "    last=len(labels)-1\n",
    "    scale_out = skimage.transform.rescale(dataset[last], scale=2.0, mode='constant')\n",
    "    scale_out=skimage.transform.resize(scale_out,(100,100))\n",
    "    scale_in = skimage.transform.rescale(dataset[last], scale=0.5, mode='constant')\n",
    "    scale_in=skimage.transform.resize(scale_in,(100,100))\n",
    "    dataset.append(scale_out)\n",
    "    labels.append(labels[last])\n",
    "    dataset.append(scale_in)\n",
    "    labels.append(labels[last])\n",
    "    \n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import utils\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "import math\n",
    "X_train,X_test,Y_train,Y_test=create_dataset('chest_xray_lower_dim2')\n",
    "X_train=X_train.reshape(-1,100,100,1)\n",
    "X_test=X_test.reshape(-1,100,100,1)\n",
    "Y_train= keras.utils.to_categorical(Y_train,3)\n",
    "Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "\n",
    "\"\"\"\n",
    "next time\n",
    "penalty 0.01\n",
    "penalty last 0.001\n",
    "reverse\n",
    "\"\"\"\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    #X_train,XX,Y_train,YY=train_test_split(\n",
    "    #dataset, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=100*100\n",
    "        w=math.sqrt(inputs)\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation='relu')(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=30\n",
    "            w=math.sqrt(inputs)\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation='softmax')(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4,mode='min')\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.33,epochs=epochs_num,batch_size=batch_len,verbose=1,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])\n",
    "    \n",
    "train(60,300,3,3)\n",
    "print(\"---------\")\n",
    "train(60,500,3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905adc21",
   "metadata": {},
   "source": [
    "#### Now let's try to increase the number of epochs to see if it is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c7409bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "63/63 [==============================] - 81s 1s/step - loss: 1.0603 - accuracy: 0.4751 - val_loss: 1.0683 - val_accuracy: 0.4560\n",
      "Epoch 2/200\n",
      "63/63 [==============================] - 78s 1s/step - loss: 1.0459 - accuracy: 0.4771 - val_loss: 1.0492 - val_accuracy: 0.4582\n",
      "Epoch 3/200\n",
      "63/63 [==============================] - 75s 1s/step - loss: 0.9608 - accuracy: 0.5345 - val_loss: 0.9075 - val_accuracy: 0.5354\n",
      "Epoch 4/200\n",
      "63/63 [==============================] - 81s 1s/step - loss: 0.7762 - accuracy: 0.6587 - val_loss: 0.6989 - val_accuracy: 0.6695\n",
      "Epoch 5/200\n",
      "63/63 [==============================] - 75s 1s/step - loss: 0.6599 - accuracy: 0.7053 - val_loss: 0.6632 - val_accuracy: 0.7031\n",
      "Epoch 6/200\n",
      "63/63 [==============================] - 75s 1s/step - loss: 0.6270 - accuracy: 0.7259 - val_loss: 0.6370 - val_accuracy: 0.7214\n",
      "Epoch 7/200\n",
      "63/63 [==============================] - 93s 1s/step - loss: 0.6047 - accuracy: 0.7404 - val_loss: 0.6187 - val_accuracy: 0.7296\n",
      "Epoch 8/200\n",
      "63/63 [==============================] - 78s 1s/step - loss: 0.5885 - accuracy: 0.7496 - val_loss: 0.5769 - val_accuracy: 0.7525\n",
      "Epoch 9/200\n",
      "63/63 [==============================] - 75s 1s/step - loss: 0.5597 - accuracy: 0.7660 - val_loss: 0.5720 - val_accuracy: 0.7658\n",
      "Epoch 10/200\n",
      "63/63 [==============================] - 74s 1s/step - loss: 0.5451 - accuracy: 0.7707 - val_loss: 0.5671 - val_accuracy: 0.7555\n",
      "Epoch 11/200\n",
      "63/63 [==============================] - 74s 1s/step - loss: 0.5357 - accuracy: 0.7724 - val_loss: 0.5609 - val_accuracy: 0.7643\n",
      "Epoch 12/200\n",
      "63/63 [==============================] - 75s 1s/step - loss: 0.5212 - accuracy: 0.7778 - val_loss: 0.5463 - val_accuracy: 0.7749\n",
      "Epoch 13/200\n",
      "63/63 [==============================] - 88s 1s/step - loss: 0.5181 - accuracy: 0.7746 - val_loss: 0.5363 - val_accuracy: 0.7760\n",
      "Epoch 14/200\n",
      "63/63 [==============================] - 83s 1s/step - loss: 0.5145 - accuracy: 0.7780 - val_loss: 0.5492 - val_accuracy: 0.7695\n",
      "Epoch 15/200\n",
      "63/63 [==============================] - 87s 1s/step - loss: 0.5081 - accuracy: 0.7819 - val_loss: 0.5341 - val_accuracy: 0.7835\n",
      "Epoch 16/200\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.4999 - accuracy: 0.7826 - val_loss: 0.5427 - val_accuracy: 0.7712\n",
      "Epoch 17/200\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.4906 - accuracy: 0.7861 - val_loss: 0.5315 - val_accuracy: 0.7865\n",
      "Epoch 18/200\n",
      "63/63 [==============================] - 86s 1s/step - loss: 0.4795 - accuracy: 0.7923 - val_loss: 0.5312 - val_accuracy: 0.7837\n",
      "Epoch 19/200\n",
      "63/63 [==============================] - 85s 1s/step - loss: 0.4735 - accuracy: 0.7916 - val_loss: 0.5770 - val_accuracy: 0.7706\n",
      "Epoch 20/200\n",
      "63/63 [==============================] - 88s 1s/step - loss: 0.4756 - accuracy: 0.7908 - val_loss: 0.5336 - val_accuracy: 0.7814\n",
      "Epoch 21/200\n",
      "63/63 [==============================] - 89s 1s/step - loss: 0.4677 - accuracy: 0.7928 - val_loss: 0.5364 - val_accuracy: 0.7848\n",
      "Epoch 22/200\n",
      "63/63 [==============================] - 88s 1s/step - loss: 0.4568 - accuracy: 0.8014 - val_loss: 0.5508 - val_accuracy: 0.7536\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 49, 49, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5455522537231445\n",
      "Test accuracy: 0.7465870380401611\n"
     ]
    }
   ],
   "source": [
    "train(200,150,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80db15d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 88s 3s/step - loss: 1.0678 - accuracy: 0.4708 - val_loss: 1.0673 - val_accuracy: 0.4560\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 76s 2s/step - loss: 1.0404 - accuracy: 0.4891 - val_loss: 1.0048 - val_accuracy: 0.5151\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 75s 2s/step - loss: 0.9638 - accuracy: 0.5364 - val_loss: 0.9418 - val_accuracy: 0.5295\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 76s 2s/step - loss: 0.9286 - accuracy: 0.5492 - val_loss: 0.9334 - val_accuracy: 0.5332\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 76s 2s/step - loss: 0.9121 - accuracy: 0.5541 - val_loss: 0.9266 - val_accuracy: 0.5388\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 75s 2s/step - loss: 0.9046 - accuracy: 0.5575 - val_loss: 0.9031 - val_accuracy: 0.5474\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 79s 2s/step - loss: 0.8762 - accuracy: 0.5665 - val_loss: 0.8592 - val_accuracy: 0.5578\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 76s 2s/step - loss: 0.7916 - accuracy: 0.6398 - val_loss: 0.6940 - val_accuracy: 0.6897\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 76s 2s/step - loss: 0.6560 - accuracy: 0.7106 - val_loss: 0.6130 - val_accuracy: 0.7464\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 77s 2s/step - loss: 0.5961 - accuracy: 0.7429 - val_loss: 0.6149 - val_accuracy: 0.7296\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 76s 2s/step - loss: 0.5770 - accuracy: 0.7532 - val_loss: 0.5911 - val_accuracy: 0.7436\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 76s 2s/step - loss: 0.5687 - accuracy: 0.7562 - val_loss: 0.6157 - val_accuracy: 0.7195\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 77s 2s/step - loss: 0.5603 - accuracy: 0.7609 - val_loss: 0.5725 - val_accuracy: 0.7684\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 87s 3s/step - loss: 0.5392 - accuracy: 0.7712 - val_loss: 0.5479 - val_accuracy: 0.7702\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 77s 2s/step - loss: 0.5347 - accuracy: 0.7749 - val_loss: 0.5381 - val_accuracy: 0.7693\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 76s 2s/step - loss: 0.5217 - accuracy: 0.7793 - val_loss: 0.5443 - val_accuracy: 0.7691\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 75s 2s/step - loss: 0.5139 - accuracy: 0.7825 - val_loss: 0.5295 - val_accuracy: 0.7790\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 76s 2s/step - loss: 0.5008 - accuracy: 0.7845 - val_loss: 0.5223 - val_accuracy: 0.7775\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 89s 3s/step - loss: 0.5010 - accuracy: 0.7828 - val_loss: 0.5217 - val_accuracy: 0.7807\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 79s 2s/step - loss: 0.4845 - accuracy: 0.7885 - val_loss: 0.5151 - val_accuracy: 0.7775\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 79s 2s/step - loss: 0.4869 - accuracy: 0.7857 - val_loss: 0.5220 - val_accuracy: 0.7816\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 77s 2s/step - loss: 0.4819 - accuracy: 0.7885 - val_loss: 0.5223 - val_accuracy: 0.7809\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 76s 2s/step - loss: 0.4689 - accuracy: 0.7938 - val_loss: 0.5279 - val_accuracy: 0.7850\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 82s 3s/step - loss: 0.4711 - accuracy: 0.7931 - val_loss: 0.5097 - val_accuracy: 0.7805\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 87s 3s/step - loss: 0.4638 - accuracy: 0.7935 - val_loss: 0.5116 - val_accuracy: 0.7768\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 79s 2s/step - loss: 0.4598 - accuracy: 0.7963 - val_loss: 0.5073 - val_accuracy: 0.7816\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 88s 3s/step - loss: 0.4494 - accuracy: 0.8008 - val_loss: 0.5123 - val_accuracy: 0.7878\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 87s 3s/step - loss: 0.4502 - accuracy: 0.8020 - val_loss: 0.5054 - val_accuracy: 0.7840\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 79s 2s/step - loss: 0.4473 - accuracy: 0.8008 - val_loss: 0.5121 - val_accuracy: 0.7812\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 80s 2s/step - loss: 0.4445 - accuracy: 0.8050 - val_loss: 0.5023 - val_accuracy: 0.7874\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 77s 2s/step - loss: 0.4305 - accuracy: 0.8107 - val_loss: 0.5133 - val_accuracy: 0.7814\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 90s 3s/step - loss: 0.4300 - accuracy: 0.8117 - val_loss: 0.5051 - val_accuracy: 0.7831\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 81s 3s/step - loss: 0.4248 - accuracy: 0.8137 - val_loss: 0.5105 - val_accuracy: 0.7831\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 79s 2s/step - loss: 0.4301 - accuracy: 0.8077 - val_loss: 0.5148 - val_accuracy: 0.7790\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 49, 49, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5050190687179565\n",
      "Test accuracy: 0.7687713503837585\n"
     ]
    }
   ],
   "source": [
    "train(100,300,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b9f8603",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "next time\n",
    "penalty 0.01\n",
    "penalty last 0.001\n",
    "reverse\n",
    "\"\"\"\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    #X_train,XX,Y_train,YY=train_test_split(\n",
    "    #dataset, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        wc=[100*100*98,49*49*40,23*23*40,10*10*40]\n",
    "        for i in range(conv_layers):\n",
    "            wc[i]=math.sqrt(wc[i])\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/wc[i],maxval=1/wc[i], seed=None))(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        wc[3]=math.sqrt(wc[3])\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/wc[3],maxval=1/wc[3], seed=None))(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=2560\n",
    "        w=math.sqrt(inputs)\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation='relu',kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w,maxval=1/w, seed=None))(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=30\n",
    "            w=math.sqrt(inputs)\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation='softmax')(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4,mode='min')\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.33,epochs=epochs_num,batch_size=batch_len,verbose=1,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "840c0e25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 78s 2s/step - loss: 1.0737 - accuracy: 0.4678 - val_loss: 1.0681 - val_accuracy: 0.4560\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 77s 2s/step - loss: 1.0542 - accuracy: 0.4771 - val_loss: 1.0676 - val_accuracy: 0.4560\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 76s 2s/step - loss: 1.0553 - accuracy: 0.4771 - val_loss: 1.0667 - val_accuracy: 0.4560\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 78s 2s/step - loss: 1.0541 - accuracy: 0.4771 - val_loss: 1.0667 - val_accuracy: 0.4560\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 76s 2s/step - loss: 1.0542 - accuracy: 0.4771 - val_loss: 1.0671 - val_accuracy: 0.4560\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 77s 2s/step - loss: 1.0547 - accuracy: 0.4771 - val_loss: 1.0666 - val_accuracy: 0.4560\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 76s 2s/step - loss: 1.0543 - accuracy: 0.4771 - val_loss: 1.0669 - val_accuracy: 0.4560\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 76s 2s/step - loss: 1.0540 - accuracy: 0.4771 - val_loss: 1.0706 - val_accuracy: 0.4560\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 76s 2s/step - loss: 1.0542 - accuracy: 0.4771 - val_loss: 1.0669 - val_accuracy: 0.4560\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 76s 2s/step - loss: 1.0547 - accuracy: 0.4771 - val_loss: 1.0685 - val_accuracy: 0.4560\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 49, 49, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 1.0462440252304077\n",
      "Test accuracy: 0.49317407608032227\n"
     ]
    }
   ],
   "source": [
    "train(100,300,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e2ccbb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 [==============================] - 71s 2s/step - loss: 1.0720 - accuracy: 0.4596 - val_loss: 1.0501 - val_accuracy: 0.4889\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 66s 2s/step - loss: 1.0317 - accuracy: 0.4906 - val_loss: 0.9439 - val_accuracy: 0.5512\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 68s 2s/step - loss: 0.9534 - accuracy: 0.5316 - val_loss: 0.9184 - val_accuracy: 0.5633\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 67s 2s/step - loss: 0.9261 - accuracy: 0.5414 - val_loss: 0.9269 - val_accuracy: 0.5542\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 67s 2s/step - loss: 0.9242 - accuracy: 0.5404 - val_loss: 0.9031 - val_accuracy: 0.5724\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 66s 2s/step - loss: 0.9122 - accuracy: 0.5485 - val_loss: 0.9068 - val_accuracy: 0.5643\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 66s 2s/step - loss: 0.9118 - accuracy: 0.5484 - val_loss: 0.9039 - val_accuracy: 0.5686\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 66s 2s/step - loss: 0.9029 - accuracy: 0.5561 - val_loss: 0.8934 - val_accuracy: 0.5786\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 66s 2s/step - loss: 0.8994 - accuracy: 0.5566 - val_loss: 0.9082 - val_accuracy: 0.5683\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 68s 2s/step - loss: 0.8956 - accuracy: 0.5598 - val_loss: 0.8789 - val_accuracy: 0.5844\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 76s 2s/step - loss: 0.8927 - accuracy: 0.5612 - val_loss: 0.8820 - val_accuracy: 0.5834\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 66s 2s/step - loss: 0.8884 - accuracy: 0.5632 - val_loss: 0.8858 - val_accuracy: 0.5828\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 66s 2s/step - loss: 0.8816 - accuracy: 0.5649 - val_loss: 0.8730 - val_accuracy: 0.5858\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 66s 2s/step - loss: 0.8831 - accuracy: 0.5662 - val_loss: 0.8923 - val_accuracy: 0.5798\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 65s 2s/step - loss: 0.8741 - accuracy: 0.5687 - val_loss: 0.8766 - val_accuracy: 0.5863\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 66s 2s/step - loss: 0.8765 - accuracy: 0.5676 - val_loss: 0.8683 - val_accuracy: 0.5885\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.8687 - accuracy: 0.5732 - val_loss: 0.8693 - val_accuracy: 0.5878\n",
      "Epoch 18/100\n",
      "36/36 [==============================] - 65s 2s/step - loss: 0.8639 - accuracy: 0.5743 - val_loss: 0.8630 - val_accuracy: 0.5908\n",
      "Epoch 19/100\n",
      "36/36 [==============================] - 65s 2s/step - loss: 0.8611 - accuracy: 0.5760 - val_loss: 0.8642 - val_accuracy: 0.5895\n",
      "Epoch 20/100\n",
      "36/36 [==============================] - 64s 2s/step - loss: 0.8600 - accuracy: 0.5777 - val_loss: 0.8649 - val_accuracy: 0.5895\n",
      "Epoch 21/100\n",
      "36/36 [==============================] - 807s 23s/step - loss: 0.8542 - accuracy: 0.5779 - val_loss: 0.8626 - val_accuracy: 0.5909\n",
      "Epoch 22/100\n",
      "36/36 [==============================] - 96s 3s/step - loss: 0.8526 - accuracy: 0.5814 - val_loss: 0.8613 - val_accuracy: 0.5905\n",
      "Epoch 23/100\n",
      "36/36 [==============================] - 69s 2s/step - loss: 0.8482 - accuracy: 0.5816 - val_loss: 0.8726 - val_accuracy: 0.5855\n",
      "Epoch 24/100\n",
      "36/36 [==============================] - 75s 2s/step - loss: 0.8499 - accuracy: 0.5783 - val_loss: 0.8711 - val_accuracy: 0.5861\n",
      "Epoch 25/100\n",
      "36/36 [==============================] - 74s 2s/step - loss: 0.8507 - accuracy: 0.5798 - val_loss: 0.8573 - val_accuracy: 0.5925\n",
      "Epoch 26/100\n",
      "36/36 [==============================] - 89s 2s/step - loss: 0.8419 - accuracy: 0.5813 - val_loss: 0.8729 - val_accuracy: 0.5882\n",
      "Epoch 27/100\n",
      "36/36 [==============================] - 75s 2s/step - loss: 0.8409 - accuracy: 0.5853 - val_loss: 0.9016 - val_accuracy: 0.5763\n",
      "Epoch 28/100\n",
      "36/36 [==============================] - 67s 2s/step - loss: 0.8467 - accuracy: 0.5826 - val_loss: 0.8766 - val_accuracy: 0.5823\n",
      "Epoch 29/100\n",
      "36/36 [==============================] - 78s 2s/step - loss: 0.8347 - accuracy: 0.5885 - val_loss: 0.8685 - val_accuracy: 0.5891\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_13 (InputLayer)       [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_51 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 49, 49, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_52 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_40 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_53 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_41 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_54 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_12 (Flatten)        (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5439460873603821\n",
      "Test accuracy: 0.7662116289138794\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'CategoricalTruePositives' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5480/3033858462.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    130\u001b[0m     ]\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_5480/3033858462.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epochs_num, batch_len, conv_layers, neur_layers)\u001b[0m\n\u001b[0;32m    127\u001b[0m     METRICS = [\n\u001b[0;32m    128\u001b[0m       \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCategoricalAccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 129\u001b[1;33m       \u001b[0mCategoricalTruePositives\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mNUM_CLASSES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    130\u001b[0m     ]\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CategoricalTruePositives' is not defined"
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "from skimage import transform\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rescale\n",
    "import cv2\n",
    "import glob\n",
    "import random as ra\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "def process(X,Y,file,aug):\n",
    "    img=cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n",
    "    X.append(img)\n",
    "    #write your code\n",
    "    if \"virus\" in file:\n",
    "        Y.append(\"0\")\n",
    "    elif \"bacteria\" in file:\n",
    "        Y.append(\"1\")\n",
    "    else:\n",
    "        Y.append(\"2\")\n",
    "    if aug:\n",
    "        augmentation(X,Y)\n",
    "\n",
    "def normalize(dataset):\n",
    "    dataset=asarray(dataset).astype('float32')\n",
    "    dataset=dataset/255.0\n",
    "    return dataset\n",
    "    \n",
    "def create_dataset(directory):\n",
    "    #before work\n",
    "    files=glob.glob(directory+'/*.jpeg')\n",
    "    ra.shuffle(files)\n",
    "    X_train=[]\n",
    "    Y_train=[]\n",
    "    X_test=[]\n",
    "    Y_test=[]\n",
    "    for file in files[0:int(len(files)*0.8)]:\n",
    "        process(X_train,Y_train,file,True)\n",
    "    for file in files[int(len(files)*0.8):]:\n",
    "        process(X_test,Y_test,file,False)        \n",
    "    from numpy import asarray\n",
    "    X_train=normalize(X_train)\n",
    "    X_test=normalize(X_test)\n",
    "    return X_train,X_test,Y_train,Y_test\n",
    "\n",
    "def augmentation(dataset,labels):\n",
    "    last=len(labels)-1\n",
    "    scale_out = skimage.transform.rescale(dataset[last], scale=2.0, mode='constant')\n",
    "    scale_out=skimage.transform.resize(scale_out,(100,100))\n",
    "    scale_in = skimage.transform.rescale(dataset[last], scale=0.5, mode='constant')\n",
    "    scale_in=skimage.transform.resize(scale_in,(100,100))\n",
    "    dataset.append(scale_out)\n",
    "    labels.append(labels[last])\n",
    "    dataset.append(scale_in)\n",
    "    labels.append(labels[last])\n",
    "    \n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import utils\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "import math\n",
    "X_train,X_test,Y_train,Y_test=create_dataset('chest_xray_lower_dim2')\n",
    "X_train=X_train.reshape(-1,100,100,1)\n",
    "X_test=X_test.reshape(-1,100,100,1)\n",
    "Y_train= keras.utils.to_categorical(Y_train,3)\n",
    "Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "\n",
    "\"\"\"\n",
    "next time\n",
    "penalty 0.01\n",
    "penalty last 0.001\n",
    "reverse\n",
    "\"\"\"\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    #X_train,XX,Y_train,YY=train_test_split(\n",
    "    #dataset, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=100*100\n",
    "        w=math.sqrt(inputs)\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation='relu')(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=30\n",
    "            w=math.sqrt(inputs)\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation='softmax')(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4,mode='min')\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.5,epochs=epochs_num,batch_size=batch_len,verbose=1,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])\n",
    "    \n",
    "train(100,200,3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584255bf",
   "metadata": {},
   "source": [
    "#### Now let's set monitor=loss to see overfitting with augmented data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5db6fc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 84s 2s/step - loss: 1.0697 - accuracy: 0.4638 - val_loss: 1.0473 - val_accuracy: 0.4864\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 1.0593 - accuracy: 0.4726 - val_loss: 1.0385 - val_accuracy: 0.4864\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 1.0004 - accuracy: 0.5062 - val_loss: 0.9291 - val_accuracy: 0.5522\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.9469 - accuracy: 0.5397 - val_loss: 0.9156 - val_accuracy: 0.5589\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.9333 - accuracy: 0.5456 - val_loss: 0.9143 - val_accuracy: 0.5643\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.9196 - accuracy: 0.5529 - val_loss: 0.8930 - val_accuracy: 0.5768\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.9053 - accuracy: 0.5614 - val_loss: 0.8820 - val_accuracy: 0.5821\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.8948 - accuracy: 0.5664 - val_loss: 0.8792 - val_accuracy: 0.5804\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.8888 - accuracy: 0.5698 - val_loss: 0.9324 - val_accuracy: 0.5502\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.8869 - accuracy: 0.5678 - val_loss: 0.8756 - val_accuracy: 0.5815\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.8827 - accuracy: 0.5693 - val_loss: 0.8726 - val_accuracy: 0.5819\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.8816 - accuracy: 0.5698 - val_loss: 0.8676 - val_accuracy: 0.5839\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.8781 - accuracy: 0.5727 - val_loss: 0.8695 - val_accuracy: 0.5843\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.8694 - accuracy: 0.5773 - val_loss: 0.8693 - val_accuracy: 0.5856\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.8725 - accuracy: 0.5771 - val_loss: 0.8739 - val_accuracy: 0.5856\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.8674 - accuracy: 0.5793 - val_loss: 0.8685 - val_accuracy: 0.5860\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.8640 - accuracy: 0.5802 - val_loss: 0.8678 - val_accuracy: 0.5824\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 87s 3s/step - loss: 0.8600 - accuracy: 0.5829 - val_loss: 0.8674 - val_accuracy: 0.5826\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 86s 3s/step - loss: 0.8623 - accuracy: 0.5803 - val_loss: 0.8704 - val_accuracy: 0.5850\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 82s 3s/step - loss: 0.8604 - accuracy: 0.5824 - val_loss: 0.8638 - val_accuracy: 0.5867\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 49, 49, 40)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 23, 23, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 10, 10, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2560)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5271691083908081\n",
      "Test accuracy: 0.7790102362632751\n"
     ]
    }
   ],
   "source": [
    "#next time patience=2 node='loss' validation_split=0.33\n",
    "import skimage\n",
    "from skimage import transform\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rescale\n",
    "import cv2\n",
    "import glob\n",
    "import random as ra\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "def process(X,Y,file,aug):\n",
    "    img=cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n",
    "    X.append(img)\n",
    "    #write your code\n",
    "    if \"virus\" in file:\n",
    "        Y.append(\"0\")\n",
    "    elif \"bacteria\" in file:\n",
    "        Y.append(\"1\")\n",
    "    else:\n",
    "        Y.append(\"2\")\n",
    "    if aug:\n",
    "        augmentation(X,Y)\n",
    "\n",
    "def normalize(dataset):\n",
    "    dataset=asarray(dataset).astype('float32')\n",
    "    dataset=dataset/255.0\n",
    "    return dataset\n",
    "    \n",
    "def create_dataset(directory):\n",
    "    #before work\n",
    "    files=glob.glob(directory+'/*.jpeg')\n",
    "    ra.shuffle(files)\n",
    "    X_train=[]\n",
    "    Y_train=[]\n",
    "    X_test=[]\n",
    "    Y_test=[]\n",
    "    for file in files[0:int(len(files)*0.8)]:\n",
    "        process(X_train,Y_train,file,True)\n",
    "    for file in files[int(len(files)*0.8):]:\n",
    "        process(X_test,Y_test,file,False)        \n",
    "    from numpy import asarray\n",
    "    X_train=normalize(X_train)\n",
    "    X_test=normalize(X_test)\n",
    "    return X_train,X_test,Y_train,Y_test\n",
    "\n",
    "def augmentation(dataset,labels):\n",
    "    last=len(labels)-1\n",
    "    scale_out = skimage.transform.rescale(dataset[last], scale=2.0, mode='constant')\n",
    "    scale_out=skimage.transform.resize(scale_out,(100,100))\n",
    "    scale_in = skimage.transform.rescale(dataset[last], scale=0.5, mode='constant')\n",
    "    scale_in=skimage.transform.resize(scale_in,(100,100))\n",
    "    dataset.append(scale_out)\n",
    "    labels.append(labels[last])\n",
    "    dataset.append(scale_in)\n",
    "    labels.append(labels[last])\n",
    "    \n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import utils\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "import math\n",
    "X_train,X_test,Y_train,Y_test=create_dataset('chest_xray_lower_dim2')\n",
    "X_train=X_train.reshape(-1,100,100,1)\n",
    "X_test=X_test.reshape(-1,100,100,1)\n",
    "Y_train= keras.utils.to_categorical(Y_train,3)\n",
    "Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "\n",
    "\"\"\"\n",
    "next time\n",
    "penalty 0.01\n",
    "penalty last 0.001\n",
    "reverse\n",
    "\"\"\"\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    #X_train,XX,Y_train,YY=train_test_split(\n",
    "    #dataset, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=100*100\n",
    "        w=math.sqrt(inputs)\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation='relu')(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=30\n",
    "            w=math.sqrt(inputs)\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation='softmax')(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2,mode='min')\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.33,epochs=epochs_num,batch_size=batch_len,verbose=1,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])\n",
    "    \n",
    "train(100,300,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af7e5ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "32/32 [==============================] - 97s 3s/step - loss: 1.0697 - accuracy: 0.4649 - val_loss: 1.0484 - val_accuracy: 0.4864\n",
      "Epoch 2/100\n",
      "32/32 [==============================] - 81s 3s/step - loss: 1.0511 - accuracy: 0.4726 - val_loss: 1.0175 - val_accuracy: 0.5004\n",
      "Epoch 3/100\n",
      "32/32 [==============================] - 94s 3s/step - loss: 0.9848 - accuracy: 0.5248 - val_loss: 0.9366 - val_accuracy: 0.5520\n",
      "Epoch 4/100\n",
      "32/32 [==============================] - 76s 2s/step - loss: 0.9514 - accuracy: 0.5346 - val_loss: 0.9151 - val_accuracy: 0.5584\n",
      "Epoch 5/100\n",
      "32/32 [==============================] - 75s 2s/step - loss: 0.9284 - accuracy: 0.5442 - val_loss: 0.9095 - val_accuracy: 0.5694\n",
      "Epoch 6/100\n",
      "32/32 [==============================] - 74s 2s/step - loss: 0.9169 - accuracy: 0.5519 - val_loss: 0.8900 - val_accuracy: 0.5757\n",
      "Epoch 7/100\n",
      "32/32 [==============================] - 76s 2s/step - loss: 0.9023 - accuracy: 0.5537 - val_loss: 0.8754 - val_accuracy: 0.5746\n",
      "Epoch 8/100\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.8768 - accuracy: 0.5637 - val_loss: 0.8344 - val_accuracy: 0.5722\n",
      "Epoch 9/100\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.7667 - accuracy: 0.6593 - val_loss: 0.6745 - val_accuracy: 0.7091\n",
      "Epoch 10/100\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.6711 - accuracy: 0.6976 - val_loss: 0.6016 - val_accuracy: 0.7331\n",
      "Epoch 11/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.6149 - accuracy: 0.7222 - val_loss: 0.6063 - val_accuracy: 0.7514\n",
      "Epoch 12/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.5961 - accuracy: 0.7428 - val_loss: 0.5705 - val_accuracy: 0.7568\n",
      "Epoch 13/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.5779 - accuracy: 0.7543 - val_loss: 0.5709 - val_accuracy: 0.7663\n",
      "Epoch 14/100\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.5620 - accuracy: 0.7641 - val_loss: 0.5490 - val_accuracy: 0.7727\n",
      "Epoch 15/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.5418 - accuracy: 0.7724 - val_loss: 0.5622 - val_accuracy: 0.7648\n",
      "Epoch 16/100\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.5372 - accuracy: 0.7738 - val_loss: 0.5365 - val_accuracy: 0.7732\n",
      "Epoch 17/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.5388 - accuracy: 0.7758 - val_loss: 0.5294 - val_accuracy: 0.7812\n",
      "Epoch 18/100\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.5223 - accuracy: 0.7792 - val_loss: 0.5241 - val_accuracy: 0.7878\n",
      "Epoch 19/100\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.5100 - accuracy: 0.7845 - val_loss: 0.5102 - val_accuracy: 0.7865\n",
      "Epoch 20/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.5105 - accuracy: 0.7776 - val_loss: 0.5342 - val_accuracy: 0.7792\n",
      "Epoch 21/100\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.5175 - accuracy: 0.7804 - val_loss: 0.5073 - val_accuracy: 0.7891\n",
      "Epoch 22/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.4978 - accuracy: 0.7906 - val_loss: 0.5256 - val_accuracy: 0.7799\n",
      "Epoch 23/100\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.4983 - accuracy: 0.7835 - val_loss: 0.5333 - val_accuracy: 0.7734\n",
      "Epoch 24/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.4822 - accuracy: 0.7912 - val_loss: 0.5005 - val_accuracy: 0.7898\n",
      "Epoch 25/100\n",
      "32/32 [==============================] - 75s 2s/step - loss: 0.4802 - accuracy: 0.7905 - val_loss: 0.4982 - val_accuracy: 0.7945\n",
      "Epoch 26/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.4647 - accuracy: 0.7994 - val_loss: 0.4956 - val_accuracy: 0.7909\n",
      "Epoch 27/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.4582 - accuracy: 0.8048 - val_loss: 0.4947 - val_accuracy: 0.7906\n",
      "Epoch 28/100\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.4557 - accuracy: 0.8015 - val_loss: 0.4968 - val_accuracy: 0.7870\n",
      "Epoch 29/100\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.4557 - accuracy: 0.8039 - val_loss: 0.5092 - val_accuracy: 0.7960\n",
      "Epoch 30/100\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.4463 - accuracy: 0.8074 - val_loss: 0.5030 - val_accuracy: 0.7824\n",
      "Epoch 31/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.4502 - accuracy: 0.8055 - val_loss: 0.5092 - val_accuracy: 0.7859\n",
      "Epoch 32/100\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.4391 - accuracy: 0.8091 - val_loss: 0.4866 - val_accuracy: 0.7982\n",
      "Epoch 33/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.4359 - accuracy: 0.8123 - val_loss: 0.5360 - val_accuracy: 0.7831\n",
      "Epoch 34/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.4309 - accuracy: 0.8167 - val_loss: 0.4998 - val_accuracy: 0.7941\n",
      "Epoch 35/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.4159 - accuracy: 0.8199 - val_loss: 0.4922 - val_accuracy: 0.7919\n",
      "Epoch 36/100\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.4147 - accuracy: 0.8176 - val_loss: 0.5042 - val_accuracy: 0.7883\n",
      "Epoch 37/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.4052 - accuracy: 0.8243 - val_loss: 0.4909 - val_accuracy: 0.7958\n",
      "Epoch 38/100\n",
      "32/32 [==============================] - 76s 2s/step - loss: 0.4074 - accuracy: 0.8236 - val_loss: 0.4913 - val_accuracy: 0.7975\n",
      "Epoch 39/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.4046 - accuracy: 0.8205 - val_loss: 0.4943 - val_accuracy: 0.7980\n",
      "Epoch 40/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.3885 - accuracy: 0.8344 - val_loss: 0.5306 - val_accuracy: 0.7809\n",
      "Epoch 41/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.3860 - accuracy: 0.8384 - val_loss: 0.5115 - val_accuracy: 0.7919\n",
      "Epoch 42/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.3816 - accuracy: 0.8374 - val_loss: 0.5220 - val_accuracy: 0.7945\n",
      "Epoch 43/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.3791 - accuracy: 0.8347 - val_loss: 0.5373 - val_accuracy: 0.7896\n",
      "Epoch 44/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.3688 - accuracy: 0.8435 - val_loss: 0.5136 - val_accuracy: 0.8008\n",
      "Epoch 45/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.3587 - accuracy: 0.8495 - val_loss: 0.5259 - val_accuracy: 0.7827\n",
      "Epoch 46/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.3677 - accuracy: 0.8435 - val_loss: 0.5308 - val_accuracy: 0.7870\n",
      "Epoch 47/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.3568 - accuracy: 0.8487 - val_loss: 0.5261 - val_accuracy: 0.7893\n",
      "Epoch 48/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.3466 - accuracy: 0.8534 - val_loss: 0.5216 - val_accuracy: 0.7853\n",
      "Epoch 49/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.3457 - accuracy: 0.8544 - val_loss: 0.5319 - val_accuracy: 0.7954\n",
      "Epoch 50/100\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.3348 - accuracy: 0.8602 - val_loss: 0.5344 - val_accuracy: 0.7883\n",
      "Epoch 51/100\n",
      "32/32 [==============================] - 75s 2s/step - loss: 0.3385 - accuracy: 0.8557 - val_loss: 0.5582 - val_accuracy: 0.7829\n",
      "Epoch 52/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.3285 - accuracy: 0.8580 - val_loss: 0.5512 - val_accuracy: 0.7909\n",
      "Epoch 53/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.3144 - accuracy: 0.8681 - val_loss: 0.5666 - val_accuracy: 0.7893\n",
      "Epoch 54/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.3087 - accuracy: 0.8732 - val_loss: 0.5711 - val_accuracy: 0.7753\n",
      "Epoch 55/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.3110 - accuracy: 0.8709 - val_loss: 0.5572 - val_accuracy: 0.7919\n",
      "Epoch 56/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.3036 - accuracy: 0.8735 - val_loss: 0.5592 - val_accuracy: 0.7878\n",
      "Epoch 57/100\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.2884 - accuracy: 0.8803 - val_loss: 0.5994 - val_accuracy: 0.7937\n",
      "Epoch 58/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.2988 - accuracy: 0.8756 - val_loss: 0.6052 - val_accuracy: 0.7551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.2834 - accuracy: 0.8851 - val_loss: 0.5862 - val_accuracy: 0.7820\n",
      "Epoch 60/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.2832 - accuracy: 0.8850 - val_loss: 0.6380 - val_accuracy: 0.7775\n",
      "Epoch 61/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.2729 - accuracy: 0.8864 - val_loss: 0.6086 - val_accuracy: 0.7682\n",
      "Epoch 62/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.2574 - accuracy: 0.8974 - val_loss: 0.6582 - val_accuracy: 0.7842\n",
      "Epoch 63/100\n",
      "32/32 [==============================] - 75s 2s/step - loss: 0.2660 - accuracy: 0.8915 - val_loss: 0.6383 - val_accuracy: 0.7691\n",
      "Epoch 64/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.2542 - accuracy: 0.8962 - val_loss: 0.6347 - val_accuracy: 0.7732\n",
      "Epoch 65/100\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.2504 - accuracy: 0.8978 - val_loss: 0.6404 - val_accuracy: 0.7868\n",
      "Epoch 66/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.2341 - accuracy: 0.9065 - val_loss: 0.6614 - val_accuracy: 0.7755\n",
      "Epoch 67/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.2243 - accuracy: 0.9110 - val_loss: 0.6634 - val_accuracy: 0.7829\n",
      "Epoch 68/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.2180 - accuracy: 0.9127 - val_loss: 0.7196 - val_accuracy: 0.7818\n",
      "Epoch 69/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.2135 - accuracy: 0.9160 - val_loss: 0.7465 - val_accuracy: 0.7693\n",
      "Epoch 70/100\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.2071 - accuracy: 0.9178 - val_loss: 0.8068 - val_accuracy: 0.7415\n",
      "Epoch 71/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.2279 - accuracy: 0.9080 - val_loss: 0.7299 - val_accuracy: 0.7730\n",
      "Epoch 72/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.2075 - accuracy: 0.9180 - val_loss: 0.7571 - val_accuracy: 0.7723\n",
      "Epoch 73/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.1981 - accuracy: 0.9234 - val_loss: 0.7643 - val_accuracy: 0.7633\n",
      "Epoch 74/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.1890 - accuracy: 0.9276 - val_loss: 0.8288 - val_accuracy: 0.7702\n",
      "Epoch 75/100\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.2050 - accuracy: 0.9208 - val_loss: 0.7904 - val_accuracy: 0.7568\n",
      "Epoch 76/100\n",
      "32/32 [==============================] - 74s 2s/step - loss: 0.1818 - accuracy: 0.9295 - val_loss: 0.8368 - val_accuracy: 0.7477\n",
      "Epoch 77/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.1916 - accuracy: 0.9237 - val_loss: 0.8208 - val_accuracy: 0.7715\n",
      "Epoch 78/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.1611 - accuracy: 0.9387 - val_loss: 0.8878 - val_accuracy: 0.7523\n",
      "Epoch 79/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.1730 - accuracy: 0.9333 - val_loss: 0.8783 - val_accuracy: 0.7637\n",
      "Epoch 80/100\n",
      "32/32 [==============================] - 90s 3s/step - loss: 0.1740 - accuracy: 0.9322 - val_loss: 0.8207 - val_accuracy: 0.7684\n",
      "Epoch 81/100\n",
      "32/32 [==============================] - 79s 2s/step - loss: 0.1471 - accuracy: 0.9447 - val_loss: 0.8908 - val_accuracy: 0.7600\n",
      "Epoch 82/100\n",
      "32/32 [==============================] - 87s 3s/step - loss: 0.1402 - accuracy: 0.9498 - val_loss: 0.9543 - val_accuracy: 0.7641\n",
      "Epoch 83/100\n",
      "32/32 [==============================] - 88s 3s/step - loss: 0.1381 - accuracy: 0.9476 - val_loss: 1.0000 - val_accuracy: 0.7577\n",
      "Epoch 84/100\n",
      "32/32 [==============================] - 86s 3s/step - loss: 0.1372 - accuracy: 0.9489 - val_loss: 0.9613 - val_accuracy: 0.7650\n",
      "Epoch 85/100\n",
      "32/32 [==============================] - 93s 3s/step - loss: 0.1314 - accuracy: 0.9534 - val_loss: 1.0218 - val_accuracy: 0.7529\n",
      "Epoch 86/100\n",
      "32/32 [==============================] - 79s 2s/step - loss: 0.1351 - accuracy: 0.9491 - val_loss: 0.9583 - val_accuracy: 0.7643\n",
      "Epoch 87/100\n",
      "32/32 [==============================] - 83s 3s/step - loss: 0.1202 - accuracy: 0.9570 - val_loss: 1.0044 - val_accuracy: 0.7639\n",
      "Epoch 88/100\n",
      "32/32 [==============================] - 77s 2s/step - loss: 0.1187 - accuracy: 0.9549 - val_loss: 1.0779 - val_accuracy: 0.7652\n",
      "Epoch 89/100\n",
      "32/32 [==============================] - 82s 3s/step - loss: 0.1054 - accuracy: 0.9648 - val_loss: 1.0827 - val_accuracy: 0.7706\n",
      "Epoch 90/100\n",
      "32/32 [==============================] - 75s 2s/step - loss: 0.1333 - accuracy: 0.9478 - val_loss: 1.0411 - val_accuracy: 0.7663\n",
      "Epoch 91/100\n",
      "32/32 [==============================] - 79s 2s/step - loss: 0.1383 - accuracy: 0.9472 - val_loss: 1.1185 - val_accuracy: 0.7551\n",
      "Epoch 92/100\n",
      "32/32 [==============================] - 77s 2s/step - loss: 0.1630 - accuracy: 0.9374 - val_loss: 1.0653 - val_accuracy: 0.7449\n",
      "Epoch 93/100\n",
      "32/32 [==============================] - 86s 3s/step - loss: 0.1347 - accuracy: 0.9484 - val_loss: 1.0459 - val_accuracy: 0.7538\n",
      "Epoch 94/100\n",
      "32/32 [==============================] - 74s 2s/step - loss: 0.1050 - accuracy: 0.9629 - val_loss: 1.0834 - val_accuracy: 0.7680\n",
      "Epoch 95/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.0923 - accuracy: 0.9673 - val_loss: 1.1104 - val_accuracy: 0.7598\n",
      "Epoch 96/100\n",
      "32/32 [==============================] - 83s 3s/step - loss: 0.0781 - accuracy: 0.9728 - val_loss: 1.1775 - val_accuracy: 0.7641\n",
      "Epoch 97/100\n",
      "32/32 [==============================] - 74s 2s/step - loss: 0.0787 - accuracy: 0.9737 - val_loss: 1.2875 - val_accuracy: 0.7592\n",
      "Epoch 98/100\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.0789 - accuracy: 0.9727 - val_loss: 1.2579 - val_accuracy: 0.7630\n",
      "Epoch 99/100\n",
      "32/32 [==============================] - 77s 2s/step - loss: 0.0695 - accuracy: 0.9763 - val_loss: 1.3509 - val_accuracy: 0.7637\n",
      "Epoch 100/100\n",
      "32/32 [==============================] - 76s 2s/step - loss: 0.0760 - accuracy: 0.9744 - val_loss: 1.3865 - val_accuracy: 0.7495\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 49, 49, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 23, 23, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 10, 10, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 1.8972465991973877\n",
      "Test accuracy: 0.7636518478393555\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    #X_train,XX,Y_train,YY=train_test_split(\n",
    "    #dataset, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=100*100\n",
    "        w=math.sqrt(inputs)\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation='relu')(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=30\n",
    "            w=math.sqrt(inputs)\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation='softmax')(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    #callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2,mode='min')\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.33,epochs=epochs_num,batch_size=batch_len,verbose=1)\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])\n",
    "    \n",
    "train(100,300,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "073de9d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "32/32 [==============================] - 79s 2s/step - loss: 1.0676 - accuracy: 0.4726 - val_loss: 1.0477 - val_accuracy: 0.4864\n",
      "Epoch 2/32\n",
      "32/32 [==============================] - 73s 2s/step - loss: 1.0441 - accuracy: 0.4817 - val_loss: 0.9863 - val_accuracy: 0.5509\n",
      "Epoch 3/32\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.9768 - accuracy: 0.5301 - val_loss: 0.9371 - val_accuracy: 0.5556\n",
      "Epoch 4/32\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.9411 - accuracy: 0.5425 - val_loss: 0.9367 - val_accuracy: 0.5554\n",
      "Epoch 5/32\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.9293 - accuracy: 0.5472 - val_loss: 0.9533 - val_accuracy: 0.5401\n",
      "Epoch 6/32\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.9228 - accuracy: 0.5477 - val_loss: 0.9181 - val_accuracy: 0.5543\n",
      "Epoch 7/32\n",
      "32/32 [==============================] - 76s 2s/step - loss: 0.9098 - accuracy: 0.5489 - val_loss: 0.8751 - val_accuracy: 0.5686\n",
      "Epoch 8/32\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.8298 - accuracy: 0.6147 - val_loss: 0.7064 - val_accuracy: 0.7113\n",
      "Epoch 9/32\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.6631 - accuracy: 0.7046 - val_loss: 0.5842 - val_accuracy: 0.7531\n",
      "Epoch 10/32\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.6010 - accuracy: 0.7431 - val_loss: 0.5809 - val_accuracy: 0.7546\n",
      "Epoch 11/32\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.5797 - accuracy: 0.7563 - val_loss: 0.5463 - val_accuracy: 0.7697\n",
      "Epoch 12/32\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.5509 - accuracy: 0.7711 - val_loss: 0.5375 - val_accuracy: 0.7710\n",
      "Epoch 13/32\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.5324 - accuracy: 0.7763 - val_loss: 0.5230 - val_accuracy: 0.7790\n",
      "Epoch 14/32\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.5291 - accuracy: 0.7732 - val_loss: 0.5493 - val_accuracy: 0.7665\n",
      "Epoch 15/32\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.5203 - accuracy: 0.7820 - val_loss: 0.5107 - val_accuracy: 0.7809\n",
      "Epoch 16/32\n",
      "32/32 [==============================] - 71s 2s/step - loss: 0.5027 - accuracy: 0.7849 - val_loss: 0.5030 - val_accuracy: 0.7805\n",
      "Epoch 17/32\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.4968 - accuracy: 0.7886 - val_loss: 0.5155 - val_accuracy: 0.7755\n",
      "Epoch 18/32\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.4889 - accuracy: 0.7913 - val_loss: 0.5091 - val_accuracy: 0.7824\n",
      "Epoch 19/32\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.4790 - accuracy: 0.7948 - val_loss: 0.5134 - val_accuracy: 0.7865\n",
      "Epoch 20/32\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.4723 - accuracy: 0.7998 - val_loss: 0.5061 - val_accuracy: 0.7818\n",
      "Epoch 21/32\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.4684 - accuracy: 0.8006 - val_loss: 0.5106 - val_accuracy: 0.7902\n",
      "Epoch 22/32\n",
      "32/32 [==============================] - 74s 2s/step - loss: 0.4557 - accuracy: 0.8048 - val_loss: 0.4907 - val_accuracy: 0.7926\n",
      "Epoch 23/32\n",
      "32/32 [==============================] - 75s 2s/step - loss: 0.4544 - accuracy: 0.8007 - val_loss: 0.5006 - val_accuracy: 0.7865\n",
      "Epoch 24/32\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.4485 - accuracy: 0.8079 - val_loss: 0.5222 - val_accuracy: 0.7859\n",
      "Epoch 25/32\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.4483 - accuracy: 0.8095 - val_loss: 0.4984 - val_accuracy: 0.7939\n",
      "Epoch 26/32\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.4329 - accuracy: 0.8165 - val_loss: 0.4898 - val_accuracy: 0.7885\n",
      "Epoch 27/32\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.4255 - accuracy: 0.8169 - val_loss: 0.4974 - val_accuracy: 0.7898\n",
      "Epoch 28/32\n",
      "32/32 [==============================] - 74s 2s/step - loss: 0.4224 - accuracy: 0.8195 - val_loss: 0.4983 - val_accuracy: 0.7937\n",
      "Epoch 29/32\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.4178 - accuracy: 0.8226 - val_loss: 0.4966 - val_accuracy: 0.7932\n",
      "Epoch 30/32\n",
      "32/32 [==============================] - 73s 2s/step - loss: 0.4071 - accuracy: 0.8243 - val_loss: 0.5118 - val_accuracy: 0.7874\n",
      "Epoch 31/32\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.4048 - accuracy: 0.8262 - val_loss: 0.5014 - val_accuracy: 0.7876\n",
      "Epoch 32/32\n",
      "32/32 [==============================] - 72s 2s/step - loss: 0.3919 - accuracy: 0.8308 - val_loss: 0.5124 - val_accuracy: 0.7771\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 49, 49, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 23, 23, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 10, 10, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.513864278793335\n",
      "Test accuracy: 0.7977815866470337\n"
     ]
    }
   ],
   "source": [
    "# epoch=32 steps_per_epoch=32\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    #X_train,XX,Y_train,YY=train_test_split(\n",
    "    #dataset, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=100*100\n",
    "        w=math.sqrt(inputs)\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation='relu')(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=30\n",
    "            w=math.sqrt(inputs)\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation='softmax')(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    #callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=2,mode='min')\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.33,steps_per_epoch=32,epochs=epochs_num,batch_size=batch_len,verbose=1)\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])\n",
    "    \n",
    "train(32,300,3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f30f28e",
   "metadata": {},
   "source": [
    "#### This time augmentation only on training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8abfd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage import transform\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rescale\n",
    "import cv2\n",
    "import glob\n",
    "import random as ra\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "def process(X,Y,file,aug):\n",
    "    img=cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n",
    "    X.append(img)\n",
    "    #write your code\n",
    "    if \"virus\" in file:\n",
    "        Y.append(\"0\")\n",
    "    elif \"bacteria\" in file:\n",
    "        Y.append(\"1\")\n",
    "    else:\n",
    "        Y.append(\"2\")\n",
    "    if aug:\n",
    "        augmentation(X,Y)\n",
    "\n",
    "def normalize(dataset):\n",
    "    dataset=asarray(dataset).astype('float32')\n",
    "    dataset=dataset/255.0\n",
    "    return dataset\n",
    "    \n",
    "def create_dataset(directory):\n",
    "    #before work\n",
    "    files=glob.glob(directory+'/*.jpeg')\n",
    "    ra.shuffle(files)\n",
    "    X_train=[]\n",
    "    Y_train=[]\n",
    "    X_valid=[]\n",
    "    Y_valid=[]\n",
    "    X_test=[]\n",
    "    Y_test=[]\n",
    "    for file in files[0:int(len(files)*0.64)]:\n",
    "        process(X_train,Y_train,file,True)\n",
    "    for file in files[int(len(files)*0.64):int(len(files)*0.8)]:\n",
    "        process(X_valid,Y_valid,file,False)    \n",
    "    for file in files[int(len(files)*0.8):]:\n",
    "        process(X_test,Y_test,file,False)        \n",
    "    from numpy import asarray\n",
    "    X_train=normalize(X_train)\n",
    "    X_valid=normalize(X_valid)\n",
    "    X_test=normalize(X_test)\n",
    "    return X_train,X_valid,X_test,Y_train,Y_valid,Y_test\n",
    "\n",
    "def augmentation(dataset,labels):\n",
    "    last=len(labels)-1\n",
    "    scale_out = skimage.transform.rescale(dataset[last], scale=2.0, mode='constant')\n",
    "    scale_out=skimage.transform.resize(scale_out,(200,200))\n",
    "    scale_in = skimage.transform.rescale(dataset[last], scale=0.5, mode='constant')\n",
    "    scale_in=skimage.transform.resize(scale_in,(200,200))\n",
    "    dataset.append(scale_out)\n",
    "    labels.append(labels[last])\n",
    "    dataset.append(scale_in)\n",
    "    labels.append(labels[last])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a43f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import utils\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "import math\n",
    "X_train,X_valid,X_test,Y_train,Y_valid,Y_test=create_dataset('chest_xray_lower_dim200x200')\n",
    "X_valid=X_valid.reshape(-1,200,200,1)\n",
    "X_test=X_test.reshape(-1,200,200,1)\n",
    "Y_train= keras.utils.to_categorical(Y_train,3)\n",
    "Y_valid=keras.utils.to_categorical(Y_valid,3)\n",
    "Y_test = keras.utils.to_categorical(Y_test,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc1e53ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "next time\n",
    "penalty 0.01\n",
    "penalty last 0.001\n",
    "reverse\n",
    "\"\"\"\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    #X_train,XX,Y_train,YY=train_test_split(\n",
    "    #dataset, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(200,200,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=100*100\n",
    "        w=math.sqrt(inputs)\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation='relu')(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=30\n",
    "            w=math.sqrt(inputs)\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation='softmax')(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4,mode='min',restore_best_weights=True)\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_data=(X_valid,Y_valid),epochs=epochs_num,batch_size=batch_len,verbose=2,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "184c8d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "75/75 - 458s - loss: 1.0602 - accuracy: 0.4761 - val_loss: 1.0552 - val_accuracy: 0.4781 - 458s/epoch - 6s/step\n",
      "Epoch 2/100\n",
      "75/75 - 462s - loss: 1.0550 - accuracy: 0.4761 - val_loss: 1.0379 - val_accuracy: 0.4781 - 462s/epoch - 6s/step\n",
      "Epoch 3/100\n",
      "75/75 - 463s - loss: 0.9765 - accuracy: 0.5285 - val_loss: 0.6552 - val_accuracy: 0.6916 - 463s/epoch - 6s/step\n",
      "Epoch 4/100\n",
      "75/75 - 466s - loss: 0.9149 - accuracy: 0.5547 - val_loss: 0.5878 - val_accuracy: 0.7407 - 466s/epoch - 6s/step\n",
      "Epoch 5/100\n",
      "75/75 - 682s - loss: 0.8986 - accuracy: 0.5629 - val_loss: 0.5579 - val_accuracy: 0.7609 - 682s/epoch - 9s/step\n",
      "Epoch 6/100\n",
      "75/75 - 738s - loss: 0.8901 - accuracy: 0.5687 - val_loss: 0.5555 - val_accuracy: 0.7748 - 738s/epoch - 10s/step\n",
      "Epoch 7/100\n",
      "75/75 - 785s - loss: 0.8889 - accuracy: 0.5673 - val_loss: 0.5370 - val_accuracy: 0.7780 - 785s/epoch - 10s/step\n",
      "Epoch 8/100\n",
      "75/75 - 908s - loss: 0.8801 - accuracy: 0.5734 - val_loss: 0.5293 - val_accuracy: 0.7866 - 908s/epoch - 12s/step\n",
      "Epoch 9/100\n",
      "75/75 - 459s - loss: 0.8733 - accuracy: 0.5771 - val_loss: 0.5585 - val_accuracy: 0.7577 - 459s/epoch - 6s/step\n",
      "Epoch 10/100\n",
      "75/75 - 456s - loss: 0.8754 - accuracy: 0.5755 - val_loss: 0.5263 - val_accuracy: 0.7652 - 456s/epoch - 6s/step\n",
      "Epoch 11/100\n",
      "75/75 - 459s - loss: 0.8709 - accuracy: 0.5753 - val_loss: 0.5165 - val_accuracy: 0.7705 - 459s/epoch - 6s/step\n",
      "Epoch 12/100\n",
      "75/75 - 431s - loss: 0.8642 - accuracy: 0.5776 - val_loss: 0.5116 - val_accuracy: 0.7834 - 431s/epoch - 6s/step\n",
      "Epoch 13/100\n",
      "75/75 - 488s - loss: 0.8642 - accuracy: 0.5829 - val_loss: 0.5065 - val_accuracy: 0.7887 - 488s/epoch - 7s/step\n",
      "Epoch 14/100\n",
      "75/75 - 436s - loss: 0.8566 - accuracy: 0.5844 - val_loss: 0.5025 - val_accuracy: 0.7940 - 436s/epoch - 6s/step\n",
      "Epoch 15/100\n",
      "75/75 - 478s - loss: 0.8392 - accuracy: 0.5978 - val_loss: 0.5522 - val_accuracy: 0.7908 - 478s/epoch - 6s/step\n",
      "Epoch 16/100\n",
      "75/75 - 585s - loss: 0.6080 - accuracy: 0.7259 - val_loss: 0.5046 - val_accuracy: 0.7855 - 585s/epoch - 8s/step\n",
      "Epoch 17/100\n",
      "75/75 - 712s - loss: 0.5176 - accuracy: 0.7694 - val_loss: 0.5004 - val_accuracy: 0.8015 - 712s/epoch - 9s/step\n",
      "Epoch 18/100\n",
      "75/75 - 486s - loss: 0.4892 - accuracy: 0.7831 - val_loss: 0.4902 - val_accuracy: 0.7940 - 486s/epoch - 6s/step\n",
      "Epoch 19/100\n",
      "75/75 - 478s - loss: 0.4639 - accuracy: 0.8000 - val_loss: 0.4963 - val_accuracy: 0.8004 - 478s/epoch - 6s/step\n",
      "Epoch 20/100\n",
      "75/75 - 439s - loss: 0.4501 - accuracy: 0.8030 - val_loss: 0.4858 - val_accuracy: 0.7972 - 439s/epoch - 6s/step\n",
      "Epoch 21/100\n",
      "75/75 - 458s - loss: 0.4320 - accuracy: 0.8102 - val_loss: 0.5173 - val_accuracy: 0.7780 - 458s/epoch - 6s/step\n",
      "Epoch 22/100\n",
      "75/75 - 459s - loss: 0.4298 - accuracy: 0.8169 - val_loss: 0.4744 - val_accuracy: 0.7930 - 459s/epoch - 6s/step\n",
      "Epoch 23/100\n",
      "75/75 - 457s - loss: 0.4189 - accuracy: 0.8198 - val_loss: 0.5028 - val_accuracy: 0.7876 - 457s/epoch - 6s/step\n",
      "Epoch 24/100\n",
      "75/75 - 442s - loss: 0.4116 - accuracy: 0.8203 - val_loss: 0.4921 - val_accuracy: 0.7930 - 442s/epoch - 6s/step\n",
      "Epoch 25/100\n",
      "75/75 - 461s - loss: 0.3965 - accuracy: 0.8294 - val_loss: 0.5500 - val_accuracy: 0.7844 - 461s/epoch - 6s/step\n",
      "Epoch 26/100\n",
      "75/75 - 504s - loss: 0.3876 - accuracy: 0.8296 - val_loss: 0.5426 - val_accuracy: 0.8004 - 504s/epoch - 7s/step\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 200, 200, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 198, 198, 40)      400       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 99, 99, 40)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 97, 97, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 48, 48, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 46, 46, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 23, 23, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 10, 10, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2560)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136,943\n",
      "Trainable params: 136,943\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5203198790550232\n",
      "Test accuracy: 0.7841296792030334\n"
     ]
    }
   ],
   "source": [
    "train(100,150,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5f5b11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
