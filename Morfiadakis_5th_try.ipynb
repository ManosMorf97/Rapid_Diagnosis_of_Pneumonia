{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b5d42cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage import transform\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rescale\n",
    "import cv2\n",
    "import glob\n",
    "import random as ra\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "def process(X,file):\n",
    "    img=cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n",
    "    X.append(img)\n",
    "    #write your code\n",
    "\n",
    "def normalize(dataset):\n",
    "    dataset=asarray(dataset).astype('float32')\n",
    "    dataset=dataset/255.0\n",
    "    return dataset\n",
    "\n",
    "def augmentation(row,label,Augmented,Y_Augmeneted):\n",
    "    scale_out = skimage.transform.rescale(row, scale=2.0, mode='constant')\n",
    "    scale_out=skimage.transform.resize(scale_out,(100,100))\n",
    "    scale_out2 = skimage.transform.rescale(row, scale=1.5, mode='constant')\n",
    "    scale_out2=skimage.transform.resize(scale_out2,(100,100))\n",
    "    scale_in= skimage.transform.rescale(row, scale=0.5, mode='constant')\n",
    "    scale_in=skimage.transform.resize(scale_in,(100,100))\n",
    "    scale_in2= skimage.transform.rescale(row, scale=0.8, mode='constant')\n",
    "    scale_in2=skimage.transform.resize(scale_in2,(100,100))\n",
    "    rot = skimage.transform.rotate(row, angle=20, mode='reflect')\n",
    "    rot=skimage.transform.resize(rot,(100,100))\n",
    "    images=[row,scale_out,scale_in,scale_out2,scale_in2,rot]\n",
    "    for image in images:\n",
    "        Augmented.append(image)\n",
    "        Y_Augmented.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48969e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1493, 2780, 1583]\n",
      "3747\n",
      "22482\n"
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "from skimage import transform\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rescale\n",
    "import cv2\n",
    "import glob\n",
    "import random as ra\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import utils\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "import math\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "Normal=[]\n",
    "Bacterial=[]\n",
    "Virus=[]\n",
    "classes=[Virus,Bacterial,Normal]\n",
    "Y_Normal=[]\n",
    "Y_Bacterial=[]\n",
    "Y_Virus=[]\n",
    "Y=[Y_Normal,Y_Bacterial,Y_Virus]\n",
    "files=glob.glob('chest_xray_lower_dim2'+'/*.jpeg')\n",
    "ra.shuffle(files)\n",
    "for file in files:\n",
    "    k=-1\n",
    "    if \"virus\" in file:\n",
    "        k=0\n",
    "    elif \"bacteria\" in file:\n",
    "        k=1\n",
    "    else:\n",
    "        k=2\n",
    "    Y[k].append(str(k))\n",
    "    process(classes[k],file)\n",
    "    \n",
    "len_classes=[]\n",
    "for class_ in classes:\n",
    "    len_classes.append(len(class_))\n",
    "print(len_classes)\n",
    "same_length=min(len_classes)\n",
    "evenly=False\n",
    "\n",
    "if evenly:\n",
    "    for i in range(3):\n",
    "        len_classes[i]=same_length\n",
    "\n",
    "for i in range(3):\n",
    "    classes[i]=classes[i][0:len_classes[i]]\n",
    "for i in range(3):\n",
    "    Y[i]=Y[i][0:len_classes[i]]\n",
    "\n",
    "Train=[]\n",
    "Valid=[]\n",
    "Test=[]\n",
    "TVT=[Train,Valid,Test]\n",
    "Y_Train=[]\n",
    "Y_Valid=[]\n",
    "Y_Test=[]\n",
    "Y_TVT=[Y_Train,Y_Valid,Y_Test]\n",
    "\n",
    "bounds=[0,0.64,0.8,1]\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        TVT[i]+=classes[j][int(bounds[i]*len_classes[j]):int(bounds[i+1]*len_classes[j])]\n",
    "        Y_TVT[i]+=Y[j][int(bounds[i]*len_classes[j]):int(bounds[i+1]*len_classes[j])]\n",
    "        \n",
    "Augmented=[]\n",
    "Y_Augmented=[]\n",
    "\n",
    "for i in range(len(Train)):\n",
    "    augmentation(Train[i],Y_Train[i],Augmented,Y_Augmented)\n",
    "\n",
    "print(len(Train))\n",
    "\n",
    "TVT[0]=Augmented\n",
    "Y_TVT[0]=Y_Augmented\n",
    "\n",
    "for i in range(3):\n",
    "    TVT[i]=normalize(TVT[i])\n",
    "    TVT[i]=TVT[i].reshape(-1,100,100,1)\n",
    "    Y_TVT[i]=keras.utils.to_categorical(Y_TVT[i],3)\n",
    "\n",
    "print(len(Augmented))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "528def0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "75/75 [==============================] - 172s 2s/step - loss: 1.0598 - accuracy: 0.4748 - val_loss: 1.0237 - val_accuracy: 0.4749\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 164s 2s/step - loss: 1.0141 - accuracy: 0.4995 - val_loss: 0.7763 - val_accuracy: 0.6521\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 162s 2s/step - loss: 0.9019 - accuracy: 0.5679 - val_loss: 0.7592 - val_accuracy: 0.7065\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 170s 2s/step - loss: 0.6663 - accuracy: 0.6959 - val_loss: 0.6614 - val_accuracy: 0.7054\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 159s 2s/step - loss: 0.6339 - accuracy: 0.7174 - val_loss: 0.6475 - val_accuracy: 0.7065\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 211s 3s/step - loss: 0.6216 - accuracy: 0.7228 - val_loss: 0.6272 - val_accuracy: 0.7225\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 202s 3s/step - loss: 0.5921 - accuracy: 0.7427 - val_loss: 0.6149 - val_accuracy: 0.7236\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 196s 3s/step - loss: 0.5675 - accuracy: 0.7550 - val_loss: 0.5962 - val_accuracy: 0.7460\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 197s 3s/step - loss: 0.5650 - accuracy: 0.7556 - val_loss: 0.6077 - val_accuracy: 0.7054\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 198s 3s/step - loss: 0.5421 - accuracy: 0.7694 - val_loss: 0.5798 - val_accuracy: 0.7556\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 192s 3s/step - loss: 0.5361 - accuracy: 0.7706 - val_loss: 0.5986 - val_accuracy: 0.7321\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 191s 3s/step - loss: 0.5248 - accuracy: 0.7785 - val_loss: 0.5532 - val_accuracy: 0.7727\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 195s 3s/step - loss: 0.5181 - accuracy: 0.7804 - val_loss: 0.5666 - val_accuracy: 0.7652\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 192s 3s/step - loss: 0.5041 - accuracy: 0.7853 - val_loss: 0.5523 - val_accuracy: 0.7780\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 195s 3s/step - loss: 0.4926 - accuracy: 0.7923 - val_loss: 0.5512 - val_accuracy: 0.7641\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 192s 3s/step - loss: 0.4888 - accuracy: 0.7947 - val_loss: 0.5129 - val_accuracy: 0.7876\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 190s 3s/step - loss: 0.4729 - accuracy: 0.7988 - val_loss: 0.5346 - val_accuracy: 0.7663\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 194s 3s/step - loss: 0.4622 - accuracy: 0.8062 - val_loss: 0.5324 - val_accuracy: 0.7663\n",
      "Epoch 19/100\n",
      "75/75 [==============================] - 189s 3s/step - loss: 0.4570 - accuracy: 0.8099 - val_loss: 0.5346 - val_accuracy: 0.7759\n",
      "Epoch 20/100\n",
      "75/75 [==============================] - 184s 2s/step - loss: 0.4456 - accuracy: 0.8157 - val_loss: 0.5312 - val_accuracy: 0.7759\n",
      "Epoch 21/100\n",
      "75/75 [==============================] - 186s 2s/step - loss: 0.4456 - accuracy: 0.8147 - val_loss: 0.5102 - val_accuracy: 0.7823\n",
      "Epoch 22/100\n",
      "75/75 [==============================] - 192s 3s/step - loss: 0.4354 - accuracy: 0.8184 - val_loss: 0.5520 - val_accuracy: 0.7556\n",
      "Epoch 23/100\n",
      "75/75 [==============================] - 195s 3s/step - loss: 0.4286 - accuracy: 0.8215 - val_loss: 0.5554 - val_accuracy: 0.7684\n",
      "Epoch 24/100\n",
      "75/75 [==============================] - 183s 2s/step - loss: 0.4208 - accuracy: 0.8239 - val_loss: 0.5246 - val_accuracy: 0.7812\n",
      "Epoch 25/100\n",
      "75/75 [==============================] - 184s 2s/step - loss: 0.4068 - accuracy: 0.8293 - val_loss: 0.5483 - val_accuracy: 0.7620\n",
      "Epoch 26/100\n",
      "75/75 [==============================] - 198s 3s/step - loss: 0.4020 - accuracy: 0.8339 - val_loss: 0.5247 - val_accuracy: 0.7727\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 49, 49, 40)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 23, 23, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 10, 10, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2560)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12188/1026120524.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12188/1026120524.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(epochs_num, batch_len, conv_layers, neur_layers)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;31m#model.load_weights(\"weights.hdf5\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m     \u001b[0mscore\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test loss:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Test accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "# epoch=32 steps_per_epoch=32\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=100*100\n",
    "        w=math.sqrt(inputs)\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation='relu')(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=30\n",
    "            w=math.sqrt(inputs)\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation='softmax')(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5,mode='min')\n",
    "    model=mlp_model()\n",
    "    model.fit(TVT[0],Y_TVT[0],validation_data=(TVT[1],Y_TVT[1]),epochs=epochs_num,batch_size=batch_len,callbacks=[callback],verbose=1)\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])\n",
    "    \n",
    "train(100,300,3,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0abbab0",
   "metadata": {},
   "source": [
    "#### Let's add alpha 0.0001  3 augmentations and batch 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28d22aec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1493, 2780, 1583]\n",
      "3747\n",
      "14988\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 150s 1s/step - loss: 1.0683 - accuracy: 0.4714 - val_loss: 1.0502 - val_accuracy: 0.4749\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 121s 1s/step - loss: 1.0146 - accuracy: 0.5052 - val_loss: 0.7321 - val_accuracy: 0.6862\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 119s 1s/step - loss: 0.9378 - accuracy: 0.5441 - val_loss: 0.6482 - val_accuracy: 0.6969\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 123s 1s/step - loss: 0.7038 - accuracy: 0.6856 - val_loss: 0.6277 - val_accuracy: 0.7086\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 129s 1s/step - loss: 0.6521 - accuracy: 0.7091 - val_loss: 0.5843 - val_accuracy: 0.7321\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 119s 1s/step - loss: 0.6241 - accuracy: 0.7269 - val_loss: 0.5614 - val_accuracy: 0.7556\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 119s 1s/step - loss: 0.5971 - accuracy: 0.7489 - val_loss: 0.5410 - val_accuracy: 0.7567\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.5798 - accuracy: 0.7559 - val_loss: 0.5680 - val_accuracy: 0.7641\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 128s 1s/step - loss: 0.5657 - accuracy: 0.7645 - val_loss: 0.5172 - val_accuracy: 0.7748\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 125s 1s/step - loss: 0.5585 - accuracy: 0.7663 - val_loss: 0.5085 - val_accuracy: 0.7812\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 124s 1s/step - loss: 0.5503 - accuracy: 0.7685 - val_loss: 0.5436 - val_accuracy: 0.7705\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 129s 1s/step - loss: 0.5341 - accuracy: 0.7758 - val_loss: 0.5271 - val_accuracy: 0.7716\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.5287 - accuracy: 0.7780 - val_loss: 0.4826 - val_accuracy: 0.7919\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 127s 1s/step - loss: 0.5168 - accuracy: 0.7846 - val_loss: 0.4722 - val_accuracy: 0.7972\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 122s 1s/step - loss: 0.5127 - accuracy: 0.7850 - val_loss: 0.5007 - val_accuracy: 0.7866\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 125s 1s/step - loss: 0.5004 - accuracy: 0.7903 - val_loss: 0.4850 - val_accuracy: 0.7919\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 124s 1s/step - loss: 0.5009 - accuracy: 0.7906 - val_loss: 0.4908 - val_accuracy: 0.7972\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 122s 1s/step - loss: 0.4847 - accuracy: 0.7971 - val_loss: 0.5132 - val_accuracy: 0.7801\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 49, 49, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 23, 23, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 10, 10, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5084810256958008\n",
      "Test accuracy: 0.7790102362632751\n"
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "from skimage import transform\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rescale\n",
    "import cv2\n",
    "import glob\n",
    "import random as ra\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "def process(X,file):\n",
    "    img=cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n",
    "    X.append(img)\n",
    "    #write your code\n",
    "\n",
    "def normalize(dataset):\n",
    "    dataset=asarray(dataset).astype('float32')\n",
    "    dataset=dataset/255.0\n",
    "    return dataset\n",
    "\n",
    "def augmentation(row,label,Augmented,Y_Augmeneted):\n",
    "    scale_out = skimage.transform.rescale(row, scale=2.0, mode='constant')\n",
    "    scale_out=skimage.transform.resize(scale_out,(100,100))\n",
    "    scale_in= skimage.transform.rescale(row, scale=0.5, mode='constant')\n",
    "    scale_in=skimage.transform.resize(scale_in,(100,100))\n",
    "    rot = skimage.transform.rotate(row, angle=20, mode='reflect')\n",
    "    rot=skimage.transform.resize(rot,(100,100))\n",
    "    images=[row,scale_out,scale_in,rot]\n",
    "    for image in images:\n",
    "        Augmented.append(image)\n",
    "        Y_Augmented.append(label)\n",
    "\n",
    "\n",
    "\n",
    "import skimage\n",
    "from skimage import transform\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rescale\n",
    "import cv2\n",
    "import glob\n",
    "import random as ra\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import utils\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "import math\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "Normal=[]\n",
    "Bacterial=[]\n",
    "Virus=[]\n",
    "classes=[Virus,Bacterial,Normal]\n",
    "Y_Normal=[]\n",
    "Y_Bacterial=[]\n",
    "Y_Virus=[]\n",
    "Y=[Y_Normal,Y_Bacterial,Y_Virus]\n",
    "files=glob.glob('chest_xray_lower_dim2'+'/*.jpeg')\n",
    "ra.shuffle(files)\n",
    "for file in files:\n",
    "    k=-1\n",
    "    if \"virus\" in file:\n",
    "        k=0\n",
    "    elif \"bacteria\" in file:\n",
    "        k=1\n",
    "    else:\n",
    "        k=2\n",
    "    Y[k].append(str(k))\n",
    "    process(classes[k],file)\n",
    "    \n",
    "len_classes=[]\n",
    "for class_ in classes:\n",
    "    len_classes.append(len(class_))\n",
    "print(len_classes)\n",
    "same_length=min(len_classes)\n",
    "evenly=False\n",
    "\n",
    "if evenly:\n",
    "    for i in range(3):\n",
    "        len_classes[i]=same_length\n",
    "\n",
    "for i in range(3):\n",
    "    classes[i]=classes[i][0:len_classes[i]]\n",
    "for i in range(3):\n",
    "    Y[i]=Y[i][0:len_classes[i]]\n",
    "\n",
    "Train=[]\n",
    "Valid=[]\n",
    "Test=[]\n",
    "TVT=[Train,Valid,Test]\n",
    "Y_Train=[]\n",
    "Y_Valid=[]\n",
    "Y_Test=[]\n",
    "Y_TVT=[Y_Train,Y_Valid,Y_Test]\n",
    "\n",
    "bounds=[0,0.64,0.8,1]\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        TVT[i]+=classes[j][int(bounds[i]*len_classes[j]):int(bounds[i+1]*len_classes[j])]\n",
    "        Y_TVT[i]+=Y[j][int(bounds[i]*len_classes[j]):int(bounds[i+1]*len_classes[j])]\n",
    "        \n",
    "Augmented=[]\n",
    "Y_Augmented=[]\n",
    "\n",
    "for i in range(len(Train)):\n",
    "    augmentation(Train[i],Y_Train[i],Augmented,Y_Augmented)\n",
    "\n",
    "print(len(Train))\n",
    "\n",
    "TVT[0]=Augmented\n",
    "Y_TVT[0]=Y_Augmented\n",
    "\n",
    "for i in range(3):\n",
    "    TVT[i]=normalize(TVT[i])\n",
    "    TVT[i]=TVT[i].reshape(-1,100,100,1)\n",
    "    Y_TVT[i]=keras.utils.to_categorical(Y_TVT[i],3)\n",
    "\n",
    "print(len(Augmented))\n",
    "\n",
    "# epoch=32 steps_per_epoch=32\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=100*100\n",
    "        w=math.sqrt(inputs)\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation='relu',kernel_regularizer=regularizers.L2(0.0001))(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=30\n",
    "            w=math.sqrt(inputs)\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation='softmax',kernel_regularizer=regularizers.L2(0.0001))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4,mode='max')\n",
    "    model=mlp_model()\n",
    "    model.fit(TVT[0],Y_TVT[0],validation_data=(TVT[1],Y_TVT[1]),epochs=epochs_num,batch_size=batch_len,callbacks=[callback],verbose=1)\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(TVT[2], Y_TVT[2],verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])\n",
    "    \n",
    "train(100,150,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3ecba5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
