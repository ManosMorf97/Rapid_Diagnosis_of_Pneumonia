{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e64f138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in d:\\anaconda\\lib\\site-packages (22.1)\n",
      "Collecting pip\n",
      "  Using cached pip-22.1.2-py3-none-any.whl (2.1 MB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: To modify pip, please run the following command:\n",
      "D:\\Anaconda\\python.exe -m pip install --upgrade pip\n",
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c02ac881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in d:\\anaconda\\lib\\site-packages (2.8.0)\n",
      "Requirement already satisfied: numpy>=1.20 in d:\\anaconda\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\anaconda\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in d:\\anaconda\\lib\\site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\anaconda\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in d:\\anaconda\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\anaconda\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in d:\\anaconda\\lib\\site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\anaconda\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in d:\\anaconda\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\anaconda\\lib\\site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\anaconda\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\anaconda\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in d:\\anaconda\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in d:\\anaconda\\lib\\site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in d:\\anaconda\\lib\\site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\anaconda\\lib\\site-packages (from tensorflow) (0.25.0)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in d:\\anaconda\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\anaconda\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: gast>=0.2.1 in d:\\anaconda\\lib\\site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in d:\\anaconda\\lib\\site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.27.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.7.2)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\anaconda\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\anaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\anaconda\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: opencv-python in d:\\anaconda\\lib\\site-packages (4.5.5.64)\n",
      "Requirement already satisfied: numpy>=1.17.3 in d:\\anaconda\\lib\\site-packages (from opencv-python) (1.21.5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in d:\\anaconda\\lib\\site-packages (9.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-image in d:\\anaconda\\lib\\site-packages (0.19.2)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in d:\\anaconda\\lib\\site-packages (from scikit-image) (2021.7.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in d:\\anaconda\\lib\\site-packages (from scikit-image) (1.21.5)\n",
      "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in d:\\anaconda\\lib\\site-packages (from scikit-image) (9.0.1)\n",
      "Requirement already satisfied: scipy>=1.4.1 in d:\\anaconda\\lib\\site-packages (from scikit-image) (1.8.0)\n",
      "Requirement already satisfied: networkx>=2.2 in d:\\anaconda\\lib\\site-packages (from scikit-image) (2.8)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in d:\\anaconda\\lib\\site-packages (from scikit-image) (1.3.0)\n",
      "Requirement already satisfied: imageio>=2.4.1 in d:\\anaconda\\lib\\site-packages (from scikit-image) (2.9.0)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\anaconda\\lib\\site-packages (from scikit-image) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in d:\\anaconda\\lib\\site-packages (from packaging>=20.0->scikit-image) (3.0.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install opencv-python    \n",
    "!pip install pillow\n",
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "898f82ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1493, 2780, 1583]\n",
      "3747\n",
      "14988\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 126s 1s/step - loss: 1.0394 - accuracy: 0.4949 - val_loss: 0.7074 - val_accuracy: 0.6841\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 119s 1s/step - loss: 0.9541 - accuracy: 0.5370 - val_loss: 0.6437 - val_accuracy: 0.7108\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 119s 1s/step - loss: 0.8794 - accuracy: 0.5850 - val_loss: 0.5700 - val_accuracy: 0.7620\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 121s 1s/step - loss: 0.6388 - accuracy: 0.7341 - val_loss: 0.5650 - val_accuracy: 0.7663\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 111s 1s/step - loss: 0.5989 - accuracy: 0.7485 - val_loss: 0.5728 - val_accuracy: 0.7684\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 106s 1s/step - loss: 0.5744 - accuracy: 0.7591 - val_loss: 0.5677 - val_accuracy: 0.7620\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 106s 1s/step - loss: 0.5535 - accuracy: 0.7686 - val_loss: 0.5487 - val_accuracy: 0.7727\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 106s 1s/step - loss: 0.5344 - accuracy: 0.7764 - val_loss: 0.5340 - val_accuracy: 0.7769\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 106s 1s/step - loss: 0.5217 - accuracy: 0.7826 - val_loss: 0.5390 - val_accuracy: 0.7823\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 106s 1s/step - loss: 0.5068 - accuracy: 0.7898 - val_loss: 0.5410 - val_accuracy: 0.7705\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 105s 1s/step - loss: 0.5007 - accuracy: 0.7891 - val_loss: 0.5812 - val_accuracy: 0.7620\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 105s 1s/step - loss: 0.4914 - accuracy: 0.7940 - val_loss: 0.5861 - val_accuracy: 0.7673\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 109s 1s/step - loss: 0.4742 - accuracy: 0.8035 - val_loss: 0.5436 - val_accuracy: 0.7844\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 105s 1s/step - loss: 0.4702 - accuracy: 0.8009 - val_loss: 0.5447 - val_accuracy: 0.7812\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 106s 1s/step - loss: 0.4538 - accuracy: 0.8104 - val_loss: 0.5693 - val_accuracy: 0.7609\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 106s 1s/step - loss: 0.4537 - accuracy: 0.8111 - val_loss: 0.5219 - val_accuracy: 0.7844\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 106s 1s/step - loss: 0.4418 - accuracy: 0.8163 - val_loss: 0.5467 - val_accuracy: 0.7823\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 98, 98, 32)        320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 49, 49, 32)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 47, 47, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 23, 23, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 21, 21, 96)        55392     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 10, 10, 96)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9600)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 50)                480050    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 50)                2550      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 556,961\n",
      "Trainable params: 556,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.4939601719379425\n",
      "Test accuracy: 0.796928346157074\n"
     ]
    }
   ],
   "source": [
    "def process(X,file):\n",
    "    img=cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n",
    "    X.append(img)\n",
    "    #write your code\n",
    "\n",
    "def normalize(dataset):\n",
    "    dataset=asarray(dataset).astype('float32')\n",
    "    dataset=dataset/255.0\n",
    "    return dataset\n",
    "\n",
    "def augmentation(row,label,Augmented,Y_Augmeneted):\n",
    "    scale_out = skimage.transform.rescale(row, scale=2.0, mode='constant')\n",
    "    scale_out=skimage.transform.resize(scale_out,(100,100))\n",
    "    scale_in= skimage.transform.rescale(row, scale=0.5, mode='constant')\n",
    "    scale_in=skimage.transform.resize(scale_in,(100,100))\n",
    "    rot = skimage.transform.rotate(row, angle=20, mode='reflect')\n",
    "    rot=skimage.transform.resize(rot,(100,100))\n",
    "    images=[row,scale_out,scale_in,rot]\n",
    "    for image in images:\n",
    "        Augmented.append(image)\n",
    "        Y_Augmented.append(label)\n",
    "\n",
    "\n",
    "\n",
    "import skimage\n",
    "from skimage import transform\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rescale\n",
    "import cv2\n",
    "import glob\n",
    "import random as ra\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import utils\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "import math\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "Normal=[]\n",
    "Bacterial=[]\n",
    "Virus=[]\n",
    "classes=[Virus,Bacterial,Normal]\n",
    "Y_Normal=[]\n",
    "Y_Bacterial=[]\n",
    "Y_Virus=[]\n",
    "Y=[Y_Normal,Y_Bacterial,Y_Virus]\n",
    "files=glob.glob('chest_xray_lower_dim2'+'/*.jpeg')\n",
    "ra.shuffle(files)\n",
    "for file in files:\n",
    "    k=-1\n",
    "    if \"virus\" in file:\n",
    "        k=0\n",
    "    elif \"bacteria\" in file:\n",
    "        k=1\n",
    "    else:\n",
    "        k=2\n",
    "    Y[k].append(str(k))\n",
    "    process(classes[k],file)\n",
    "    \n",
    "len_classes=[]\n",
    "for class_ in classes:\n",
    "    len_classes.append(len(class_))\n",
    "print(len_classes)\n",
    "same_length=min(len_classes)\n",
    "evenly=False\n",
    "\n",
    "if evenly:\n",
    "    for i in range(3):\n",
    "        len_classes[i]=same_length\n",
    "\n",
    "for i in range(3):\n",
    "    classes[i]=classes[i][0:len_classes[i]]\n",
    "for i in range(3):\n",
    "    Y[i]=Y[i][0:len_classes[i]]\n",
    "\n",
    "Train=[]\n",
    "Valid=[]\n",
    "Test=[]\n",
    "TVT=[Train,Valid,Test]\n",
    "Y_Train=[]\n",
    "Y_Valid=[]\n",
    "Y_Test=[]\n",
    "Y_TVT=[Y_Train,Y_Valid,Y_Test]\n",
    "\n",
    "bounds=[0,0.64,0.8,1]\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        TVT[i]+=classes[j][int(bounds[i]*len_classes[j]):int(bounds[i+1]*len_classes[j])]\n",
    "        Y_TVT[i]+=Y[j][int(bounds[i]*len_classes[j]):int(bounds[i+1]*len_classes[j])]\n",
    "        \n",
    "Augmented=[]\n",
    "Y_Augmented=[]\n",
    "\n",
    "for i in range(len(Train)):\n",
    "    augmentation(Train[i],Y_Train[i],Augmented,Y_Augmented)\n",
    "\n",
    "print(len(Train))\n",
    "\n",
    "TVT[0]=Augmented\n",
    "Y_TVT[0]=Y_Augmented\n",
    "\n",
    "for i in range(3):\n",
    "    TVT[i]=normalize(TVT[i])\n",
    "    TVT[i]=TVT[i].reshape(-1,100,100,1)\n",
    "    Y_TVT[i]=keras.utils.to_categorical(Y_TVT[i],3)\n",
    "\n",
    "print(len(Augmented))\n",
    "\n",
    "# epoch=32 steps_per_epoch=32\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train(epochs_num,batch_len,conv_neurons,art_neurons):\n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for conv_neuron in conv_neurons:\n",
    "            hidden=layers.Conv2D(conv_neuron,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=100*100\n",
    "        w=math.sqrt(inputs)\n",
    "        for art_neuron in art_neurons:\n",
    "            hidden=layers.Dense(art_neuron,activation='relu',kernel_regularizer=regularizers.L2(0.0001))(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=30\n",
    "            w=math.sqrt(inputs)\n",
    "        output=layers.Dense(3,activation='softmax',kernel_regularizer=regularizers.L2(0.0001))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4,mode='max')\n",
    "    model=mlp_model()\n",
    "    model.fit(TVT[0],Y_TVT[0],validation_data=(TVT[1],Y_TVT[1]),epochs=epochs_num,batch_size=batch_len,callbacks=[callback],verbose=1)\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(TVT[2], Y_TVT[2],verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])\n",
    "    \n",
    "train(100,150,[32,64,96],[50,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1fd56fd",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     21\u001b[0m         Augmented\u001b[38;5;241m.\u001b[39mappend(image)\n\u001b[0;32m     22\u001b[0m         Y_Augmented\u001b[38;5;241m.\u001b[39mappend(label)\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transform\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mskimage\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m resize\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\skimage\\__init__.py:157\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    154\u001b[0m         _raise_build_error(e)\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;66;03m# All skimage root imports go here\u001b[39;00m\n\u001b[1;32m--> 157\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdtype\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (img_as_float32,\n\u001b[0;32m    158\u001b[0m                              img_as_float64,\n\u001b[0;32m    159\u001b[0m                              img_as_float,\n\u001b[0;32m    160\u001b[0m                              img_as_int,\n\u001b[0;32m    161\u001b[0m                              img_as_uint,\n\u001b[0;32m    162\u001b[0m                              img_as_ubyte,\n\u001b[0;32m    163\u001b[0m                              img_as_bool,\n\u001b[0;32m    164\u001b[0m                              dtype_limits)\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlookfor\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lookfor\n\u001b[0;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdev\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m __version__:\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;66;03m# Append last commit date and hash to dev version information, if available\u001b[39;00m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\skimage\\util\\__init__.py:16\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munique\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m unique_rows\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_invert\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m invert\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_montage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m montage\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_map_array\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m map_array\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_label\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m label_points\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\skimage\\util\\_montage.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shared\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m exposure\n\u001b[0;32m      6\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmontage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      9\u001b[0m \u001b[38;5;129m@utils\u001b[39m\u001b[38;5;241m.\u001b[39mchannel_as_last_axis(multichannel_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;129m@utils\u001b[39m\u001b[38;5;241m.\u001b[39mdeprecate_multichannel_kwarg()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmontage\u001b[39m(arr_in, fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m, rescale_intensity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, grid_shape\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m     12\u001b[0m             padding_width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, multichannel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, channel_axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1055\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\skimage\\_shared\\lazy.py:62\u001b[0m, in \u001b[0;36mattach.<locals>.__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m submodules:\n\u001b[1;32m---> 62\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mpackage_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mname\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m attr_to_modules:\n\u001b[0;32m     64\u001b[0m         submod \u001b[38;5;241m=\u001b[39m importlib\u001b[38;5;241m.\u001b[39mimport_module(\n\u001b[0;32m     65\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpackage_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_to_modules[name]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     66\u001b[0m         )\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\skimage\\exposure\\__init__.py:6\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexposure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m histogram, equalize_hist, \\\n\u001b[0;32m      2\u001b[0m                       rescale_intensity, cumulative_distribution, \\\n\u001b[0;32m      3\u001b[0m                       adjust_gamma, adjust_sigmoid, adjust_log, \\\n\u001b[0;32m      4\u001b[0m                       is_low_contrast\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_adapthist\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m equalize_adapthist\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhistogram_matching\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m match_histograms\n\u001b[0;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhistogram\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     11\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mequalize_hist\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     12\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mequalize_adapthist\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mis_low_contrast\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     19\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmatch_histograms\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\skimage\\exposure\\_adapthist.py:21\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_shared\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _supported_float_type\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolor\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madapt_rgb\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adapt_rgb, hsv_value\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexposure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rescale_intensity\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m img_as_uint\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\skimage\\color\\__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolorconv\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (convert_colorspace,\n\u001b[0;32m      2\u001b[0m                         rgba2rgb,\n\u001b[0;32m      3\u001b[0m                         rgb2hsv,\n\u001b[0;32m      4\u001b[0m                         hsv2rgb,\n\u001b[0;32m      5\u001b[0m                         rgb2xyz,\n\u001b[0;32m      6\u001b[0m                         xyz2rgb,\n\u001b[0;32m      7\u001b[0m                         rgb2rgbcie,\n\u001b[0;32m      8\u001b[0m                         rgbcie2rgb,\n\u001b[0;32m      9\u001b[0m                         rgb2gray,\n\u001b[0;32m     10\u001b[0m                         gray2rgb,\n\u001b[0;32m     11\u001b[0m                         gray2rgba,\n\u001b[0;32m     12\u001b[0m                         xyz2lab,\n\u001b[0;32m     13\u001b[0m                         lab2xyz,\n\u001b[0;32m     14\u001b[0m                         lab2rgb,\n\u001b[0;32m     15\u001b[0m                         rgb2lab,\n\u001b[0;32m     16\u001b[0m                         xyz2luv,\n\u001b[0;32m     17\u001b[0m                         luv2xyz,\n\u001b[0;32m     18\u001b[0m                         luv2rgb,\n\u001b[0;32m     19\u001b[0m                         rgb2luv,\n\u001b[0;32m     20\u001b[0m                         rgb2hed,\n\u001b[0;32m     21\u001b[0m                         hed2rgb,\n\u001b[0;32m     22\u001b[0m                         lab2lch,\n\u001b[0;32m     23\u001b[0m                         lch2lab,\n\u001b[0;32m     24\u001b[0m                         rgb2yuv,\n\u001b[0;32m     25\u001b[0m                         yuv2rgb,\n\u001b[0;32m     26\u001b[0m                         rgb2yiq,\n\u001b[0;32m     27\u001b[0m                         yiq2rgb,\n\u001b[0;32m     28\u001b[0m                         rgb2ypbpr,\n\u001b[0;32m     29\u001b[0m                         ypbpr2rgb,\n\u001b[0;32m     30\u001b[0m                         rgb2ycbcr,\n\u001b[0;32m     31\u001b[0m                         ycbcr2rgb,\n\u001b[0;32m     32\u001b[0m                         rgb2ydbdr,\n\u001b[0;32m     33\u001b[0m                         ydbdr2rgb,\n\u001b[0;32m     34\u001b[0m                         separate_stains,\n\u001b[0;32m     35\u001b[0m                         combine_stains,\n\u001b[0;32m     36\u001b[0m                         rgb_from_hed,\n\u001b[0;32m     37\u001b[0m                         hed_from_rgb,\n\u001b[0;32m     38\u001b[0m                         rgb_from_hdx,\n\u001b[0;32m     39\u001b[0m                         hdx_from_rgb,\n\u001b[0;32m     40\u001b[0m                         rgb_from_fgx,\n\u001b[0;32m     41\u001b[0m                         fgx_from_rgb,\n\u001b[0;32m     42\u001b[0m                         rgb_from_bex,\n\u001b[0;32m     43\u001b[0m                         bex_from_rgb,\n\u001b[0;32m     44\u001b[0m                         rgb_from_rbd,\n\u001b[0;32m     45\u001b[0m                         rbd_from_rgb,\n\u001b[0;32m     46\u001b[0m                         rgb_from_gdx,\n\u001b[0;32m     47\u001b[0m                         gdx_from_rgb,\n\u001b[0;32m     48\u001b[0m                         rgb_from_hax,\n\u001b[0;32m     49\u001b[0m                         hax_from_rgb,\n\u001b[0;32m     50\u001b[0m                         rgb_from_bro,\n\u001b[0;32m     51\u001b[0m                         bro_from_rgb,\n\u001b[0;32m     52\u001b[0m                         rgb_from_bpx,\n\u001b[0;32m     53\u001b[0m                         bpx_from_rgb,\n\u001b[0;32m     54\u001b[0m                         rgb_from_ahx,\n\u001b[0;32m     55\u001b[0m                         ahx_from_rgb,\n\u001b[0;32m     56\u001b[0m                         rgb_from_hpx,\n\u001b[0;32m     57\u001b[0m                         hpx_from_rgb)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolorlabel\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m color_dict, label2rgb\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdelta_e\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (deltaE_cie76,\n\u001b[0;32m     62\u001b[0m                       deltaE_ciede94,\n\u001b[0;32m     63\u001b[0m                       deltaE_ciede2000,\n\u001b[0;32m     64\u001b[0m                       deltaE_cmc,\n\u001b[0;32m     65\u001b[0m                       )\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\skimage\\color\\colorconv.py:407\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    404\u001b[0m rgbcie_from_xyz \u001b[38;5;241m=\u001b[39m linalg\u001b[38;5;241m.\u001b[39minv(xyz_from_rgbcie)\n\u001b[0;32m    406\u001b[0m \u001b[38;5;66;03m# construct matrices to and from rgb:\u001b[39;00m\n\u001b[1;32m--> 407\u001b[0m rgbcie_from_rgb \u001b[38;5;241m=\u001b[39m rgbcie_from_xyz \u001b[38;5;241m@\u001b[39m xyz_from_rgb\n\u001b[0;32m    408\u001b[0m rgb_from_rgbcie \u001b[38;5;241m=\u001b[39m rgb_from_xyz \u001b[38;5;241m@\u001b[39m xyz_from_rgbcie\n\u001b[0;32m    411\u001b[0m gray_from_rgb \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([[\u001b[38;5;241m0.2125\u001b[39m, \u001b[38;5;241m0.7154\u001b[39m, \u001b[38;5;241m0.0721\u001b[39m],\n\u001b[0;32m    412\u001b[0m                           [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    413\u001b[0m                           [\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]])\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#200,200\n",
    "def process(X,file):\n",
    "    img=cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n",
    "    X.append(img)\n",
    "    #write your code\n",
    "\n",
    "def normalize(dataset):\n",
    "    dataset=asarray(dataset).astype('float32')\n",
    "    dataset=dataset/255.0\n",
    "    return dataset\n",
    "\n",
    "def augmentation(row,label,Augmented,Y_Augmeneted):\n",
    "    scale_out = skimage.transform.rescale(row, scale=2.0, mode='constant')\n",
    "    scale_out=skimage.transform.resize(scale_out,(200,200))\n",
    "    scale_in= skimage.transform.rescale(row, scale=0.5, mode='constant')\n",
    "    scale_in=skimage.transform.resize(scale_in,(200,200))\n",
    "    rot = skimage.transform.rotate(row, angle=20, mode='reflect')\n",
    "    rot=skimage.transform.resize(rot,(200,200))\n",
    "    images=[row,scale_out,scale_in,rot]\n",
    "    for image in images:\n",
    "        Augmented.append(image)\n",
    "        Y_Augmented.append(label)\n",
    "\n",
    "\n",
    "\n",
    "import skimage\n",
    "from skimage import transform\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rescale\n",
    "import cv2\n",
    "import glob\n",
    "import random as ra\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import utils\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "import math\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "Normal=[]\n",
    "Bacterial=[]\n",
    "Virus=[]\n",
    "classes=[Virus,Bacterial,Normal]\n",
    "Y_Normal=[]\n",
    "Y_Bacterial=[]\n",
    "Y_Virus=[]\n",
    "Y=[Y_Normal,Y_Bacterial,Y_Virus]\n",
    "files=glob.glob('chest_xray_lower_dim200x200'+'/*.jpeg')\n",
    "ra.shuffle(files)\n",
    "for file in files:\n",
    "    k=-1\n",
    "    if \"virus\" in file:\n",
    "        k=0\n",
    "    elif \"bacteria\" in file:\n",
    "        k=1\n",
    "    else:\n",
    "        k=2\n",
    "    Y[k].append(str(k))\n",
    "    process(classes[k],file)\n",
    "    \n",
    "len_classes=[]\n",
    "for class_ in classes:\n",
    "    len_classes.append(len(class_))\n",
    "print(len_classes)\n",
    "same_length=min(len_classes)\n",
    "evenly=False\n",
    "\n",
    "if evenly:\n",
    "    for i in range(3):\n",
    "        len_classes[i]=same_length\n",
    "\n",
    "for i in range(3):\n",
    "    classes[i]=classes[i][0:len_classes[i]]\n",
    "for i in range(3):\n",
    "    Y[i]=Y[i][0:len_classes[i]]\n",
    "\n",
    "Train=[]\n",
    "Valid=[]\n",
    "Test=[]\n",
    "TVT=[Train,Valid,Test]\n",
    "Y_Train=[]\n",
    "Y_Valid=[]\n",
    "Y_Test=[]\n",
    "Y_TVT=[Y_Train,Y_Valid,Y_Test]\n",
    "\n",
    "bounds=[0,0.64,0.8,1]\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        TVT[i]+=classes[j][int(bounds[i]*len_classes[j]):int(bounds[i+1]*len_classes[j])]\n",
    "        Y_TVT[i]+=Y[j][int(bounds[i]*len_classes[j]):int(bounds[i+1]*len_classes[j])]\n",
    "        \n",
    "Augmented=[]\n",
    "Y_Augmented=[]\n",
    "\n",
    "for i in range(len(Train)):\n",
    "    augmentation(Train[i],Y_Train[i],Augmented,Y_Augmented)\n",
    "\n",
    "print(len(Train))\n",
    "\n",
    "TVT[0]=Augmented\n",
    "Y_TVT[0]=Y_Augmented\n",
    "\n",
    "for i in range(3):\n",
    "    TVT[i]=normalize(TVT[i])\n",
    "    TVT[i]=TVT[i].reshape(-1,200,200,1)\n",
    "    Y_TVT[i]=keras.utils.to_categorical(Y_TVT[i],3)\n",
    "\n",
    "print(len(Augmented))\n",
    "\n",
    "# epoch=32 steps_per_epoch=32\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train(epochs_num,batch_len,conv_neurons,art_neurons):\n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(200,200,1))\n",
    "        hidden=Inp\n",
    "        for conv_neuron in conv_neurons:\n",
    "            hidden=layers.Conv2D(conv_neuron,kernel_size=(3,3),padding='same',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=100*100\n",
    "        w=math.sqrt(inputs)\n",
    "        for art_neuron in art_neurons:\n",
    "            hidden=layers.Dense(art_neuron,activation='relu',kernel_regularizer=regularizers.L2(0.0001))(hidden)\n",
    "            hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=30\n",
    "            w=math.sqrt(inputs)\n",
    "        output=layers.Dense(3,activation='softmax',kernel_regularizer=regularizers.L2(0.0001))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4,mode='max')\n",
    "    model=mlp_model()\n",
    "    model.fit(TVT[0],Y_TVT[0],validation_data=(TVT[1],Y_TVT[1]),epochs=epochs_num,batch_size=batch_len,callbacks=[callback],verbose=1)\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(TVT[2], Y_TVT[2],verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])\n",
    "    \n",
    "train(100,150,[32,64,96,128],[50,50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9723895c",
   "metadata": {},
   "source": [
    "#### Now we wil test it with 2 dense layers smaller batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0e40608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1493, 2780, 1583]\n",
      "1872\n",
      "7488\n",
      "Epoch 1/100\n",
      "75/75 [==============================] - 459s 6s/step - loss: 1.0742 - accuracy: 0.4675 - val_loss: 1.0775 - val_accuracy: 0.4749\n",
      "Epoch 2/100\n",
      "75/75 [==============================] - 444s 6s/step - loss: 1.0665 - accuracy: 0.4748 - val_loss: 1.0695 - val_accuracy: 0.4749\n",
      "Epoch 3/100\n",
      "75/75 [==============================] - 440s 6s/step - loss: 1.0538 - accuracy: 0.4752 - val_loss: 0.9448 - val_accuracy: 0.4899\n",
      "Epoch 4/100\n",
      "75/75 [==============================] - 440s 6s/step - loss: 1.0173 - accuracy: 0.5051 - val_loss: 0.7240 - val_accuracy: 0.6884\n",
      "Epoch 5/100\n",
      "75/75 [==============================] - 437s 6s/step - loss: 0.9824 - accuracy: 0.5294 - val_loss: 0.6458 - val_accuracy: 0.7364\n",
      "Epoch 6/100\n",
      "75/75 [==============================] - 441s 6s/step - loss: 0.9612 - accuracy: 0.5385 - val_loss: 0.6413 - val_accuracy: 0.7417\n",
      "Epoch 7/100\n",
      "75/75 [==============================] - 438s 6s/step - loss: 0.9544 - accuracy: 0.5387 - val_loss: 0.5628 - val_accuracy: 0.7577\n",
      "Epoch 8/100\n",
      "75/75 [==============================] - 443s 6s/step - loss: 0.9407 - accuracy: 0.5433 - val_loss: 0.5669 - val_accuracy: 0.7673\n",
      "Epoch 9/100\n",
      "75/75 [==============================] - 438s 6s/step - loss: 0.9311 - accuracy: 0.5474 - val_loss: 0.6178 - val_accuracy: 0.7460\n",
      "Epoch 10/100\n",
      "75/75 [==============================] - 438s 6s/step - loss: 0.9241 - accuracy: 0.5521 - val_loss: 0.5477 - val_accuracy: 0.7834\n",
      "Epoch 11/100\n",
      "75/75 [==============================] - 442s 6s/step - loss: 0.9245 - accuracy: 0.5522 - val_loss: 0.5475 - val_accuracy: 0.7705\n",
      "Epoch 12/100\n",
      "75/75 [==============================] - 437s 6s/step - loss: 0.9168 - accuracy: 0.5544 - val_loss: 0.5633 - val_accuracy: 0.7759\n",
      "Epoch 13/100\n",
      "75/75 [==============================] - 437s 6s/step - loss: 0.9113 - accuracy: 0.5560 - val_loss: 0.6003 - val_accuracy: 0.7599\n",
      "Epoch 14/100\n",
      "75/75 [==============================] - 440s 6s/step - loss: 0.9071 - accuracy: 0.5569 - val_loss: 0.5873 - val_accuracy: 0.7866\n",
      "Epoch 15/100\n",
      "75/75 [==============================] - 548s 7s/step - loss: 0.9018 - accuracy: 0.5590 - val_loss: 0.6776 - val_accuracy: 0.7823\n",
      "Epoch 16/100\n",
      "75/75 [==============================] - 452s 6s/step - loss: 0.9060 - accuracy: 0.5597 - val_loss: 0.6613 - val_accuracy: 0.7652\n",
      "Epoch 17/100\n",
      "75/75 [==============================] - 438s 6s/step - loss: 0.9058 - accuracy: 0.5574 - val_loss: 0.6762 - val_accuracy: 0.7439\n",
      "Epoch 18/100\n",
      "75/75 [==============================] - 469s 6s/step - loss: 0.8936 - accuracy: 0.5646 - val_loss: 0.6496 - val_accuracy: 0.7855\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 200, 200, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 198, 198, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 99, 99, 32)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 97, 97, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 48, 48, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 46, 46, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 23, 23, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 21, 21, 256)       295168    \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 10, 10, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 25600)             0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 40)                1024040   \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 40)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 30)                1230      \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 30)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,413,203\n",
      "Trainable params: 1,413,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.6659302711486816\n",
      "Test accuracy: 0.7738907933235168\n"
     ]
    }
   ],
   "source": [
    "#200,200\n",
    "def process(X,file):\n",
    "    img=cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n",
    "    X.append(img)\n",
    "    #write your code\n",
    "\n",
    "def normalize(dataset):\n",
    "    dataset=asarray(dataset).astype('float32')\n",
    "    dataset=dataset/255.0\n",
    "    return dataset\n",
    "\n",
    "def augmentation(row,label,Augmented,Y_Augmeneted):\n",
    "    scale_out = skimage.transform.rescale(row, scale=2.0, mode='constant')\n",
    "    scale_out=skimage.transform.resize(scale_out,(200,200))\n",
    "    scale_in= skimage.transform.rescale(row, scale=0.5, mode='constant')\n",
    "    scale_in=skimage.transform.resize(scale_in,(200,200))\n",
    "    rot = skimage.transform.rotate(row, angle=20, mode='reflect')\n",
    "    rot=skimage.transform.resize(rot,(200,200))\n",
    "    images=[row,scale_out,scale_in,rot]\n",
    "    for image in images:\n",
    "        Augmented.append(image)\n",
    "        Y_Augmented.append(label)\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import skimage\n",
    "from skimage import transform\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rescale\n",
    "import cv2\n",
    "import glob\n",
    "import random as ra\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import utils\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "import math\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "Normal=[]\n",
    "Bacterial=[]\n",
    "Virus=[]\n",
    "classes=[Virus,Bacterial,Normal]\n",
    "Y_Normal=[]\n",
    "Y_Bacterial=[]\n",
    "Y_Virus=[]\n",
    "Y=[Y_Normal,Y_Bacterial,Y_Virus]\n",
    "files=glob.glob('chest_xray_lower_dim200x200'+'/*.jpeg')\n",
    "ra.shuffle(files)\n",
    "for file in files:\n",
    "    k=-1\n",
    "    if \"virus\" in file:\n",
    "        k=0\n",
    "    elif \"bacteria\" in file:\n",
    "        k=1\n",
    "    else:\n",
    "        k=2\n",
    "    Y[k].append(str(k))\n",
    "    process(classes[k],file)\n",
    "    \n",
    "len_classes=[]\n",
    "for class_ in classes:\n",
    "    len_classes.append(len(class_))\n",
    "print(len_classes)\n",
    "same_length=min(len_classes)\n",
    "evenly=False\n",
    "\n",
    "if evenly:\n",
    "    for i in range(3):\n",
    "        len_classes[i]=same_length\n",
    "\n",
    "for i in range(3):\n",
    "    classes[i]=classes[i][0:len_classes[i]]\n",
    "for i in range(3):\n",
    "    Y[i]=Y[i][0:len_classes[i]]\n",
    "\n",
    "Train=[]\n",
    "Valid=[]\n",
    "Test=[]\n",
    "TVT=[Train,Valid,Test]\n",
    "Y_Train=[]\n",
    "Y_Valid=[]\n",
    "Y_Test=[]\n",
    "Y_TVT=[Y_Train,Y_Valid,Y_Test]\n",
    "\n",
    "bounds=[0,0.64,0.8,1]\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        keeped=classes[j][int(bounds[i]*len_classes[j]):int(bounds[i+1]*len_classes[j])]\n",
    "        keeped_Y=Y[j][int(bounds[i]*len_classes[j]):int(bounds[i+1]*len_classes[j])]\n",
    "        if(i==0):\n",
    "            keeped=keeped[0:int(len(keeped)/2)]\n",
    "            keeped_Y=keeped_Y[0:int(len(keeped_Y)/2)]                 \n",
    "        TVT[i]+=keeped\n",
    "        Y_TVT[i]+=keeped_Y\n",
    "        \n",
    "Augmented=[]\n",
    "Y_Augmented=[]\n",
    "\n",
    "for i in range(len(Train)):\n",
    "    augmentation(Train[i],Y_Train[i],Augmented,Y_Augmented)\n",
    "\n",
    "print(len(Train))\n",
    "\n",
    "TVT[0]=Augmented\n",
    "Y_TVT[0]=Y_Augmented\n",
    "TVT[0],Y_TVT[0]=shuffle(TVT[0],Y_TVT[0])\n",
    "\n",
    "for i in range(3):\n",
    "    TVT[i]=normalize(TVT[i])\n",
    "    TVT[i]=TVT[i].reshape(-1,200,200,1)\n",
    "    Y_TVT[i]=keras.utils.to_categorical(Y_TVT[i],3)\n",
    "\n",
    "print(len(Augmented))\n",
    "\n",
    "# epoch=32 steps_per_epoch=32\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train(epochs_num,batch_len,conv_neurons,art_neurons):\n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(200,200,1))\n",
    "        hidden=Inp\n",
    "        for conv_neuron in conv_neurons:\n",
    "            hidden=layers.Conv2D(conv_neuron,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            #hidden=layers.BatchNormalization()(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=100*100\n",
    "        w=math.sqrt(inputs)\n",
    "        for art_neuron in art_neurons:\n",
    "            hidden=layers.Dense(art_neuron,activation='relu',kernel_regularizer=regularizers.L2(0.0001))(hidden)\n",
    "            hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=30\n",
    "            w=math.sqrt(inputs)\n",
    "        output=layers.Dense(3,activation='softmax',kernel_regularizer=regularizers.L2(0.0001))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4,mode='max')\n",
    "    model=mlp_model()\n",
    "    model.fit(TVT[0],Y_TVT[0],validation_data=(TVT[1],Y_TVT[1]),epochs=epochs_num,batch_size=batch_len,callbacks=[callback],verbose=1)\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(TVT[2], Y_TVT[2],verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])\n",
    "    \n",
    "train(100,100,[pow(2,5+i) for i in range(4)],[40,30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446d2ba7",
   "metadata": {},
   "source": [
    "#### Let's  set batch size 75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31e71990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1493, 2780, 1583]\n",
      "1872\n",
      "7488\n",
      "Epoch 1/100\n",
      "100/100 [==============================] - 53s 498ms/step - loss: 1.0726 - accuracy: 0.4745 - val_loss: 1.0625 - val_accuracy: 0.4749\n",
      "Epoch 2/100\n",
      "100/100 [==============================] - 48s 484ms/step - loss: 1.0639 - accuracy: 0.4749 - val_loss: 1.0580 - val_accuracy: 0.4749\n",
      "Epoch 3/100\n",
      "100/100 [==============================] - 49s 492ms/step - loss: 1.0601 - accuracy: 0.4749 - val_loss: 1.0341 - val_accuracy: 0.4749\n",
      "Epoch 4/100\n",
      "100/100 [==============================] - 48s 480ms/step - loss: 1.0534 - accuracy: 0.4749 - val_loss: 1.0381 - val_accuracy: 0.4749\n",
      "Epoch 5/100\n",
      "100/100 [==============================] - 49s 487ms/step - loss: 1.0350 - accuracy: 0.4896 - val_loss: 0.8356 - val_accuracy: 0.6564\n",
      "Epoch 6/100\n",
      "100/100 [==============================] - 49s 486ms/step - loss: 1.0048 - accuracy: 0.5179 - val_loss: 0.7636 - val_accuracy: 0.6660\n",
      "Epoch 7/100\n",
      "100/100 [==============================] - 49s 493ms/step - loss: 0.9807 - accuracy: 0.5283 - val_loss: 0.6916 - val_accuracy: 0.7279\n",
      "Epoch 8/100\n",
      "100/100 [==============================] - 50s 503ms/step - loss: 0.9771 - accuracy: 0.5312 - val_loss: 0.7371 - val_accuracy: 0.6873\n",
      "Epoch 9/100\n",
      "100/100 [==============================] - 49s 492ms/step - loss: 0.9676 - accuracy: 0.5355 - val_loss: 0.6550 - val_accuracy: 0.7150\n",
      "Epoch 10/100\n",
      "100/100 [==============================] - 48s 478ms/step - loss: 0.9611 - accuracy: 0.5362 - val_loss: 0.6423 - val_accuracy: 0.7396\n",
      "Epoch 11/100\n",
      "100/100 [==============================] - 48s 478ms/step - loss: 0.9591 - accuracy: 0.5379 - val_loss: 0.6307 - val_accuracy: 0.7449\n",
      "Epoch 12/100\n",
      "100/100 [==============================] - 48s 476ms/step - loss: 0.9569 - accuracy: 0.5398 - val_loss: 0.6284 - val_accuracy: 0.7364\n",
      "Epoch 13/100\n",
      "100/100 [==============================] - 49s 488ms/step - loss: 0.9557 - accuracy: 0.5389 - val_loss: 0.6172 - val_accuracy: 0.7513\n",
      "Epoch 14/100\n",
      "100/100 [==============================] - 48s 481ms/step - loss: 0.9505 - accuracy: 0.5411 - val_loss: 0.6246 - val_accuracy: 0.7311\n",
      "Epoch 15/100\n",
      "100/100 [==============================] - 48s 478ms/step - loss: 0.9477 - accuracy: 0.5437 - val_loss: 0.6133 - val_accuracy: 0.7513\n",
      "Epoch 16/100\n",
      "100/100 [==============================] - 48s 476ms/step - loss: 0.9484 - accuracy: 0.5430 - val_loss: 0.6100 - val_accuracy: 0.7524\n",
      "Epoch 17/100\n",
      "100/100 [==============================] - 50s 499ms/step - loss: 0.9473 - accuracy: 0.5415 - val_loss: 0.6479 - val_accuracy: 0.7279\n",
      "Epoch 18/100\n",
      "100/100 [==============================] - 47s 468ms/step - loss: 0.9450 - accuracy: 0.5463 - val_loss: 0.6277 - val_accuracy: 0.7428\n",
      "Epoch 19/100\n",
      "100/100 [==============================] - 47s 469ms/step - loss: 0.9407 - accuracy: 0.5462 - val_loss: 0.6099 - val_accuracy: 0.7545\n",
      "Epoch 20/100\n",
      "100/100 [==============================] - 49s 488ms/step - loss: 0.9412 - accuracy: 0.5442 - val_loss: 0.5988 - val_accuracy: 0.7556\n",
      "Epoch 21/100\n",
      "100/100 [==============================] - 48s 480ms/step - loss: 0.9393 - accuracy: 0.5479 - val_loss: 0.6010 - val_accuracy: 0.7556\n",
      "Epoch 22/100\n",
      "100/100 [==============================] - 48s 475ms/step - loss: 0.9358 - accuracy: 0.5462 - val_loss: 0.5986 - val_accuracy: 0.7567\n",
      "Epoch 23/100\n",
      "100/100 [==============================] - 51s 512ms/step - loss: 0.9360 - accuracy: 0.5459 - val_loss: 0.5968 - val_accuracy: 0.7503\n",
      "Epoch 24/100\n",
      "100/100 [==============================] - 51s 513ms/step - loss: 0.9358 - accuracy: 0.5466 - val_loss: 0.6081 - val_accuracy: 0.7407\n",
      "Epoch 25/100\n",
      "100/100 [==============================] - 48s 479ms/step - loss: 0.9343 - accuracy: 0.5479 - val_loss: 0.5972 - val_accuracy: 0.7556\n",
      "Epoch 26/100\n",
      "100/100 [==============================] - 49s 486ms/step - loss: 0.9333 - accuracy: 0.5469 - val_loss: 0.6253 - val_accuracy: 0.7428\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 200, 200, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 198, 198, 2)       20        \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 99, 99, 2)        0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 97, 97, 2)         38        \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 48, 48, 2)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 46, 46, 2)         38        \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 23, 23, 2)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 21, 21, 2)         38        \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 10, 10, 2)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 200)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 40)                8040      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 40)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                1230      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 30)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,497\n",
      "Trainable params: 9,497\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.6034315228462219\n",
      "Test accuracy: 0.7542662024497986\n"
     ]
    }
   ],
   "source": [
    "#EXECUTE\n",
    "def process(X,file):\n",
    "    img=cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n",
    "    X.append(img)\n",
    "    #write your code\n",
    "\n",
    "def normalize(dataset):\n",
    "    dataset=asarray(dataset).astype('float32')\n",
    "    dataset=dataset/255.0\n",
    "    return dataset\n",
    "\n",
    "def augmentation(row,label,Augmented,Y_Augmeneted):\n",
    "    scale_out = skimage.transform.rescale(row, scale=2.0, mode='constant')\n",
    "    scale_out=skimage.transform.resize(scale_out,(200,200))\n",
    "    scale_in= skimage.transform.rescale(row, scale=0.5, mode='constant')\n",
    "    scale_in=skimage.transform.resize(scale_in,(200,200))\n",
    "    rot = skimage.transform.rotate(row, angle=20, mode='reflect')\n",
    "    rot=skimage.transform.resize(rot,(200,200))\n",
    "    images=[row,scale_out,scale_in,rot]\n",
    "    for image in images:\n",
    "        Augmented.append(image)\n",
    "        Y_Augmented.append(label)\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import skimage\n",
    "from skimage import transform\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rescale\n",
    "import cv2\n",
    "import glob\n",
    "import random as ra\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import utils\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "import math\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "Normal=[]\n",
    "Bacterial=[]\n",
    "Virus=[]\n",
    "classes=[Virus,Bacterial,Normal]\n",
    "Y_Normal=[]\n",
    "Y_Bacterial=[]\n",
    "Y_Virus=[]\n",
    "Y=[Y_Normal,Y_Bacterial,Y_Virus]\n",
    "files=glob.glob('chest_xray_lower_dim200x200'+'/*.jpeg')\n",
    "ra.shuffle(files)\n",
    "for file in files:\n",
    "    k=-1\n",
    "    if \"virus\" in file:\n",
    "        k=0\n",
    "    elif \"bacteria\" in file:\n",
    "        k=1\n",
    "    else:\n",
    "        k=2\n",
    "    Y[k].append(str(k))\n",
    "    process(classes[k],file)\n",
    "    \n",
    "len_classes=[]\n",
    "for class_ in classes:\n",
    "    len_classes.append(len(class_))\n",
    "print(len_classes)\n",
    "same_length=min(len_classes)\n",
    "evenly=False\n",
    "\n",
    "if evenly:\n",
    "    for i in range(3):\n",
    "        len_classes[i]=same_length\n",
    "\n",
    "for i in range(3):\n",
    "    classes[i]=classes[i][0:len_classes[i]]\n",
    "for i in range(3):\n",
    "    Y[i]=Y[i][0:len_classes[i]]\n",
    "\n",
    "Train=[]\n",
    "Valid=[]\n",
    "Test=[]\n",
    "TVT=[Train,Valid,Test]\n",
    "Y_Train=[]\n",
    "Y_Valid=[]\n",
    "Y_Test=[]\n",
    "Y_TVT=[Y_Train,Y_Valid,Y_Test]\n",
    "\n",
    "bounds=[0,0.64,0.8,1]\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        keeped=classes[j][int(bounds[i]*len_classes[j]):int(bounds[i+1]*len_classes[j])]\n",
    "        keeped_Y=Y[j][int(bounds[i]*len_classes[j]):int(bounds[i+1]*len_classes[j])]\n",
    "        if(i==0):\n",
    "            keeped=keeped[0:int(len(keeped)/2)]\n",
    "            keeped_Y=keeped_Y[0:int(len(keeped_Y)/2)]                 \n",
    "        TVT[i]+=keeped\n",
    "        Y_TVT[i]+=keeped_Y\n",
    "        \n",
    "Augmented=[]\n",
    "Y_Augmented=[]\n",
    "\n",
    "for i in range(len(Train)):\n",
    "    augmentation(Train[i],Y_Train[i],Augmented,Y_Augmented)\n",
    "\n",
    "print(len(Train))\n",
    "\n",
    "TVT[0]=Augmented\n",
    "Y_TVT[0]=Y_Augmented\n",
    "TVT[0],Y_TVT[0]=shuffle(TVT[0],Y_TVT[0])\n",
    "\n",
    "for i in range(3):\n",
    "    TVT[i]=normalize(TVT[i])\n",
    "    TVT[i]=TVT[i].reshape(-1,200,200,1)\n",
    "    Y_TVT[i]=keras.utils.to_categorical(Y_TVT[i],3)\n",
    "\n",
    "print(len(Augmented))\n",
    "\n",
    "# epoch=32 steps_per_epoch=32\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train(epochs_num,batch_len,conv_neurons,art_neurons):\n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(200,200,1))\n",
    "        hidden=Inp\n",
    "        for conv_neuron in conv_neurons:\n",
    "            hidden=layers.Conv2D(conv_neuron,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            #hidden=layers.BatchNormalization()(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=100*100\n",
    "        w=math.sqrt(inputs)\n",
    "        for art_neuron in art_neurons:\n",
    "            hidden=layers.Dense(art_neuron,activation='relu',kernel_regularizer=regularizers.L2(0.0001))(hidden)\n",
    "            hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=30\n",
    "            w=math.sqrt(inputs)\n",
    "        output=layers.Dense(3,activation='softmax',kernel_regularizer=regularizers.L2(0.0001))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=20,restore_best_weights=True,mode='max')\n",
    "    model=mlp_model()\n",
    "    model.fit(TVT[0],Y_TVT[0],validation_data=(TVT[1],Y_TVT[1]),epochs=epochs_num,batch_size=batch_len,callbacks=[callback],verbose=1)\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(TVT[2], Y_TVT[2],verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])\n",
    "    \n",
    "train(100,75,[2 for i in range(4)],[40,30])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d526967",
   "metadata": {},
   "source": [
    "#### We dropped data.That was wrong.Next step we will use VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db6d893a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " fc1 (Dense)                 (None, 4096)              102764544 \n",
      "                                                                 \n",
      " fc2 (Dense)                 (None, 4096)              16781312  \n",
      "                                                                 \n",
      " predictions (Dense)         (None, 1000)              4097000   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "model = VGG16()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "562c04f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "INFO:tensorflow:Assets written to: ram://bdcfa5d2-423b-430f-931b-a2d5fcf909c5/assets\n",
      "Stored 'model' (Functional)\n"
     ]
    }
   ],
   "source": [
    "%store model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7bebe4e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "path='chest_xray_lower_dim224x224'\n",
    "old_path='chest_xray_lower_dim/'\n",
    "isExist = os.path.exists(path)\n",
    "if not isExist:\n",
    "    os.makedirs(path)\n",
    "import cv2\n",
    "import glob\n",
    "files=glob.glob('chest_xray_lower_dim/*.jpeg')\n",
    "dataset=[]\n",
    "labels=[]\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "for file in files:\n",
    "    img=Image.open(file)\n",
    "    img=img.convert(mode='L')#too much information without reason x-rays are BlackWhite\n",
    "    img=img.resize((224,224))#we try to stop curse of dimensionality\n",
    "    img.save('chest_xray_lower_dim224x224/'+file[len(old_path):])\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cef5066e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1493, 2780, 1583]\n",
      "3747\n",
      "(224, 224, 3)\n",
      "Epoch 1/76\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"D:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"D:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"D:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"D:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"D:\\Anaconda\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"D:\\Anaconda\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"D:\\Anaconda\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"D:\\Anaconda\\lib\\site-packages\\keras\\losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"D:\\Anaconda\\lib\\site-packages\\keras\\backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 3) and (None, 1000) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 125>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, score[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    123\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m,score[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m--> 125\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m76\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(epochs_num, batch_len)\u001b[0m\n\u001b[0;32m    115\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcategorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m,optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,metrics\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mCategoricalAccuracy())\n\u001b[0;32m    116\u001b[0m callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 117\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTVT\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_TVT\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mTVT\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_TVT\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs_num\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m          \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[38;5;66;03m#model.load_weights(\"weights.hdf5\")\u001b[39;00m\n\u001b[0;32m    120\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m---> 67\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     69\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mD:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1147\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m   1148\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"D:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"D:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"D:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"D:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"D:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"D:\\Anaconda\\lib\\site-packages\\keras\\engine\\compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"D:\\Anaconda\\lib\\site-packages\\keras\\losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"D:\\Anaconda\\lib\\site-packages\\keras\\losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"D:\\Anaconda\\lib\\site-packages\\keras\\losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"D:\\Anaconda\\lib\\site-packages\\keras\\backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 3) and (None, 1000) are incompatible\n"
     ]
    }
   ],
   "source": [
    "def process(X,file):\n",
    "    img=cv2.imread(file)\n",
    "    X.append(img)\n",
    "    #write your code\n",
    "\n",
    "def normalize(dataset):\n",
    "    dataset=asarray(dataset).astype('float32')\n",
    "    dataset=dataset/255.0\n",
    "    return dataset\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "import skimage\n",
    "from skimage import transform\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rescale\n",
    "import cv2\n",
    "import glob\n",
    "import random as ra\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import utils\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "import math\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "Normal=[]\n",
    "Bacterial=[]\n",
    "Virus=[]\n",
    "classes=[Virus,Bacterial,Normal]\n",
    "Y_Normal=[]\n",
    "Y_Bacterial=[]\n",
    "Y_Virus=[]\n",
    "Y=[Y_Normal,Y_Bacterial,Y_Virus]\n",
    "files=glob.glob('chest_xray_lower_dim224x224/*.jpeg')\n",
    "ra.shuffle(files)\n",
    "for file in files:\n",
    "    k=-1\n",
    "    if \"virus\" in file:\n",
    "        k=0\n",
    "    elif \"bacteria\" in file:\n",
    "        k=1\n",
    "    else:\n",
    "        k=2\n",
    "    Y[k].append(str(k))\n",
    "    process(classes[k],file)\n",
    "    \n",
    "len_classes=[]\n",
    "for class_ in classes:\n",
    "    len_classes.append(len(class_))\n",
    "print(len_classes)\n",
    "same_length=min(len_classes)\n",
    "evenly=False\n",
    "\n",
    "if evenly:\n",
    "    for i in range(3):\n",
    "        len_classes[i]=same_length\n",
    "\n",
    "for i in range(3):\n",
    "    classes[i]=classes[i][0:len_classes[i]]\n",
    "for i in range(3):\n",
    "    Y[i]=Y[i][0:len_classes[i]]\n",
    "\n",
    "Train=[]\n",
    "Valid=[]\n",
    "Test=[]\n",
    "TVT=[Train,Valid,Test]\n",
    "Y_Train=[]\n",
    "Y_Valid=[]\n",
    "Y_Test=[]\n",
    "Y_TVT=[Y_Train,Y_Valid,Y_Test]\n",
    "\n",
    "bounds=[0,0.64,0.8,1]\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        keeped=classes[j][int(bounds[i]*len_classes[j]):int(bounds[i+1]*len_classes[j])]\n",
    "        keeped_Y=Y[j][int(bounds[i]*len_classes[j]):int(bounds[i+1]*len_classes[j])]               \n",
    "        TVT[i]+=keeped\n",
    "        Y_TVT[i]+=keeped_Y\n",
    "        \n",
    "print(len(Train))\n",
    "\n",
    "print(np.shape(TVT[0][0]))\n",
    "\n",
    "TVT[0],Y_TVT[0]=shuffle(TVT[0],Y_TVT[0])\n",
    "\n",
    "for i in range(3):\n",
    "    TVT[i]=normalize(TVT[i])\n",
    "    #TVT[i]=TVT[i].reshape(-1,224,224,3)\n",
    "    Y_TVT[i]=keras.utils.to_categorical(Y_TVT[i],3)\n",
    "\n",
    "\n",
    "# epoch=32 steps_per_epoch=32\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "def train(epochs_num,batch_len):\n",
    "    \n",
    "    \n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=tf.keras.metrics.CategoricalAccuracy())\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4,mode='max')\n",
    "    model.fit(TVT[0],Y_TVT[0],validation_data=(TVT[1],Y_TVT[1]),epochs=epochs_num,\n",
    "              batch_size=batch_len,callbacks=[callback],verbose=1)\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(TVT[2], Y_TVT[2],verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])\n",
    "    \n",
    "train(76,256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29fdf63",
   "metadata": {},
   "source": [
    "#### Try with ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97e43522",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "bad operand type for unary -: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 62>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m3\u001b[39m):\n\u001b[1;32m     71\u001b[0m         Y[k]\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(k))\n\u001b[0;32m---> 72\u001b[0m     \u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdatagen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m len_classes\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m class_ \u001b[38;5;129;01min\u001b[39;00m classes:\n",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36mprocess\u001b[0;34m(X, file, gen)\u001b[0m\n\u001b[1;32m     45\u001b[0m it\u001b[38;5;241m=\u001b[39mgen\u001b[38;5;241m.\u001b[39mflow(img_array, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m---> 47\u001b[0m     batch\u001b[38;5;241m=\u001b[39m\u001b[43mit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     X\u001b[38;5;241m.\u001b[39mappend(load_img(batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muint8\u001b[39m\u001b[38;5;124m\"\u001b[39m)),color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrayscale\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/notebook/jupyterenv/lib/python3.10/site-packages/keras/preprocessing/image.py:160\u001b[0m, in \u001b[0;36mIterator.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    157\u001b[0m   index_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex_generator)\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# The transformation of images is not under thread lock\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# so it can be done in parallel\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_batches_of_transformed_samples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex_array\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/notebook/jupyterenv/lib/python3.10/site-packages/keras/preprocessing/image.py:708\u001b[0m, in \u001b[0;36mNumpyArrayIterator._get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(index_array):\n\u001b[1;32m    707\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx[j]\n\u001b[0;32m--> 708\u001b[0m   params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_data_generator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_random_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    709\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_data_generator\u001b[38;5;241m.\u001b[39mapply_transform(\n\u001b[1;32m    710\u001b[0m       x\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype), params)\n\u001b[1;32m    711\u001b[0m   x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_data_generator\u001b[38;5;241m.\u001b[39mstandardize(x)\n",
      "File \u001b[0;32m~/notebook/jupyterenv/lib/python3.10/site-packages/keras/preprocessing/image.py:1707\u001b[0m, in \u001b[0;36mImageDataGenerator.get_random_transform\u001b[0;34m(self, img_shape, seed)\u001b[0m\n\u001b[1;32m   1704\u001b[0m   np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[1;32m   1706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotation_range:\n\u001b[0;32m-> 1707\u001b[0m   theta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39muniform(\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrotation_range\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotation_range)\n\u001b[1;32m   1708\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1709\u001b[0m   theta \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: bad operand type for unary -: 'list'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import random as ra\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import utils\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "import math\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import load_img,img_to_array\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=[10,20],\n",
    "        zoom_range=[-0.2,0.2],\n",
    "        fill_mode=\"reflect\",\n",
    "        horizontal_flip=True\n",
    "    )\n",
    "\n",
    "def process(X,file,gen):\n",
    "    img=load_img(\n",
    "        file,color_mode=\"grayscale\"\n",
    "    )\n",
    "    X.append(img)\n",
    "    \n",
    "    img_array = img_to_array(img)\n",
    "    img_array = img_array.reshape((1,) + img_array.shape)\n",
    "    it=gen.flow(img_array, batch_size=3)\n",
    "    for i in range(2):\n",
    "        batch=it.next()\n",
    "        X.append(load_img(batch[0].astype(\"uint8\")),color_mode=\"grayscale\")\n",
    "    \n",
    "    \n",
    "\n",
    "Normal=[]\n",
    "Bacterial=[]\n",
    "Virus=[]\n",
    "classes=[Virus,Bacterial,Normal]\n",
    "Y_Normal=[]\n",
    "Y_Bacterial=[]\n",
    "Y_Virus=[]\n",
    "Y=[Y_Normal,Y_Bacterial,Y_Virus]\n",
    "files=glob.glob('chest_xray_lower_dim2'+'/*.jpeg')\n",
    "ra.shuffle(files)\n",
    "for file in files:\n",
    "    k=-1\n",
    "    if \"virus\" in file:\n",
    "        k=0\n",
    "    elif \"bacteria\" in file:\n",
    "        k=1\n",
    "    else:\n",
    "        k=2\n",
    "    for i in range(3):\n",
    "        Y[k].append(str(k))\n",
    "    process(classes[k],file,datagen)\n",
    "    \n",
    "len_classes=[]\n",
    "for class_ in classes:\n",
    "    len_classes.append(len(class_))\n",
    "print(len_classes)\n",
    "same_length=min(len_classes)\n",
    "evenly=False\n",
    "\n",
    "if evenly:\n",
    "    for i in range(3):\n",
    "        len_classes[i]=same_length\n",
    "\n",
    "for i in range(3):\n",
    "    classes[i]=classes[i][0:len_classes[i]]\n",
    "for i in range(3):\n",
    "    Y[i]=Y[i][0:len_classes[i]]\n",
    "\n",
    "Train=[]\n",
    "Valid=[]\n",
    "Test=[]\n",
    "TVT=[Train,Valid,Test]\n",
    "Y_Train=[]\n",
    "Y_Valid=[]\n",
    "Y_Test=[]\n",
    "Y_TVT=[Y_Train,Y_Valid,Y_Test]\n",
    "\n",
    "bounds=[0,0.64,0.8,1]\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        TVT[i]+=classes[j][int(bounds[i]*len_classes[j]):int(bounds[i+1]*len_classes[j])]\n",
    "        Y_TVT[i]+=Y[j][int(bounds[i]*len_classes[j]):int(bounds[i+1]*len_classes[j])]\n",
    "    Y_TVT[i]=keras.utils.to_categorical(Y_TVT[i],3)\n",
    "\n",
    "#train_datagen.fit(Train)\n",
    "#validation_datagen.fit(Valid)\n",
    "#test_datagen.fit(Test)\n",
    "\n",
    "def train(epochs_num,batch_len,conv_neurons,art_neurons):\n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for conv_neuron in conv_neurons:\n",
    "            hidden=layers.Conv2D(conv_neuron,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=100*100\n",
    "        w=math.sqrt(inputs)\n",
    "        for art_neuron in art_neurons:\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(art_neuron,activation='relu',kernel_regularizer=regularizers.L2(0.0001))(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=30\n",
    "            w=math.sqrt(inputs)\n",
    "        output=layers.Dense(3,activation='softmax',kernel_regularizer=regularizers.L2(0.0001))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4,mode='max')\n",
    "    model=mlp_model()\n",
    "    model.fit(TVT[0],Y_TVT[0],validation_data=(validation_datagen.flow(TVT[1]),Y_TVT[1]),epochs=epochs_num,\n",
    "              batch_size=batch_len,callbacks=[callback],verbose=1)\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(test_datagen.flow(TVT[2]), Y_TVT[2],verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])\n",
    "    \n",
    "train(100,150,[32,64,96],[50,50])\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e0ee04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
