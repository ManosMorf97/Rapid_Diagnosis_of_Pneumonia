{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9e64f138",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (22.1.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c02ac881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (2.9.1)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorflow) (2.9.1)\n",
      "Requirement already satisfied: packaging in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorflow) (21.3)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorflow) (1.12)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorflow) (1.47.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorflow) (4.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorflow) (2.9.0)\n",
      "Requirement already satisfied: setuptools in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorflow) (62.3.2)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorflow) (1.22.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (2.28.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from tensorboard<2.10,>=2.9->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from packaging->tensorflow) (3.0.9)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.2.0)\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (60.9 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.9/60.9 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21.2 in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (from opencv-python) (1.22.4)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.6.0.66\n",
      "Requirement already satisfied: pillow in /home/manos/notebook/jupyterenv/lib/python3.10/site-packages (9.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow\n",
    "!pip install opencv-python    \n",
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97e43522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-25 20:34:28.605235: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/manos/notebook/jupyterenv/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-06-25 20:34:28.605298: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1493, 2780, 1583]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-25 20:36:20.040460: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/manos/notebook/jupyterenv/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2022-06-25 20:36:20.062502: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-06-25 20:36:20.076751: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (manos-Lenovo-G50-70): /proc/driver/nvidia/version does not exist\n",
      "2022-06-25 20:36:20.552657: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`x` (images tensor) and `y` (labels) should have the same length. Found: x.shape = (100, 100, 3), y.shape = (3747, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 144>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest loss:\u001b[39m\u001b[38;5;124m\"\u001b[39m, score[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest accuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m,score[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m--> 144\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m96\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epochs_num, batch_len, conv_neurons, art_neurons)\u001b[0m\n\u001b[1;32m    133\u001b[0m callback \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mcallbacks\u001b[38;5;241m.\u001b[39mEarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    134\u001b[0m model\u001b[38;5;241m=\u001b[39mmlp_model()\n\u001b[0;32m--> 135\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mtrain_datagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTVT\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mY_TVT\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    136\u001b[0m           validation_data\u001b[38;5;241m=\u001b[39m(TVT[\u001b[38;5;241m1\u001b[39m],Y_TVT[\u001b[38;5;241m1\u001b[39m]),epochs\u001b[38;5;241m=\u001b[39mepochs_num,\n\u001b[1;32m    137\u001b[0m           batch_size\u001b[38;5;241m=\u001b[39mbatch_len,callbacks\u001b[38;5;241m=\u001b[39m[callback],verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m#model.load_weights(\"weights.hdf5\")\u001b[39;00m\n\u001b[1;32m    139\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/notebook/jupyterenv/lib/python3.10/site-packages/keras/preprocessing/image.py:1370\u001b[0m, in \u001b[0;36mImageDataGenerator.flow\u001b[0;34m(self, x, y, batch_size, shuffle, sample_weight, seed, save_to_dir, save_prefix, save_format, ignore_class_split, subset)\u001b[0m\n\u001b[1;32m   1316\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflow\u001b[39m(\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1317\u001b[0m          x,\n\u001b[1;32m   1318\u001b[0m          y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1326\u001b[0m          ignore_class_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1327\u001b[0m          subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1328\u001b[0m   \u001b[38;5;124;03m\"\"\"Takes data & label arrays, generates batches of augmented data.\u001b[39;00m\n\u001b[1;32m   1329\u001b[0m \n\u001b[1;32m   1330\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \n\u001b[1;32m   1369\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1370\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mNumpyArrayIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[43m      \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1372\u001b[0m \u001b[43m      \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m      \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m      \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m      \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1377\u001b[0m \u001b[43m      \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1378\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1379\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1380\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1381\u001b[0m \u001b[43m      \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1382\u001b[0m \u001b[43m      \u001b[49m\u001b[43mignore_class_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_class_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1383\u001b[0m \u001b[43m      \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1384\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/notebook/jupyterenv/lib/python3.10/site-packages/keras/preprocessing/image.py:637\u001b[0m, in \u001b[0;36mNumpyArrayIterator.__init__\u001b[0;34m(self, x, y, image_data_generator, batch_size, shuffle, sample_weight, seed, data_format, save_to_dir, save_prefix, save_format, subset, ignore_class_split, dtype)\u001b[0m\n\u001b[1;32m    634\u001b[0m   x_misc \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(y):\n\u001b[0;32m--> 637\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`x` (images tensor) and `y` (labels) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    638\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshould have the same length. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    639\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFound: x.shape = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, y.shape = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    640\u001b[0m                    (np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mshape, np\u001b[38;5;241m.\u001b[39masarray(y)\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(sample_weight):\n\u001b[1;32m    642\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`x` (images tensor) and `sample_weight` \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    643\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mshould have the same length. \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    644\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFound: x.shape = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, sample_weight.shape = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    645\u001b[0m                    (np\u001b[38;5;241m.\u001b[39masarray(x)\u001b[38;5;241m.\u001b[39mshape, np\u001b[38;5;241m.\u001b[39masarray(sample_weight)\u001b[38;5;241m.\u001b[39mshape))\n",
      "\u001b[0;31mValueError\u001b[0m: `x` (images tensor) and `y` (labels) should have the same length. Found: x.shape = (100, 100, 3), y.shape = (3747, 3)"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import random as ra\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import utils\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "import math\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def process(X,file):\n",
    "    img=tf.keras.preprocessing.image.load_img(\n",
    "        file,color_mode=\"grayscale\", target_size=None, interpolation=\"nearest\"\n",
    "    )\n",
    "    img=cv2.imread(file)\n",
    "    X.append(img)\n",
    "\n",
    "Normal=[]\n",
    "Bacterial=[]\n",
    "Virus=[]\n",
    "classes=[Virus,Bacterial,Normal]\n",
    "Y_Normal=[]\n",
    "Y_Bacterial=[]\n",
    "Y_Virus=[]\n",
    "Y=[Y_Normal,Y_Bacterial,Y_Virus]\n",
    "files=glob.glob('chest_xray_lower_dim2'+'/*.jpeg')\n",
    "ra.shuffle(files)\n",
    "for file in files:\n",
    "    k=-1\n",
    "    if \"virus\" in file:\n",
    "        k=0\n",
    "    elif \"bacteria\" in file:\n",
    "        k=1\n",
    "    else:\n",
    "        k=2\n",
    "    Y[k].append(str(k))\n",
    "    process(classes[k],file)\n",
    "    \n",
    "len_classes=[]\n",
    "for class_ in classes:\n",
    "    len_classes.append(len(class_))\n",
    "print(len_classes)\n",
    "same_length=min(len_classes)\n",
    "evenly=False\n",
    "\n",
    "if evenly:\n",
    "    for i in range(3):\n",
    "        len_classes[i]=same_length\n",
    "\n",
    "for i in range(3):\n",
    "    classes[i]=classes[i][0:len_classes[i]]\n",
    "for i in range(3):\n",
    "    Y[i]=Y[i][0:len_classes[i]]\n",
    "\n",
    "Train=[]\n",
    "Valid=[]\n",
    "Test=[]\n",
    "TVT=[Train,Valid,Test]\n",
    "Y_Train=[]\n",
    "Y_Valid=[]\n",
    "Y_Test=[]\n",
    "Y_TVT=[Y_Train,Y_Valid,Y_Test]\n",
    "\n",
    "bounds=[0,0.64,0.8,1]\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        TVT[i]+=classes[j][int(bounds[i]*len_classes[j]):int(bounds[i+1]*len_classes[j])]\n",
    "        Y_TVT[i]+=Y[j][int(bounds[i]*len_classes[j]):int(bounds[i+1]*len_classes[j])]\n",
    "    Y_TVT[i]=keras.utils.to_categorical(Y_TVT[i],3)\n",
    "    \n",
    "\n",
    "train_datagen=tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization=True,\n",
    "        rescale=1./255,\n",
    "        zoom_range=[-0.2,0.2],\n",
    "        rotation_range=[-20,20],\n",
    "        horizontal_flip=True)\n",
    "validation_datagen=tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "test_datagen =tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_datagen.fit(Train)\n",
    "validation_datagen.fit(Valid)\n",
    "test_datagen.fit(Test)\n",
    "\n",
    "def train(epochs_num,batch_len,conv_neurons,art_neurons):\n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,3))\n",
    "        hidden=Inp\n",
    "        for conv_neuron in conv_neurons:\n",
    "            hidden=layers.Conv2D(conv_neuron,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=100*100\n",
    "        w=math.sqrt(inputs)\n",
    "        for art_neuron in art_neurons:\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(art_neuron,activation='relu',kernel_regularizer=regularizers.L2(0.0001))(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=30\n",
    "            w=math.sqrt(inputs)\n",
    "        output=layers.Dense(3,activation='softmax',kernel_regularizer=regularizers.L2(0.0001))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4,mode='max')\n",
    "    model=mlp_model()\n",
    "    model.fit(train_datagen.flow(TVT[0],Y_TVT[0],batch_size=32,subset='training'),\n",
    "              validation_data=(TVT[1],Y_TVT[1]),epochs=epochs_num,\n",
    "              batch_size=batch_len,callbacks=[callback],verbose=1)\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(TVT[2], Y_TVT[2],verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])\n",
    "    \n",
    "train(100,150,[32,64,96],[50,50])\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e0ee04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
