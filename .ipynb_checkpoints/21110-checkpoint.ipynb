{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3c50baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in d:\\anaconda\\lib\\site-packages (21.2.4)\n",
      "Collecting pip\n",
      "  Downloading pip-22.1-py3-none-any.whl (2.1 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 21.2.4\n",
      "    Uninstalling pip-21.2.4:\n",
      "      Successfully uninstalled pip-21.2.4\n",
      "Successfully installed pip-22.1\n",
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.5.64-cp36-abi3-win_amd64.whl (35.4 MB)\n",
      "     -------------------------------------- 35.4/35.4 MB 242.6 kB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.14.5 in d:\\anaconda\\lib\\site-packages (from opencv-python) (1.21.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.5.64\n",
      "Requirement already satisfied: pillow in d:\\anaconda\\lib\\site-packages (9.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install opencv-python    \n",
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c3e8c6",
   "metadata": {},
   "source": [
    "# First we reduce dimensions because the data are very big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7088674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to anaconda prompt: jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\n",
    "# jupyter notebook --notebook-dir=D:/\n",
    "from PIL import Image\n",
    "import os\n",
    "path='chest_xray_lower_dim'\n",
    "old_path='chest_xray/'\n",
    "isExist = os.path.exists(path)\n",
    "if not isExist:\n",
    "    os.makedirs(path)\n",
    "import cv2\n",
    "import glob\n",
    "files=glob.glob('chest_xray/*.jpeg')\n",
    "dataset=[]\n",
    "labels=[]\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "for file in files:\n",
    "    img=Image.open(file)\n",
    "    img=img.convert(mode='L')#too much information without reason x-rays are BlackWhite\n",
    "    img=img.resize((400,400))#we try to stop curse of dimensionality\n",
    "    img.save('chest_xray_lower_dim/'+file[len(old_path):])\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cac95d3",
   "metadata": {},
   "source": [
    "### The data has lower dimension but it takes too long to process them so we reduce to 100x100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c0a862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "# write to anaconda prompt: jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10\n",
    "from PIL import Image\n",
    "import os\n",
    "path='chest_xray_lower_dim2'\n",
    "old_path='chest_xray_lower_dim/'\n",
    "isExist = os.path.exists(path)\n",
    "if not isExist:\n",
    "    os.makedirs(path)\n",
    "import cv2\n",
    "import glob\n",
    "files=glob.glob('chest_xray_lower_dim/*.jpeg')\n",
    "dataset=[]\n",
    "labels=[]\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import cv2\n",
    "for file in files:\n",
    "    img=Image.open(file)\n",
    "    img=img.convert(mode='L')#too much information without reason x-rays are BlackWhite\n",
    "    img=img.resize((100,100))#we try to stop curse of dimensionality\n",
    "    img.save('chest_xray_lower_dim2/'+file[len(old_path):])\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ec21c4",
   "metadata": {},
   "source": [
    "### Afterwards we create the dataset with the labels and we will try to make a prediction system about these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52a05f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#before work\n",
    "import cv2\n",
    "import glob\n",
    "files=glob.glob('chest_xray_lower_dim2/*.jpeg')\n",
    "dataset=[]\n",
    "labels=[]\n",
    "for file in files:\n",
    "    img=cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n",
    "    dataset.append(img)\n",
    "    #write your code\n",
    "    if \"virus\" in file:\n",
    "        labels.append(\"0\")\n",
    "    elif \"bacteria\" in file:\n",
    "        labels.append(\"1\")\n",
    "    else:\n",
    "        labels.append(\"2\")\n",
    "        \n",
    "from numpy import asarray\n",
    "dataset=asarray(dataset).astype('float32')\n",
    "dataset=dataset/255.0\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import utils\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2e90bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.8.0-cp39-cp39-win_amd64.whl (438.0 MB)\n",
      "     -------------------------------------- 438.0/438.0 MB 1.4 MB/s eta 0:00:00\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.25.0-cp39-cp39-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 1.5/1.5 MB 3.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\anaconda\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting keras<2.9,>=2.8.0rc0\n",
      "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
      "     ---------------------------------------- 1.4/1.4 MB 2.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wrapt>=1.11.0 in d:\\anaconda\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "     ---------------------------------------- 42.6/42.6 kB 2.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.20 in d:\\anaconda\\lib\\site-packages (from tensorflow) (1.21.5)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 57.5/57.5 kB 3.1 MB/s eta 0:00:00\n",
      "Collecting flatbuffers>=1.12\n",
      "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\anaconda\\lib\\site-packages (from tensorflow) (4.1.1)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\anaconda\\lib\\site-packages (from tensorflow) (3.6.0)\n",
      "Collecting tensorboard<2.9,>=2.8\n",
      "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
      "     ---------------------------------------- 5.8/5.8 MB 2.5 MB/s eta 0:00:00\n",
      "Collecting libclang>=9.0.1\n",
      "  Downloading libclang-14.0.1-py2.py3-none-win_amd64.whl (14.2 MB)\n",
      "     ---------------------------------------- 14.2/14.2 MB 3.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\anaconda\\lib\\site-packages (from tensorflow) (1.42.0)\n",
      "Collecting absl-py>=0.4.0\n",
      "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "     -------------------------------------- 126.7/126.7 kB 2.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: protobuf>=3.9.2 in d:\\anaconda\\lib\\site-packages (from tensorflow) (3.19.1)\n",
      "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
      "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
      "     -------------------------------------- 462.5/462.5 kB 2.9 MB/s eta 0:00:00\n",
      "Collecting gast>=0.2.1\n",
      "  Downloading gast-0.5.3-py3-none-any.whl (19 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 65.5/65.5 kB 3.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: setuptools in d:\\anaconda\\lib\\site-packages (from tensorflow) (61.2.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\anaconda\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.27.1)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "     -------------------------------------- 781.3/781.3 kB 3.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.0.3)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.33.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\anaconda\\lib\\site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.4)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in d:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\anaconda\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.7.2)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\anaconda\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.3)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in d:\\anaconda\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
      "     -------------------------------------- 151.5/151.5 kB 4.6 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: termcolor\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4848 sha256=ffc7122282abd4cc487411daee43288a28d7d3662812d48789668cc4ddf30c53\n",
      "  Stored in directory: c:\\users\\manos\\appdata\\local\\pip\\cache\\wheels\\b6\\0d\\90\\0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
      "Successfully built termcolor\n",
      "Installing collected packages: tf-estimator-nightly, termcolor, tensorboard-plugin-wit, libclang, keras, flatbuffers, tensorflow-io-gcs-filesystem, tensorboard-data-server, opt-einsum, oauthlib, keras-preprocessing, google-pasta, gast, astunparse, absl-py, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 flatbuffers-2.0 gast-0.5.3 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 keras-2.8.0 keras-preprocessing-1.1.2 libclang-14.0.1 oauthlib-3.2.0 opt-einsum-3.3.0 requests-oauthlib-1.3.1 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.25.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941e997e",
   "metadata": {},
   "source": [
    "#### First try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87c84d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 98, 98, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 49, 49, 10)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 47, 47, 10)        910       \n",
      "                                                                 \n",
      " average_pooling2d_9 (Averag  (None, 23, 23, 10)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 5290)              0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 30)                158730    \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_61 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 163,553\n",
      "Trainable params: 163,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "37/37 [==============================] - 1s 28ms/step - loss: 0.5456 - accuracy: 0.7543\n",
      "Test loss: 0.5455935597419739\n",
      "Test accuracy: 0.7542662024497986\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "dataset, labels, test_size=0.2, random_state=42)\n",
    "X_train=X_train.reshape(-1,100,100,1)\n",
    "X_test=X_test.reshape(-1,100,100,1)\n",
    "Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "Inp=layers.Input(shape=(100,100,1))\n",
    "hidden=layers.Conv2D(10,kernel_size=(3,3),padding='valid',activation='relu')(Inp)\n",
    "hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "hidden=layers.Conv2D(10,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "hidden=layers.AveragePooling2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "hidden=layers.Flatten()(hidden)\n",
    "for i in range(5):\n",
    "    hidden=layers.Dense(30,activation=\"relu\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/76.4, maxval=1/76.4, seed=None))(hidden)\n",
    "output=layers.Dense(3,activation=\"softmax\")(hidden)\n",
    "model=keras.Model(Inp,output)\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=tf.keras.metrics.CategoricalAccuracy())\n",
    "model.fit(X_train,Y_train,epochs=int(len(X_train)/200),batch_size=200,verbose=0)\n",
    "model.summary()\n",
    "score = model.evaluate(X_test, Y_test,verbose=2)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc0c573b",
   "metadata": {},
   "source": [
    "#### let's test it with 10 layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3edd4baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 98, 98, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 49, 49, 10)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 47, 47, 10)        910       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 23, 23, 10)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5290)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 30)                158730    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 168,203\n",
      "Trainable params: 168,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 1.0662 - categorical_accuracy: 0.4565\n",
      "Test loss: 1.0662440061569214\n",
      "Test accuracy: 0.4564846456050873\n"
     ]
    }
   ],
   "source": [
    "#με αυτό το score για 2η φάση α\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "dataset, labels, test_size=0.2, random_state=42)\n",
    "X_train=X_train.reshape(-1,100,100,1)\n",
    "X_test=X_test.reshape(-1,100,100,1)\n",
    "Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "Inp=layers.Input(shape=(100,100,1))\n",
    "hidden=layers.Conv2D(10,kernel_size=(3,3),padding='valid',activation='relu')(Inp)\n",
    "hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "hidden=layers.Conv2D(10,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "hidden=layers.AveragePooling2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "hidden=layers.Flatten()(hidden)\n",
    "for i in range(10):\n",
    "    hidden=layers.Dense(30,activation=\"relu\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/76.4, maxval=1/76.4, seed=None))(hidden)\n",
    "output=layers.Dense(3,activation=\"softmax\")(hidden)\n",
    "model=keras.Model(Inp,output)\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=tf.keras.metrics.CategoricalAccuracy())\n",
    "model.fit(X_train,Y_train,epochs=int(len(X_train)/100),batch_size=200,verbose=0)\n",
    "model.summary()\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c9430e",
   "metadata": {},
   "source": [
    "#### That was worst,lets reduce the neurons to 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8f980df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 98, 98, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 49, 49, 10)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 47, 47, 10)        910       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 23, 23, 10)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5290)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 30)                158730    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,693\n",
      "Trainable params: 161,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 0.4992 - categorical_accuracy: 0.7816\n",
      "Test loss: 0.499212384223938\n",
      "Test accuracy: 0.7815699577331543\n"
     ]
    }
   ],
   "source": [
    "#με αυτό το score για 2η φάση α\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "dataset, labels, test_size=0.2, random_state=42)\n",
    "X_train=X_train.reshape(-1,100,100,1)\n",
    "X_test=X_test.reshape(-1,100,100,1)\n",
    "Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "Inp=layers.Input(shape=(100,100,1))\n",
    "hidden=layers.Conv2D(10,kernel_size=(3,3),padding='valid',activation='relu')(Inp)\n",
    "hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "hidden=layers.Conv2D(10,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "hidden=layers.AveragePooling2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "hidden=layers.Flatten()(hidden)\n",
    "for i in range(3):\n",
    "    hidden=layers.Dense(30,activation=\"relu\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/76.4, maxval=1/76.4, seed=None))(hidden)\n",
    "output=layers.Dense(3,activation=\"softmax\")(hidden)\n",
    "model=keras.Model(Inp,output)\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=tf.keras.metrics.CategoricalAccuracy())\n",
    "model.fit(X_train,Y_train,epochs=int(len(X_train)/100),batch_size=200,verbose=0)\n",
    "model.summary()\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e4fc7f",
   "metadata": {},
   "source": [
    "### Three layers are good let's test the number of neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04c5ec32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 98, 98, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 49, 49, 10)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 47, 47, 10)        910       \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 23, 23, 10)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 5290)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 60)                317460    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 60)                3660      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 183       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 325,973\n",
      "Trainable params: 325,973\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "37/37 [==============================] - 1s 22ms/step - loss: 0.5196 - categorical_accuracy: 0.7790\n",
      "Test loss: 0.5195930004119873\n",
      "Test accuracy: 0.7790102362632751\n"
     ]
    }
   ],
   "source": [
    "#3 layers is good lets see number of neurons\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "dataset, labels, test_size=0.2, random_state=42)\n",
    "X_train=X_train.reshape(-1,100,100,1)\n",
    "X_test=X_test.reshape(-1,100,100,1)\n",
    "Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "Inp=layers.Input(shape=(100,100,1))\n",
    "hidden=layers.Conv2D(10,kernel_size=(3,3),padding='valid',activation='relu')(Inp)\n",
    "hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "hidden=layers.Conv2D(10,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "hidden=layers.AveragePooling2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "hidden=layers.Flatten()(hidden)\n",
    "for i in range(3):\n",
    "    hidden=layers.Dense(60,activation=\"relu\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/76.4, maxval=1/76.4, seed=None))(hidden)\n",
    "output=layers.Dense(3,activation=\"softmax\")(hidden)\n",
    "model=keras.Model(Inp,output)\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=tf.keras.metrics.CategoricalAccuracy())\n",
    "model.fit(X_train,Y_train,epochs=int(len(X_train)/100),batch_size=200,verbose=0)\n",
    "model.summary()\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ded9f7d",
   "metadata": {},
   "source": [
    "#### let's make function to avoid repeated code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abd6f839",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 layers is good lets see number of neurons\n",
    "def train_neurons(neurons):\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "    dataset, labels, test_size=0.2, random_state=42)\n",
    "    X_train=X_train.reshape(-1,100,100,1)\n",
    "    X_test=X_test.reshape(-1,100,100,1)\n",
    "    Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "    Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "    Inp=layers.Input(shape=(100,100,1))\n",
    "    hidden=layers.Conv2D(10,kernel_size=(3,3),padding='valid',activation='relu')(Inp)\n",
    "    hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "    hidden=layers.Conv2D(10,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "    hidden=layers.AveragePooling2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "    hidden=layers.Flatten()(hidden)\n",
    "    for i in range(3):\n",
    "        hidden=layers.Dense(neurons,activation=\"relu\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/76.4, maxval=1/76.4, seed=None))(hidden)\n",
    "    output=layers.Dense(3,activation=\"softmax\")(hidden)\n",
    "    model=keras.Model(Inp,output)\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=tf.keras.metrics.CategoricalAccuracy())\n",
    "    model.fit(X_train,Y_train,epochs=int(len(X_train)/100),batch_size=200,verbose=0)\n",
    "    model.summary()\n",
    "    score = model.evaluate(X_test, Y_test)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\", score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "17b18012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 98, 98, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 49, 49, 10)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 47, 47, 10)        910       \n",
      "                                                                 \n",
      " average_pooling2d_2 (Averag  (None, 23, 23, 10)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 5290)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 40)                211640    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 40)                1640      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 123       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 216,053\n",
      "Trainable params: 216,053\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "37/37 [==============================] - 1s 20ms/step - loss: 0.5431 - categorical_accuracy: 0.7722\n",
      "Test loss: 0.5431237816810608\n",
      "Test accuracy: 0.7721843123435974\n"
     ]
    }
   ],
   "source": [
    "train_neurons(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6223a5a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 98, 98, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 49, 49, 10)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 47, 47, 10)        910       \n",
      "                                                                 \n",
      " average_pooling2d_3 (Averag  (None, 23, 23, 10)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 5290)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 20)                105820    \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 20)                420       \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 20)                420       \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 3)                 63        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 107,733\n",
      "Trainable params: 107,733\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.5196 - categorical_accuracy: 0.7637\n",
      "Test loss: 0.5195580124855042\n",
      "Test accuracy: 0.7636518478393555\n"
     ]
    }
   ],
   "source": [
    "train_neurons(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45934876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 98, 98, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 49, 49, 10)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 47, 47, 10)        910       \n",
      "                                                                 \n",
      " average_pooling2d_4 (Averag  (None, 23, 23, 10)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 5290)              0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 35)                185185    \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 35)                1260      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 35)                1260      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 3)                 108       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 188,823\n",
      "Trainable params: 188,823\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "37/37 [==============================] - 1s 23ms/step - loss: 0.5485 - categorical_accuracy: 0.7628\n",
      "Test loss: 0.5485417246818542\n",
      "Test accuracy: 0.7627986073493958\n"
     ]
    }
   ],
   "source": [
    "train_neurons(35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eaf882",
   "metadata": {},
   "source": [
    "##### We quess that 30 neurons are better,let's test the learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92de0c37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 98, 98, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 49, 49, 10)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 47, 47, 10)        910       \n",
      "                                                                 \n",
      " average_pooling2d_6 (Averag  (None, 23, 23, 10)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 5290)              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 30)                158730    \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,693\n",
      "Trainable params: 161,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.8467 - categorical_accuracy: 0.7526\n",
      "Test loss: 0.8467274904251099\n",
      "Test accuracy: 0.7525597214698792\n"
     ]
    }
   ],
   "source": [
    "#best model has 30 neurons\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "dataset, labels, test_size=0.2, random_state=42)\n",
    "X_train=X_train.reshape(-1,100,100,1)\n",
    "X_test=X_test.reshape(-1,100,100,1)\n",
    "Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "Inp=layers.Input(shape=(100,100,1))\n",
    "hidden=layers.Conv2D(10,kernel_size=(3,3),padding='valid',activation='relu')(Inp)\n",
    "hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "hidden=layers.Conv2D(10,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "hidden=layers.AveragePooling2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "hidden=layers.Flatten()(hidden)\n",
    "for i in range(3):\n",
    "    hidden=layers.Dense(30,activation=\"relu\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/76.4, maxval=1/76.4, seed=None))(hidden)\n",
    "output=layers.Dense(3,activation=\"softmax\")(hidden)\n",
    "model=keras.Model(Inp,output)\n",
    "model.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),metrics=tf.keras.metrics.CategoricalAccuracy())\n",
    "model.fit(X_train,Y_train,epochs=int(len(X_train)/100),batch_size=200,verbose=0)\n",
    "model.summary()\n",
    "score = model.evaluate(X_test, Y_test)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5476010a",
   "metadata": {},
   "source": [
    "#### learning rate is high.Let's reduce it rather than increase it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81e478b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_rate_neurons(neurons,learn):\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "    dataset, labels, test_size=0.2, random_state=42)\n",
    "    X_train=X_train.reshape(-1,100,100,1)\n",
    "    X_test=X_test.reshape(-1,100,100,1)\n",
    "    Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "    Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "    Inp=layers.Input(shape=(100,100,1))\n",
    "    hidden=layers.Conv2D(10,kernel_size=(3,3),padding='valid',activation='relu')(Inp)\n",
    "    hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "    hidden=layers.Conv2D(10,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "    hidden=layers.AveragePooling2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "    hidden=layers.Flatten()(hidden)\n",
    "    for i in range(3):\n",
    "        hidden=layers.Dense(neurons,activation=\"relu\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/76.4, maxval=1/76.4, seed=None))(hidden)\n",
    "    output=layers.Dense(3,activation=\"softmax\")(hidden)\n",
    "    model=keras.Model(Inp,output)\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=learn),metrics=tf.keras.metrics.CategoricalAccuracy())\n",
    "    model.fit(X_train,Y_train,epochs=int(len(X_train)/100),batch_size=200,verbose=0)\n",
    "    model.summary()\n",
    "    score = model.evaluate(X_test, Y_test)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\", score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "159dc359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 98, 98, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 49, 49, 10)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 47, 47, 10)        910       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 23, 23, 10)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5290)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 30)                158730    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,693\n",
      "Trainable params: 161,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "37/37 [==============================] - 1s 24ms/step - loss: 0.6174 - categorical_accuracy: 0.7065\n",
      "Test loss: 0.6174189448356628\n",
      "Test accuracy: 0.7064846158027649\n"
     ]
    }
   ],
   "source": [
    "train_rate_neurons(30,0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003a99a8",
   "metadata": {},
   "source": [
    "#### We think that best learning rate for now is the default"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
