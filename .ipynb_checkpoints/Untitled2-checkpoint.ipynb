{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5b5d42cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage import transform\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rescale\n",
    "import cv2\n",
    "import glob\n",
    "import random as ra\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "def process(X,file):\n",
    "    img=cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n",
    "    X.append(img)\n",
    "    #write your code\n",
    "\n",
    "def normalize(dataset):\n",
    "    dataset=asarray(dataset).astype('float32')\n",
    "    dataset=dataset/255.0\n",
    "    return dataset\n",
    "\n",
    "def augmentation(row,label,Augmented,Y_Augmeneted):\n",
    "    scale_out = skimage.transform.rescale(row, scale=2.0, mode='constant')\n",
    "    scale_out=skimage.transform.resize(scale_out,(100,100))\n",
    "    scale_in = skimage.transform.rescale(row, scale=0.5, mode='constant')\n",
    "    scale_in=skimage.transform.resize(scale_in,(100,100))\n",
    "    images=[row,scale_out,scale_in]\n",
    "    for image in images:\n",
    "        Augmented.append(image)\n",
    "        Y_Augmented.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "48969e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1493, 2780, 1583]\n",
      "1493\n",
      "2865\n",
      "8595\n"
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "from skimage import transform\n",
    "from skimage.transform import resize\n",
    "from skimage.transform import rescale\n",
    "import cv2\n",
    "import glob\n",
    "import random as ra\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from numpy import asarray\n",
    "\n",
    "Normal=[]\n",
    "Bacterial=[]\n",
    "Virus=[]\n",
    "classes=[Virus,Bacterial,Normal]\n",
    "Y_Normal=[]\n",
    "Y_Bacterial=[]\n",
    "Y_Virus=[]\n",
    "Y=[Y_Normal,Y_Bacterial,Y_Virus]\n",
    "files=glob.glob('chest_xray_lower_dim2'+'/*.jpeg')\n",
    "ra.shuffle(files)\n",
    "for file in files:\n",
    "    k=-1\n",
    "    if \"virus\" in file:\n",
    "        k=0\n",
    "    elif \"bacteria\" in file:\n",
    "        k=1\n",
    "    else:\n",
    "        k=2\n",
    "    Y[k].append(str(k))\n",
    "    process(classes[k],file)\n",
    "    \n",
    "len_classes=[]\n",
    "for class_ in classes:\n",
    "    len_classes.append(len(class_))\n",
    "print(len_classes)\n",
    "same_length=min(len_classes)\n",
    "for i in range(3):\n",
    "    classes[i]=classes[i][0:same_length]\n",
    "for i in range(3):\n",
    "    Y[i]=Y[i][0:same_length]\n",
    "print(len(Y[2]))\n",
    "length=len(Y[2])\n",
    "\n",
    "Train=[]\n",
    "Valid=[]\n",
    "Test=[]\n",
    "TVT=[Train,Valid,Test]\n",
    "Y_Train=[]\n",
    "Y_Valid=[]\n",
    "Y_Test=[]\n",
    "Y_TVT=[Y_Train,Y_Valid,Y_Test]\n",
    "\n",
    "bounds=[0,0.64,0.8,1]\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        TVT[i]+=classes[j][int(bounds[i]*same_length):int(bounds[i+1]*same_length)]\n",
    "        Y_TVT[i]+=Y[j][int(bounds[i]*same_length):int(bounds[i+1]*same_length)]\n",
    "        \n",
    "Augmented=[]\n",
    "Y_Augmented=[]\n",
    "\n",
    "for i in range(len(Train)):#3 augmentations so three steps\n",
    "    augmentation(Train[i],Y_Train[i],Augmented,Y_Augmented)\n",
    "\n",
    "print(len(Train))\n",
    "\n",
    "TVT[0]=Augmented\n",
    "Y_TVT[0]=Y_Augmented\n",
    "\n",
    "print(len(Augmented))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "528def0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1493, 1493, 1493]\n",
      "1493\n"
     ]
    }
   ],
   "source": [
    "# epoch=32 steps_per_epoch=32\n",
    "\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        inputs=100*100\n",
    "        w=math.sqrt(inputs)\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation='relu')(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "            inputs=30\n",
    "            w=math.sqrt(inputs)\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation='softmax')(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5,mode='min')\n",
    "    model=mlp_model()\n",
    "    model.fit(TVT[0],Y_TVT[0],validation_data=(TVT[1],Y_TVT[1]),epochs=epochs_num,batch_size=batch_len,callbacks=[callback],verbose=1)\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])\n",
    "    \n",
    "train(100,300,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feac858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
