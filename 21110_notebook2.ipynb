{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "077719c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(directory):\n",
    "    #before work\n",
    "    import cv2\n",
    "    import glob\n",
    "    files=glob.glob(directory+'/*.jpeg')\n",
    "    dataset=[]\n",
    "    labels=[]\n",
    "    for file in files:\n",
    "        img=cv2.imread(file,cv2.IMREAD_GRAYSCALE)\n",
    "        dataset.append(img)\n",
    "        #write your code\n",
    "        if \"virus\" in file:\n",
    "            labels.append(\"0\")\n",
    "        elif \"bacteria\" in file:\n",
    "            labels.append(\"1\")\n",
    "        else:\n",
    "            labels.append(\"2\")\n",
    "\n",
    "    from numpy import asarray\n",
    "    dataset=asarray(dataset).astype('float32')\n",
    "    dataset=dataset/255.0\n",
    "    return dataset,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a969fc57",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset,labels=create_dataset('chest_xray_lower_dim2')\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import utils\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9cf9895a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.title(\"NORMAL\")\n",
    "plt.imshow(dataset[0], cmap='gray')    \n",
    "plt.axis('off')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffa6aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#   score  2  \n",
    "def train(dividor_epoch,batch_len):\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "    dataset, labels, test_size=0.2, random_state=42)\n",
    "    X_train=X_train.reshape(-1,100,100,1)\n",
    "    X_test=X_test.reshape(-1,100,100,1)\n",
    "    Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "    Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "    Inp=layers.Input(shape=(100,100,1))\n",
    "    hidden=layers.Conv2D(10,kernel_size=(3,3),padding='valid',activation='relu')(Inp)\n",
    "    hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "    hidden=layers.Conv2D(10,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "    hidden=layers.AveragePooling2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "    hidden=layers.Flatten()(hidden)\n",
    "    for i in range(3):\n",
    "        hidden=layers.Dense(30,activation=\"relu\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/76.4, maxval=1/76.4, seed=None))(hidden)\n",
    "    output=layers.Dense(3,activation=\"softmax\")(hidden)\n",
    "    model=keras.Model(Inp,output)\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=tf.keras.metrics.CategoricalAccuracy())\n",
    "    model.fit(X_train,Y_train,validation_split=0.2,epochs=int(len(X_train)/dividor_epoch),batch_size=batch_len,verbose=2)\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "265660e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/46\n",
      "19/19 - 15s - loss: 1.0780 - categorical_accuracy: 0.4780 - val_loss: 1.0550 - val_categorical_accuracy: 0.4813 - 15s/epoch - 787ms/step\n",
      "Epoch 2/46\n",
      "19/19 - 10s - loss: 1.0531 - categorical_accuracy: 0.4788 - val_loss: 1.0479 - val_categorical_accuracy: 0.4813 - 10s/epoch - 536ms/step\n",
      "Epoch 3/46\n",
      "19/19 - 10s - loss: 1.0253 - categorical_accuracy: 0.4788 - val_loss: 0.9825 - val_categorical_accuracy: 0.4813 - 10s/epoch - 510ms/step\n",
      "Epoch 4/46\n",
      "19/19 - 10s - loss: 0.9171 - categorical_accuracy: 0.4788 - val_loss: 0.9009 - val_categorical_accuracy: 0.4813 - 10s/epoch - 505ms/step\n",
      "Epoch 5/46\n",
      "19/19 - 10s - loss: 0.8618 - categorical_accuracy: 0.6120 - val_loss: 0.8502 - val_categorical_accuracy: 0.6457 - 10s/epoch - 522ms/step\n",
      "Epoch 6/46\n",
      "19/19 - 9s - loss: 0.8265 - categorical_accuracy: 0.6675 - val_loss: 0.8366 - val_categorical_accuracy: 0.6233 - 9s/epoch - 451ms/step\n",
      "Epoch 7/46\n",
      "19/19 - 9s - loss: 0.7974 - categorical_accuracy: 0.6739 - val_loss: 0.7900 - val_categorical_accuracy: 0.6681 - 9s/epoch - 476ms/step\n",
      "Epoch 8/46\n",
      "19/19 - 10s - loss: 0.7634 - categorical_accuracy: 0.6894 - val_loss: 0.7678 - val_categorical_accuracy: 0.6734 - 10s/epoch - 508ms/step\n",
      "Epoch 9/46\n",
      "19/19 - 10s - loss: 0.7264 - categorical_accuracy: 0.6942 - val_loss: 0.7346 - val_categorical_accuracy: 0.6809 - 10s/epoch - 516ms/step\n",
      "Epoch 10/46\n",
      "19/19 - 11s - loss: 0.6943 - categorical_accuracy: 0.6995 - val_loss: 0.7043 - val_categorical_accuracy: 0.6809 - 11s/epoch - 564ms/step\n",
      "Epoch 11/46\n",
      "19/19 - 9s - loss: 0.6660 - categorical_accuracy: 0.7104 - val_loss: 0.6893 - val_categorical_accuracy: 0.6948 - 9s/epoch - 471ms/step\n",
      "Epoch 12/46\n",
      "19/19 - 9s - loss: 0.6521 - categorical_accuracy: 0.7216 - val_loss: 0.6775 - val_categorical_accuracy: 0.6969 - 9s/epoch - 462ms/step\n",
      "Epoch 13/46\n",
      "19/19 - 9s - loss: 0.6234 - categorical_accuracy: 0.7294 - val_loss: 0.6506 - val_categorical_accuracy: 0.7332 - 9s/epoch - 468ms/step\n",
      "Epoch 14/46\n",
      "19/19 - 10s - loss: 0.6117 - categorical_accuracy: 0.7459 - val_loss: 0.6238 - val_categorical_accuracy: 0.7385 - 10s/epoch - 535ms/step\n",
      "Epoch 15/46\n",
      "19/19 - 11s - loss: 0.5882 - categorical_accuracy: 0.7526 - val_loss: 0.6514 - val_categorical_accuracy: 0.7204 - 11s/epoch - 587ms/step\n",
      "Epoch 16/46\n",
      "19/19 - 9s - loss: 0.5838 - categorical_accuracy: 0.7585 - val_loss: 0.6477 - val_categorical_accuracy: 0.7108 - 9s/epoch - 453ms/step\n",
      "Epoch 17/46\n",
      "19/19 - 9s - loss: 0.5806 - categorical_accuracy: 0.7491 - val_loss: 0.6231 - val_categorical_accuracy: 0.7236 - 9s/epoch - 453ms/step\n",
      "Epoch 18/46\n",
      "19/19 - 9s - loss: 0.5676 - categorical_accuracy: 0.7619 - val_loss: 0.6225 - val_categorical_accuracy: 0.7300 - 9s/epoch - 449ms/step\n",
      "Epoch 19/46\n",
      "19/19 - 8s - loss: 0.5574 - categorical_accuracy: 0.7646 - val_loss: 0.5818 - val_categorical_accuracy: 0.7449 - 8s/epoch - 447ms/step\n",
      "Epoch 20/46\n",
      "19/19 - 8s - loss: 0.5312 - categorical_accuracy: 0.7774 - val_loss: 0.5736 - val_categorical_accuracy: 0.7481 - 8s/epoch - 445ms/step\n",
      "Epoch 21/46\n",
      "19/19 - 10s - loss: 0.5410 - categorical_accuracy: 0.7713 - val_loss: 0.6351 - val_categorical_accuracy: 0.7300 - 10s/epoch - 535ms/step\n",
      "Epoch 22/46\n",
      "19/19 - 10s - loss: 0.5419 - categorical_accuracy: 0.7732 - val_loss: 0.5825 - val_categorical_accuracy: 0.7396 - 10s/epoch - 503ms/step\n",
      "Epoch 23/46\n",
      "19/19 - 9s - loss: 0.5311 - categorical_accuracy: 0.7681 - val_loss: 0.5919 - val_categorical_accuracy: 0.7300 - 9s/epoch - 448ms/step\n",
      "Epoch 24/46\n",
      "19/19 - 9s - loss: 0.5245 - categorical_accuracy: 0.7801 - val_loss: 0.5896 - val_categorical_accuracy: 0.7428 - 9s/epoch - 483ms/step\n",
      "Epoch 25/46\n",
      "19/19 - 8s - loss: 0.5161 - categorical_accuracy: 0.7860 - val_loss: 0.5659 - val_categorical_accuracy: 0.7556 - 8s/epoch - 435ms/step\n",
      "Epoch 26/46\n",
      "19/19 - 10s - loss: 0.5098 - categorical_accuracy: 0.7809 - val_loss: 0.5603 - val_categorical_accuracy: 0.7599 - 10s/epoch - 505ms/step\n",
      "Epoch 27/46\n",
      "19/19 - 10s - loss: 0.5036 - categorical_accuracy: 0.7934 - val_loss: 0.5744 - val_categorical_accuracy: 0.7439 - 10s/epoch - 535ms/step\n",
      "Epoch 28/46\n",
      "19/19 - 10s - loss: 0.4999 - categorical_accuracy: 0.7932 - val_loss: 0.5619 - val_categorical_accuracy: 0.7545 - 10s/epoch - 508ms/step\n",
      "Epoch 29/46\n",
      "19/19 - 10s - loss: 0.4921 - categorical_accuracy: 0.7980 - val_loss: 0.5683 - val_categorical_accuracy: 0.7492 - 10s/epoch - 536ms/step\n",
      "Epoch 30/46\n",
      "19/19 - 11s - loss: 0.4906 - categorical_accuracy: 0.7972 - val_loss: 0.5755 - val_categorical_accuracy: 0.7460 - 11s/epoch - 556ms/step\n",
      "Epoch 31/46\n",
      "19/19 - 9s - loss: 0.4961 - categorical_accuracy: 0.7948 - val_loss: 0.5720 - val_categorical_accuracy: 0.7545 - 9s/epoch - 484ms/step\n",
      "Epoch 32/46\n",
      "19/19 - 8s - loss: 0.4823 - categorical_accuracy: 0.7982 - val_loss: 0.5569 - val_categorical_accuracy: 0.7588 - 8s/epoch - 446ms/step\n",
      "Epoch 33/46\n",
      "19/19 - 9s - loss: 0.4796 - categorical_accuracy: 0.7972 - val_loss: 0.5601 - val_categorical_accuracy: 0.7577 - 9s/epoch - 459ms/step\n",
      "Epoch 34/46\n",
      "19/19 - 9s - loss: 0.4898 - categorical_accuracy: 0.7937 - val_loss: 0.5646 - val_categorical_accuracy: 0.7503 - 9s/epoch - 465ms/step\n",
      "Epoch 35/46\n",
      "19/19 - 11s - loss: 0.4760 - categorical_accuracy: 0.8012 - val_loss: 0.5613 - val_categorical_accuracy: 0.7620 - 11s/epoch - 566ms/step\n",
      "Epoch 36/46\n",
      "19/19 - 10s - loss: 0.4681 - categorical_accuracy: 0.8068 - val_loss: 0.5510 - val_categorical_accuracy: 0.7567 - 10s/epoch - 549ms/step\n",
      "Epoch 37/46\n",
      "19/19 - 11s - loss: 0.4621 - categorical_accuracy: 0.8081 - val_loss: 0.5731 - val_categorical_accuracy: 0.7503 - 11s/epoch - 553ms/step\n",
      "Epoch 38/46\n",
      "19/19 - 10s - loss: 0.4633 - categorical_accuracy: 0.8092 - val_loss: 0.5766 - val_categorical_accuracy: 0.7471 - 10s/epoch - 530ms/step\n",
      "Epoch 39/46\n",
      "19/19 - 10s - loss: 0.4684 - categorical_accuracy: 0.8049 - val_loss: 0.5853 - val_categorical_accuracy: 0.7385 - 10s/epoch - 520ms/step\n",
      "Epoch 40/46\n",
      "19/19 - 8s - loss: 0.4558 - categorical_accuracy: 0.8076 - val_loss: 0.5616 - val_categorical_accuracy: 0.7673 - 8s/epoch - 444ms/step\n",
      "Epoch 41/46\n",
      "19/19 - 9s - loss: 0.4509 - categorical_accuracy: 0.8113 - val_loss: 0.5492 - val_categorical_accuracy: 0.7609 - 9s/epoch - 460ms/step\n",
      "Epoch 42/46\n",
      "19/19 - 8s - loss: 0.4459 - categorical_accuracy: 0.8129 - val_loss: 0.5582 - val_categorical_accuracy: 0.7641 - 8s/epoch - 443ms/step\n",
      "Epoch 43/46\n",
      "19/19 - 8s - loss: 0.4372 - categorical_accuracy: 0.8177 - val_loss: 0.5484 - val_categorical_accuracy: 0.7524 - 8s/epoch - 445ms/step\n",
      "Epoch 44/46\n",
      "19/19 - 8s - loss: 0.4364 - categorical_accuracy: 0.8183 - val_loss: 0.5512 - val_categorical_accuracy: 0.7545 - 8s/epoch - 426ms/step\n",
      "Epoch 45/46\n",
      "19/19 - 8s - loss: 0.4297 - categorical_accuracy: 0.8188 - val_loss: 0.5606 - val_categorical_accuracy: 0.7567 - 8s/epoch - 443ms/step\n",
      "Epoch 46/46\n",
      "19/19 - 8s - loss: 0.4211 - categorical_accuracy: 0.8265 - val_loss: 0.5834 - val_categorical_accuracy: 0.7535 - 8s/epoch - 444ms/step\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 98, 98, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 49, 49, 10)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 47, 47, 10)        910       \n",
      "                                                                 \n",
      " average_pooling2d (AverageP  (None, 23, 23, 10)       0         \n",
      " ooling2D)                                                       \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 5290)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 30)                158730    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                930       \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dense_2 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,693\n",
      "Trainable params: 161,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5399441123008728\n",
      "Test accuracy: 0.7662116289138794\n"
     ]
    }
   ],
   "source": [
    "train(100,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bd1823c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/93\n",
      "19/19 - 9s - loss: 1.0815 - categorical_accuracy: 0.4788 - val_loss: 1.0628 - val_categorical_accuracy: 0.4813 - 9s/epoch - 475ms/step\n",
      "Epoch 2/93\n",
      "19/19 - 8s - loss: 1.0550 - categorical_accuracy: 0.4788 - val_loss: 1.0500 - val_categorical_accuracy: 0.4813 - 8s/epoch - 420ms/step\n",
      "Epoch 3/93\n",
      "19/19 - 10s - loss: 1.0403 - categorical_accuracy: 0.4788 - val_loss: 1.0251 - val_categorical_accuracy: 0.4813 - 10s/epoch - 528ms/step\n",
      "Epoch 4/93\n",
      "19/19 - 10s - loss: 0.9652 - categorical_accuracy: 0.4788 - val_loss: 0.9080 - val_categorical_accuracy: 0.4813 - 10s/epoch - 543ms/step\n",
      "Epoch 5/93\n",
      "19/19 - 11s - loss: 0.8648 - categorical_accuracy: 0.5746 - val_loss: 0.8422 - val_categorical_accuracy: 0.6371 - 11s/epoch - 590ms/step\n",
      "Epoch 6/93\n",
      "19/19 - 10s - loss: 0.8329 - categorical_accuracy: 0.6568 - val_loss: 0.8189 - val_categorical_accuracy: 0.6521 - 10s/epoch - 513ms/step\n",
      "Epoch 7/93\n",
      "19/19 - 8s - loss: 0.7901 - categorical_accuracy: 0.6805 - val_loss: 0.7817 - val_categorical_accuracy: 0.6628 - 8s/epoch - 442ms/step\n",
      "Epoch 8/93\n",
      "19/19 - 8s - loss: 0.7478 - categorical_accuracy: 0.6883 - val_loss: 0.7396 - val_categorical_accuracy: 0.6713 - 8s/epoch - 430ms/step\n",
      "Epoch 9/93\n",
      "19/19 - 9s - loss: 0.6909 - categorical_accuracy: 0.6931 - val_loss: 0.6931 - val_categorical_accuracy: 0.6681 - 9s/epoch - 455ms/step\n",
      "Epoch 10/93\n",
      "19/19 - 8s - loss: 0.6229 - categorical_accuracy: 0.7211 - val_loss: 0.6409 - val_categorical_accuracy: 0.6980 - 8s/epoch - 441ms/step\n",
      "Epoch 11/93\n",
      "19/19 - 9s - loss: 0.6005 - categorical_accuracy: 0.7345 - val_loss: 0.6225 - val_categorical_accuracy: 0.7407 - 9s/epoch - 476ms/step\n",
      "Epoch 12/93\n",
      "19/19 - 9s - loss: 0.5866 - categorical_accuracy: 0.7406 - val_loss: 0.6228 - val_categorical_accuracy: 0.7279 - 9s/epoch - 492ms/step\n",
      "Epoch 13/93\n",
      "19/19 - 9s - loss: 0.5777 - categorical_accuracy: 0.7451 - val_loss: 0.5967 - val_categorical_accuracy: 0.7407 - 9s/epoch - 451ms/step\n",
      "Epoch 14/93\n",
      "19/19 - 8s - loss: 0.5713 - categorical_accuracy: 0.7427 - val_loss: 0.5902 - val_categorical_accuracy: 0.7407 - 8s/epoch - 439ms/step\n",
      "Epoch 15/93\n",
      "19/19 - 10s - loss: 0.5708 - categorical_accuracy: 0.7430 - val_loss: 0.6277 - val_categorical_accuracy: 0.7225 - 10s/epoch - 508ms/step\n",
      "Epoch 16/93\n",
      "19/19 - 8s - loss: 0.5688 - categorical_accuracy: 0.7475 - val_loss: 0.6532 - val_categorical_accuracy: 0.7022 - 8s/epoch - 445ms/step\n",
      "Epoch 17/93\n",
      "19/19 - 9s - loss: 0.5611 - categorical_accuracy: 0.7510 - val_loss: 0.5862 - val_categorical_accuracy: 0.7343 - 9s/epoch - 452ms/step\n",
      "Epoch 18/93\n",
      "19/19 - 9s - loss: 0.5541 - categorical_accuracy: 0.7521 - val_loss: 0.5904 - val_categorical_accuracy: 0.7375 - 9s/epoch - 484ms/step\n",
      "Epoch 19/93\n",
      "19/19 - 9s - loss: 0.5502 - categorical_accuracy: 0.7531 - val_loss: 0.5920 - val_categorical_accuracy: 0.7300 - 9s/epoch - 473ms/step\n",
      "Epoch 20/93\n",
      "19/19 - 9s - loss: 0.5630 - categorical_accuracy: 0.7473 - val_loss: 0.6625 - val_categorical_accuracy: 0.6788 - 9s/epoch - 456ms/step\n",
      "Epoch 21/93\n",
      "19/19 - 10s - loss: 0.5747 - categorical_accuracy: 0.7425 - val_loss: 0.6012 - val_categorical_accuracy: 0.7289 - 10s/epoch - 505ms/step\n",
      "Epoch 22/93\n",
      "19/19 - 9s - loss: 0.5420 - categorical_accuracy: 0.7619 - val_loss: 0.5678 - val_categorical_accuracy: 0.7449 - 9s/epoch - 500ms/step\n",
      "Epoch 23/93\n",
      "19/19 - 8s - loss: 0.5341 - categorical_accuracy: 0.7665 - val_loss: 0.6258 - val_categorical_accuracy: 0.7161 - 8s/epoch - 445ms/step\n",
      "Epoch 24/93\n",
      "19/19 - 9s - loss: 0.5406 - categorical_accuracy: 0.7622 - val_loss: 0.5632 - val_categorical_accuracy: 0.7449 - 9s/epoch - 448ms/step\n",
      "Epoch 25/93\n",
      "19/19 - 8s - loss: 0.5225 - categorical_accuracy: 0.7721 - val_loss: 0.5766 - val_categorical_accuracy: 0.7407 - 8s/epoch - 436ms/step\n",
      "Epoch 26/93\n",
      "19/19 - 9s - loss: 0.5294 - categorical_accuracy: 0.7699 - val_loss: 0.5591 - val_categorical_accuracy: 0.7535 - 9s/epoch - 485ms/step\n",
      "Epoch 27/93\n",
      "19/19 - 9s - loss: 0.5139 - categorical_accuracy: 0.7796 - val_loss: 0.5637 - val_categorical_accuracy: 0.7503 - 9s/epoch - 458ms/step\n",
      "Epoch 28/93\n",
      "19/19 - 8s - loss: 0.5170 - categorical_accuracy: 0.7758 - val_loss: 0.5619 - val_categorical_accuracy: 0.7535 - 8s/epoch - 439ms/step\n",
      "Epoch 29/93\n",
      "19/19 - 9s - loss: 0.5073 - categorical_accuracy: 0.7753 - val_loss: 0.5604 - val_categorical_accuracy: 0.7567 - 9s/epoch - 456ms/step\n",
      "Epoch 30/93\n",
      "19/19 - 8s - loss: 0.5082 - categorical_accuracy: 0.7828 - val_loss: 0.5660 - val_categorical_accuracy: 0.7439 - 8s/epoch - 440ms/step\n",
      "Epoch 31/93\n",
      "19/19 - 8s - loss: 0.5028 - categorical_accuracy: 0.7844 - val_loss: 0.5585 - val_categorical_accuracy: 0.7545 - 8s/epoch - 446ms/step\n",
      "Epoch 32/93\n",
      "19/19 - 8s - loss: 0.4908 - categorical_accuracy: 0.7865 - val_loss: 0.5601 - val_categorical_accuracy: 0.7449 - 8s/epoch - 432ms/step\n",
      "Epoch 33/93\n",
      "19/19 - 10s - loss: 0.4981 - categorical_accuracy: 0.7889 - val_loss: 0.5579 - val_categorical_accuracy: 0.7524 - 10s/epoch - 505ms/step\n",
      "Epoch 34/93\n",
      "19/19 - 9s - loss: 0.4848 - categorical_accuracy: 0.7870 - val_loss: 0.5691 - val_categorical_accuracy: 0.7353 - 9s/epoch - 475ms/step\n",
      "Epoch 35/93\n",
      "19/19 - 10s - loss: 0.4879 - categorical_accuracy: 0.7918 - val_loss: 0.6024 - val_categorical_accuracy: 0.7385 - 10s/epoch - 519ms/step\n",
      "Epoch 36/93\n",
      "19/19 - 10s - loss: 0.4896 - categorical_accuracy: 0.7908 - val_loss: 0.5624 - val_categorical_accuracy: 0.7599 - 10s/epoch - 547ms/step\n",
      "Epoch 37/93\n",
      "19/19 - 8s - loss: 0.4825 - categorical_accuracy: 0.7950 - val_loss: 0.5669 - val_categorical_accuracy: 0.7407 - 8s/epoch - 440ms/step\n",
      "Epoch 38/93\n",
      "19/19 - 9s - loss: 0.4766 - categorical_accuracy: 0.7956 - val_loss: 0.5876 - val_categorical_accuracy: 0.7343 - 9s/epoch - 463ms/step\n",
      "Epoch 39/93\n",
      "19/19 - 8s - loss: 0.4770 - categorical_accuracy: 0.7996 - val_loss: 0.5451 - val_categorical_accuracy: 0.7641 - 8s/epoch - 440ms/step\n",
      "Epoch 40/93\n",
      "19/19 - 9s - loss: 0.4650 - categorical_accuracy: 0.8025 - val_loss: 0.5472 - val_categorical_accuracy: 0.7545 - 9s/epoch - 485ms/step\n",
      "Epoch 41/93\n",
      "19/19 - 9s - loss: 0.4585 - categorical_accuracy: 0.8022 - val_loss: 0.5445 - val_categorical_accuracy: 0.7631 - 9s/epoch - 469ms/step\n",
      "Epoch 42/93\n",
      "19/19 - 9s - loss: 0.4526 - categorical_accuracy: 0.8068 - val_loss: 0.5749 - val_categorical_accuracy: 0.7417 - 9s/epoch - 467ms/step\n",
      "Epoch 43/93\n",
      "19/19 - 13s - loss: 0.4735 - categorical_accuracy: 0.7924 - val_loss: 0.5382 - val_categorical_accuracy: 0.7620 - 13s/epoch - 681ms/step\n",
      "Epoch 44/93\n",
      "19/19 - 8s - loss: 0.4635 - categorical_accuracy: 0.8038 - val_loss: 0.5452 - val_categorical_accuracy: 0.7535 - 8s/epoch - 436ms/step\n",
      "Epoch 45/93\n",
      "19/19 - 9s - loss: 0.4522 - categorical_accuracy: 0.8054 - val_loss: 0.5682 - val_categorical_accuracy: 0.7535 - 9s/epoch - 450ms/step\n",
      "Epoch 46/93\n",
      "19/19 - 8s - loss: 0.4465 - categorical_accuracy: 0.8121 - val_loss: 0.5407 - val_categorical_accuracy: 0.7599 - 8s/epoch - 435ms/step\n",
      "Epoch 47/93\n",
      "19/19 - 8s - loss: 0.4505 - categorical_accuracy: 0.8070 - val_loss: 0.5608 - val_categorical_accuracy: 0.7663 - 8s/epoch - 441ms/step\n",
      "Epoch 48/93\n",
      "19/19 - 8s - loss: 0.4559 - categorical_accuracy: 0.8052 - val_loss: 0.5450 - val_categorical_accuracy: 0.7609 - 8s/epoch - 434ms/step\n",
      "Epoch 49/93\n",
      "19/19 - 9s - loss: 0.4385 - categorical_accuracy: 0.8153 - val_loss: 0.5341 - val_categorical_accuracy: 0.7663 - 9s/epoch - 450ms/step\n",
      "Epoch 50/93\n",
      "19/19 - 8s - loss: 0.4342 - categorical_accuracy: 0.8193 - val_loss: 0.5448 - val_categorical_accuracy: 0.7695 - 8s/epoch - 438ms/step\n",
      "Epoch 51/93\n",
      "19/19 - 9s - loss: 0.4308 - categorical_accuracy: 0.8217 - val_loss: 0.5398 - val_categorical_accuracy: 0.7599 - 9s/epoch - 483ms/step\n",
      "Epoch 52/93\n",
      "19/19 - 8s - loss: 0.4279 - categorical_accuracy: 0.8220 - val_loss: 0.5603 - val_categorical_accuracy: 0.7556 - 8s/epoch - 437ms/step\n",
      "Epoch 53/93\n",
      "19/19 - 8s - loss: 0.4398 - categorical_accuracy: 0.8129 - val_loss: 0.5364 - val_categorical_accuracy: 0.7663 - 8s/epoch - 445ms/step\n",
      "Epoch 54/93\n",
      "19/19 - 9s - loss: 0.4329 - categorical_accuracy: 0.8172 - val_loss: 0.5761 - val_categorical_accuracy: 0.7545 - 9s/epoch - 469ms/step\n",
      "Epoch 55/93\n",
      "19/19 - 9s - loss: 0.4339 - categorical_accuracy: 0.8121 - val_loss: 0.5505 - val_categorical_accuracy: 0.7524 - 9s/epoch - 461ms/step\n",
      "Epoch 56/93\n",
      "19/19 - 9s - loss: 0.4307 - categorical_accuracy: 0.8135 - val_loss: 0.5356 - val_categorical_accuracy: 0.7609 - 9s/epoch - 464ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/93\n",
      "19/19 - 8s - loss: 0.4264 - categorical_accuracy: 0.8199 - val_loss: 0.5482 - val_categorical_accuracy: 0.7641 - 8s/epoch - 414ms/step\n",
      "Epoch 58/93\n",
      "19/19 - 8s - loss: 0.4141 - categorical_accuracy: 0.8199 - val_loss: 0.5362 - val_categorical_accuracy: 0.7748 - 8s/epoch - 431ms/step\n",
      "Epoch 59/93\n",
      "19/19 - 8s - loss: 0.4142 - categorical_accuracy: 0.8271 - val_loss: 0.5325 - val_categorical_accuracy: 0.7769 - 8s/epoch - 418ms/step\n",
      "Epoch 60/93\n",
      "19/19 - 9s - loss: 0.4053 - categorical_accuracy: 0.8271 - val_loss: 0.5483 - val_categorical_accuracy: 0.7705 - 9s/epoch - 459ms/step\n",
      "Epoch 61/93\n",
      "19/19 - 9s - loss: 0.4073 - categorical_accuracy: 0.8247 - val_loss: 0.5326 - val_categorical_accuracy: 0.7759 - 9s/epoch - 450ms/step\n",
      "Epoch 62/93\n",
      "19/19 - 8s - loss: 0.4051 - categorical_accuracy: 0.8249 - val_loss: 0.5523 - val_categorical_accuracy: 0.7684 - 8s/epoch - 429ms/step\n",
      "Epoch 63/93\n",
      "19/19 - 8s - loss: 0.3964 - categorical_accuracy: 0.8313 - val_loss: 0.5310 - val_categorical_accuracy: 0.7705 - 8s/epoch - 413ms/step\n",
      "Epoch 64/93\n",
      "19/19 - 9s - loss: 0.3936 - categorical_accuracy: 0.8327 - val_loss: 0.5448 - val_categorical_accuracy: 0.7663 - 9s/epoch - 464ms/step\n",
      "Epoch 65/93\n",
      "19/19 - 9s - loss: 0.3905 - categorical_accuracy: 0.8380 - val_loss: 0.5462 - val_categorical_accuracy: 0.7812 - 9s/epoch - 463ms/step\n",
      "Epoch 66/93\n",
      "19/19 - 8s - loss: 0.3937 - categorical_accuracy: 0.8305 - val_loss: 0.5372 - val_categorical_accuracy: 0.7727 - 8s/epoch - 442ms/step\n",
      "Epoch 67/93\n",
      "19/19 - 10s - loss: 0.3863 - categorical_accuracy: 0.8353 - val_loss: 0.5501 - val_categorical_accuracy: 0.7748 - 10s/epoch - 540ms/step\n",
      "Epoch 68/93\n",
      "19/19 - 11s - loss: 0.3797 - categorical_accuracy: 0.8396 - val_loss: 0.5360 - val_categorical_accuracy: 0.7737 - 11s/epoch - 588ms/step\n",
      "Epoch 69/93\n",
      "19/19 - 10s - loss: 0.3852 - categorical_accuracy: 0.8404 - val_loss: 0.5665 - val_categorical_accuracy: 0.7631 - 10s/epoch - 552ms/step\n",
      "Epoch 70/93\n",
      "19/19 - 9s - loss: 0.3819 - categorical_accuracy: 0.8380 - val_loss: 0.5429 - val_categorical_accuracy: 0.7791 - 9s/epoch - 451ms/step\n",
      "Epoch 71/93\n",
      "19/19 - 9s - loss: 0.3753 - categorical_accuracy: 0.8404 - val_loss: 0.5501 - val_categorical_accuracy: 0.7652 - 9s/epoch - 477ms/step\n",
      "Epoch 72/93\n",
      "19/19 - 8s - loss: 0.3781 - categorical_accuracy: 0.8377 - val_loss: 0.5612 - val_categorical_accuracy: 0.7748 - 8s/epoch - 439ms/step\n",
      "Epoch 73/93\n",
      "19/19 - 8s - loss: 0.3743 - categorical_accuracy: 0.8452 - val_loss: 0.5611 - val_categorical_accuracy: 0.7577 - 8s/epoch - 426ms/step\n",
      "Epoch 74/93\n",
      "19/19 - 8s - loss: 0.3802 - categorical_accuracy: 0.8356 - val_loss: 0.5676 - val_categorical_accuracy: 0.7567 - 8s/epoch - 419ms/step\n",
      "Epoch 75/93\n",
      "19/19 - 8s - loss: 0.3666 - categorical_accuracy: 0.8452 - val_loss: 0.5420 - val_categorical_accuracy: 0.7748 - 8s/epoch - 433ms/step\n",
      "Epoch 76/93\n",
      "19/19 - 10s - loss: 0.3604 - categorical_accuracy: 0.8497 - val_loss: 0.5627 - val_categorical_accuracy: 0.7716 - 10s/epoch - 521ms/step\n",
      "Epoch 77/93\n",
      "19/19 - 9s - loss: 0.3491 - categorical_accuracy: 0.8554 - val_loss: 0.5556 - val_categorical_accuracy: 0.7716 - 9s/epoch - 467ms/step\n",
      "Epoch 78/93\n",
      "19/19 - 9s - loss: 0.3428 - categorical_accuracy: 0.8591 - val_loss: 0.5587 - val_categorical_accuracy: 0.7834 - 9s/epoch - 474ms/step\n",
      "Epoch 79/93\n",
      "19/19 - 8s - loss: 0.3454 - categorical_accuracy: 0.8607 - val_loss: 0.5722 - val_categorical_accuracy: 0.7577 - 8s/epoch - 419ms/step\n",
      "Epoch 80/93\n",
      "19/19 - 10s - loss: 0.3541 - categorical_accuracy: 0.8503 - val_loss: 0.5828 - val_categorical_accuracy: 0.7705 - 10s/epoch - 514ms/step\n",
      "Epoch 81/93\n",
      "19/19 - 9s - loss: 0.3431 - categorical_accuracy: 0.8599 - val_loss: 0.5511 - val_categorical_accuracy: 0.7663 - 9s/epoch - 492ms/step\n",
      "Epoch 82/93\n",
      "19/19 - 8s - loss: 0.3370 - categorical_accuracy: 0.8618 - val_loss: 0.5531 - val_categorical_accuracy: 0.7599 - 8s/epoch - 439ms/step\n",
      "Epoch 83/93\n",
      "19/19 - 8s - loss: 0.3339 - categorical_accuracy: 0.8674 - val_loss: 0.5744 - val_categorical_accuracy: 0.7577 - 8s/epoch - 441ms/step\n",
      "Epoch 84/93\n",
      "19/19 - 8s - loss: 0.3299 - categorical_accuracy: 0.8668 - val_loss: 0.5802 - val_categorical_accuracy: 0.7727 - 8s/epoch - 444ms/step\n",
      "Epoch 85/93\n",
      "19/19 - 9s - loss: 0.3396 - categorical_accuracy: 0.8559 - val_loss: 0.6061 - val_categorical_accuracy: 0.7449 - 9s/epoch - 461ms/step\n",
      "Epoch 86/93\n",
      "19/19 - 9s - loss: 0.3468 - categorical_accuracy: 0.8489 - val_loss: 0.5833 - val_categorical_accuracy: 0.7748 - 9s/epoch - 467ms/step\n",
      "Epoch 87/93\n",
      "19/19 - 8s - loss: 0.3307 - categorical_accuracy: 0.8631 - val_loss: 0.5899 - val_categorical_accuracy: 0.7524 - 8s/epoch - 442ms/step\n",
      "Epoch 88/93\n",
      "19/19 - 8s - loss: 0.3280 - categorical_accuracy: 0.8607 - val_loss: 0.5691 - val_categorical_accuracy: 0.7716 - 8s/epoch - 413ms/step\n",
      "Epoch 89/93\n",
      "19/19 - 8s - loss: 0.3142 - categorical_accuracy: 0.8663 - val_loss: 0.5732 - val_categorical_accuracy: 0.7737 - 8s/epoch - 431ms/step\n",
      "Epoch 90/93\n",
      "19/19 - 8s - loss: 0.3042 - categorical_accuracy: 0.8799 - val_loss: 0.5912 - val_categorical_accuracy: 0.7641 - 8s/epoch - 428ms/step\n",
      "Epoch 91/93\n",
      "19/19 - 9s - loss: 0.3145 - categorical_accuracy: 0.8722 - val_loss: 0.5902 - val_categorical_accuracy: 0.7684 - 9s/epoch - 457ms/step\n",
      "Epoch 92/93\n",
      "19/19 - 8s - loss: 0.3167 - categorical_accuracy: 0.8732 - val_loss: 0.6057 - val_categorical_accuracy: 0.7481 - 8s/epoch - 425ms/step\n",
      "Epoch 93/93\n",
      "19/19 - 8s - loss: 0.3127 - categorical_accuracy: 0.8804 - val_loss: 0.5847 - val_categorical_accuracy: 0.7695 - 8s/epoch - 426ms/step\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 98, 98, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 49, 49, 10)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 47, 47, 10)        910       \n",
      "                                                                 \n",
      " average_pooling2d_1 (Averag  (None, 23, 23, 10)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 5290)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 30)                158730    \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,693\n",
      "Trainable params: 161,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5876277089118958\n",
      "Test accuracy: 0.7687713503837585\n"
     ]
    }
   ],
   "source": [
    "train(50,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7489d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/23\n",
      "19/19 - 10s - loss: 1.0765 - categorical_accuracy: 0.4614 - val_loss: 1.0598 - val_categorical_accuracy: 0.4813 - 10s/epoch - 502ms/step\n",
      "Epoch 2/23\n",
      "19/19 - 9s - loss: 1.0515 - categorical_accuracy: 0.4788 - val_loss: 1.0410 - val_categorical_accuracy: 0.4813 - 9s/epoch - 451ms/step\n",
      "Epoch 3/23\n",
      "19/19 - 9s - loss: 0.9870 - categorical_accuracy: 0.4908 - val_loss: 0.9341 - val_categorical_accuracy: 0.5891 - 9s/epoch - 498ms/step\n",
      "Epoch 4/23\n",
      "19/19 - 10s - loss: 0.8811 - categorical_accuracy: 0.6504 - val_loss: 0.8623 - val_categorical_accuracy: 0.6211 - 10s/epoch - 533ms/step\n",
      "Epoch 5/23\n",
      "19/19 - 9s - loss: 0.7789 - categorical_accuracy: 0.6688 - val_loss: 0.7663 - val_categorical_accuracy: 0.6606 - 9s/epoch - 458ms/step\n",
      "Epoch 6/23\n",
      "19/19 - 8s - loss: 0.6943 - categorical_accuracy: 0.6861 - val_loss: 0.7158 - val_categorical_accuracy: 0.6724 - 8s/epoch - 440ms/step\n",
      "Epoch 7/23\n",
      "19/19 - 8s - loss: 0.6509 - categorical_accuracy: 0.7120 - val_loss: 0.7060 - val_categorical_accuracy: 0.6734 - 8s/epoch - 417ms/step\n",
      "Epoch 8/23\n",
      "19/19 - 8s - loss: 0.6331 - categorical_accuracy: 0.7096 - val_loss: 0.6508 - val_categorical_accuracy: 0.6969 - 8s/epoch - 426ms/step\n",
      "Epoch 9/23\n",
      "19/19 - 8s - loss: 0.6397 - categorical_accuracy: 0.7163 - val_loss: 0.6564 - val_categorical_accuracy: 0.7054 - 8s/epoch - 421ms/step\n",
      "Epoch 10/23\n",
      "19/19 - 8s - loss: 0.6208 - categorical_accuracy: 0.7158 - val_loss: 0.6468 - val_categorical_accuracy: 0.6948 - 8s/epoch - 433ms/step\n",
      "Epoch 11/23\n",
      "19/19 - 8s - loss: 0.6159 - categorical_accuracy: 0.7232 - val_loss: 0.6803 - val_categorical_accuracy: 0.6926 - 8s/epoch - 420ms/step\n",
      "Epoch 12/23\n",
      "19/19 - 8s - loss: 0.6122 - categorical_accuracy: 0.7208 - val_loss: 0.6324 - val_categorical_accuracy: 0.7108 - 8s/epoch - 424ms/step\n",
      "Epoch 13/23\n",
      "19/19 - 8s - loss: 0.6141 - categorical_accuracy: 0.7192 - val_loss: 0.6322 - val_categorical_accuracy: 0.7065 - 8s/epoch - 423ms/step\n",
      "Epoch 14/23\n",
      "19/19 - 8s - loss: 0.6071 - categorical_accuracy: 0.7222 - val_loss: 0.6270 - val_categorical_accuracy: 0.7172 - 8s/epoch - 429ms/step\n",
      "Epoch 15/23\n",
      "19/19 - 8s - loss: 0.5968 - categorical_accuracy: 0.7262 - val_loss: 0.6203 - val_categorical_accuracy: 0.7161 - 8s/epoch - 421ms/step\n",
      "Epoch 16/23\n",
      "19/19 - 8s - loss: 0.5931 - categorical_accuracy: 0.7302 - val_loss: 0.6433 - val_categorical_accuracy: 0.6990 - 8s/epoch - 425ms/step\n",
      "Epoch 17/23\n",
      "19/19 - 8s - loss: 0.5913 - categorical_accuracy: 0.7297 - val_loss: 0.6151 - val_categorical_accuracy: 0.7353 - 8s/epoch - 413ms/step\n",
      "Epoch 18/23\n",
      "19/19 - 8s - loss: 0.6036 - categorical_accuracy: 0.7243 - val_loss: 0.6381 - val_categorical_accuracy: 0.7129 - 8s/epoch - 428ms/step\n",
      "Epoch 19/23\n",
      "19/19 - 8s - loss: 0.6006 - categorical_accuracy: 0.7243 - val_loss: 0.6145 - val_categorical_accuracy: 0.7140 - 8s/epoch - 413ms/step\n",
      "Epoch 20/23\n",
      "19/19 - 8s - loss: 0.5863 - categorical_accuracy: 0.7369 - val_loss: 0.6428 - val_categorical_accuracy: 0.7012 - 8s/epoch - 442ms/step\n",
      "Epoch 21/23\n",
      "19/19 - 8s - loss: 0.5827 - categorical_accuracy: 0.7329 - val_loss: 0.6193 - val_categorical_accuracy: 0.7172 - 8s/epoch - 437ms/step\n",
      "Epoch 22/23\n",
      "19/19 - 8s - loss: 0.5806 - categorical_accuracy: 0.7326 - val_loss: 0.6155 - val_categorical_accuracy: 0.7225 - 8s/epoch - 425ms/step\n",
      "Epoch 23/23\n",
      "19/19 - 8s - loss: 0.5806 - categorical_accuracy: 0.7350 - val_loss: 0.6143 - val_categorical_accuracy: 0.7225 - 8s/epoch - 414ms/step\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 98, 98, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 49, 49, 10)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 47, 47, 10)        910       \n",
      "                                                                 \n",
      " average_pooling2d_2 (Averag  (None, 23, 23, 10)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 5290)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 30)                158730    \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,693\n",
      "Trainable params: 161,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.6285479068756104\n",
      "Test accuracy: 0.7073378562927246\n"
     ]
    }
   ],
   "source": [
    "train(200,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dcdd0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/46\n",
      "75/75 - 9s - loss: 1.0575 - categorical_accuracy: 0.4686 - val_loss: 1.0117 - val_categorical_accuracy: 0.4813 - 9s/epoch - 124ms/step\n",
      "Epoch 2/46\n",
      "75/75 - 10s - loss: 0.8165 - categorical_accuracy: 0.6298 - val_loss: 0.7337 - val_categorical_accuracy: 0.6649 - 10s/epoch - 128ms/step\n",
      "Epoch 3/46\n",
      "75/75 - 10s - loss: 0.6791 - categorical_accuracy: 0.6990 - val_loss: 0.7180 - val_categorical_accuracy: 0.6724 - 10s/epoch - 129ms/step\n",
      "Epoch 4/46\n",
      "75/75 - 13s - loss: 0.6333 - categorical_accuracy: 0.7118 - val_loss: 0.6545 - val_categorical_accuracy: 0.6980 - 13s/epoch - 167ms/step\n",
      "Epoch 5/46\n",
      "75/75 - 12s - loss: 0.6145 - categorical_accuracy: 0.7219 - val_loss: 0.6214 - val_categorical_accuracy: 0.7118 - 12s/epoch - 157ms/step\n",
      "Epoch 6/46\n",
      "75/75 - 9s - loss: 0.6037 - categorical_accuracy: 0.7259 - val_loss: 0.6189 - val_categorical_accuracy: 0.7172 - 9s/epoch - 122ms/step\n",
      "Epoch 7/46\n",
      "75/75 - 9s - loss: 0.5967 - categorical_accuracy: 0.7224 - val_loss: 0.6009 - val_categorical_accuracy: 0.7375 - 9s/epoch - 122ms/step\n",
      "Epoch 8/46\n",
      "75/75 - 9s - loss: 0.5809 - categorical_accuracy: 0.7334 - val_loss: 0.6086 - val_categorical_accuracy: 0.7225 - 9s/epoch - 122ms/step\n",
      "Epoch 9/46\n",
      "75/75 - 9s - loss: 0.5882 - categorical_accuracy: 0.7331 - val_loss: 0.5911 - val_categorical_accuracy: 0.7279 - 9s/epoch - 123ms/step\n",
      "Epoch 10/46\n",
      "75/75 - 9s - loss: 0.5734 - categorical_accuracy: 0.7419 - val_loss: 0.5915 - val_categorical_accuracy: 0.7343 - 9s/epoch - 119ms/step\n",
      "Epoch 11/46\n",
      "75/75 - 9s - loss: 0.5658 - categorical_accuracy: 0.7411 - val_loss: 0.5834 - val_categorical_accuracy: 0.7407 - 9s/epoch - 124ms/step\n",
      "Epoch 12/46\n",
      "75/75 - 9s - loss: 0.5520 - categorical_accuracy: 0.7518 - val_loss: 0.5735 - val_categorical_accuracy: 0.7407 - 9s/epoch - 119ms/step\n",
      "Epoch 13/46\n",
      "75/75 - 9s - loss: 0.5465 - categorical_accuracy: 0.7571 - val_loss: 0.5682 - val_categorical_accuracy: 0.7343 - 9s/epoch - 124ms/step\n",
      "Epoch 14/46\n",
      "75/75 - 9s - loss: 0.5338 - categorical_accuracy: 0.7571 - val_loss: 0.5611 - val_categorical_accuracy: 0.7503 - 9s/epoch - 122ms/step\n",
      "Epoch 15/46\n",
      "75/75 - 9s - loss: 0.5297 - categorical_accuracy: 0.7665 - val_loss: 0.5620 - val_categorical_accuracy: 0.7535 - 9s/epoch - 119ms/step\n",
      "Epoch 16/46\n",
      "75/75 - 9s - loss: 0.5276 - categorical_accuracy: 0.7670 - val_loss: 0.5747 - val_categorical_accuracy: 0.7513 - 9s/epoch - 122ms/step\n",
      "Epoch 17/46\n",
      "75/75 - 9s - loss: 0.5174 - categorical_accuracy: 0.7737 - val_loss: 0.5518 - val_categorical_accuracy: 0.7599 - 9s/epoch - 119ms/step\n",
      "Epoch 18/46\n",
      "75/75 - 9s - loss: 0.5142 - categorical_accuracy: 0.7774 - val_loss: 0.5929 - val_categorical_accuracy: 0.7385 - 9s/epoch - 122ms/step\n",
      "Epoch 19/46\n",
      "75/75 - 9s - loss: 0.5161 - categorical_accuracy: 0.7772 - val_loss: 0.5443 - val_categorical_accuracy: 0.7652 - 9s/epoch - 122ms/step\n",
      "Epoch 20/46\n",
      "75/75 - 9s - loss: 0.5008 - categorical_accuracy: 0.7854 - val_loss: 0.5454 - val_categorical_accuracy: 0.7620 - 9s/epoch - 121ms/step\n",
      "Epoch 21/46\n",
      "75/75 - 9s - loss: 0.4987 - categorical_accuracy: 0.7817 - val_loss: 0.5341 - val_categorical_accuracy: 0.7641 - 9s/epoch - 120ms/step\n",
      "Epoch 22/46\n",
      "75/75 - 9s - loss: 0.4907 - categorical_accuracy: 0.7902 - val_loss: 0.5590 - val_categorical_accuracy: 0.7481 - 9s/epoch - 121ms/step\n",
      "Epoch 23/46\n",
      "75/75 - 9s - loss: 0.4817 - categorical_accuracy: 0.7950 - val_loss: 0.5367 - val_categorical_accuracy: 0.7599 - 9s/epoch - 122ms/step\n",
      "Epoch 24/46\n",
      "75/75 - 9s - loss: 0.4881 - categorical_accuracy: 0.7878 - val_loss: 0.5364 - val_categorical_accuracy: 0.7588 - 9s/epoch - 120ms/step\n",
      "Epoch 25/46\n",
      "75/75 - 9s - loss: 0.4850 - categorical_accuracy: 0.7945 - val_loss: 0.5670 - val_categorical_accuracy: 0.7684 - 9s/epoch - 122ms/step\n",
      "Epoch 26/46\n",
      "75/75 - 10s - loss: 0.4648 - categorical_accuracy: 0.8014 - val_loss: 0.5412 - val_categorical_accuracy: 0.7695 - 10s/epoch - 131ms/step\n",
      "Epoch 27/46\n",
      "75/75 - 13s - loss: 0.4675 - categorical_accuracy: 0.8025 - val_loss: 0.5457 - val_categorical_accuracy: 0.7641 - 13s/epoch - 167ms/step\n",
      "Epoch 28/46\n",
      "75/75 - 13s - loss: 0.4531 - categorical_accuracy: 0.8113 - val_loss: 0.5528 - val_categorical_accuracy: 0.7673 - 13s/epoch - 176ms/step\n",
      "Epoch 29/46\n",
      "75/75 - 12s - loss: 0.4595 - categorical_accuracy: 0.8052 - val_loss: 0.5406 - val_categorical_accuracy: 0.7737 - 12s/epoch - 165ms/step\n",
      "Epoch 30/46\n",
      "75/75 - 10s - loss: 0.4504 - categorical_accuracy: 0.8060 - val_loss: 0.5694 - val_categorical_accuracy: 0.7588 - 10s/epoch - 127ms/step\n",
      "Epoch 31/46\n",
      "75/75 - 10s - loss: 0.4398 - categorical_accuracy: 0.8143 - val_loss: 0.5555 - val_categorical_accuracy: 0.7620 - 10s/epoch - 136ms/step\n",
      "Epoch 32/46\n",
      "75/75 - 10s - loss: 0.4427 - categorical_accuracy: 0.8159 - val_loss: 0.6235 - val_categorical_accuracy: 0.7492 - 10s/epoch - 132ms/step\n",
      "Epoch 33/46\n",
      "75/75 - 10s - loss: 0.4378 - categorical_accuracy: 0.8199 - val_loss: 0.5422 - val_categorical_accuracy: 0.7652 - 10s/epoch - 130ms/step\n",
      "Epoch 34/46\n",
      "75/75 - 10s - loss: 0.4201 - categorical_accuracy: 0.8241 - val_loss: 0.5579 - val_categorical_accuracy: 0.7652 - 10s/epoch - 132ms/step\n",
      "Epoch 35/46\n",
      "75/75 - 10s - loss: 0.4190 - categorical_accuracy: 0.8271 - val_loss: 0.5688 - val_categorical_accuracy: 0.7631 - 10s/epoch - 131ms/step\n",
      "Epoch 36/46\n",
      "75/75 - 10s - loss: 0.4229 - categorical_accuracy: 0.8265 - val_loss: 0.5504 - val_categorical_accuracy: 0.7748 - 10s/epoch - 137ms/step\n",
      "Epoch 37/46\n",
      "75/75 - 10s - loss: 0.4077 - categorical_accuracy: 0.8305 - val_loss: 0.5535 - val_categorical_accuracy: 0.7631 - 10s/epoch - 132ms/step\n",
      "Epoch 38/46\n",
      "75/75 - 9s - loss: 0.4046 - categorical_accuracy: 0.8337 - val_loss: 0.5555 - val_categorical_accuracy: 0.7695 - 9s/epoch - 121ms/step\n",
      "Epoch 39/46\n",
      "75/75 - 9s - loss: 0.4048 - categorical_accuracy: 0.8361 - val_loss: 0.5491 - val_categorical_accuracy: 0.7631 - 9s/epoch - 121ms/step\n",
      "Epoch 40/46\n",
      "75/75 - 9s - loss: 0.3893 - categorical_accuracy: 0.8415 - val_loss: 0.5869 - val_categorical_accuracy: 0.7663 - 9s/epoch - 118ms/step\n",
      "Epoch 41/46\n",
      "75/75 - 9s - loss: 0.3850 - categorical_accuracy: 0.8417 - val_loss: 0.5726 - val_categorical_accuracy: 0.7673 - 9s/epoch - 121ms/step\n",
      "Epoch 42/46\n",
      "75/75 - 9s - loss: 0.3823 - categorical_accuracy: 0.8457 - val_loss: 0.6126 - val_categorical_accuracy: 0.7673 - 9s/epoch - 121ms/step\n",
      "Epoch 43/46\n",
      "75/75 - 9s - loss: 0.3849 - categorical_accuracy: 0.8463 - val_loss: 0.5567 - val_categorical_accuracy: 0.7737 - 9s/epoch - 119ms/step\n",
      "Epoch 44/46\n",
      "75/75 - 9s - loss: 0.3772 - categorical_accuracy: 0.8476 - val_loss: 0.5662 - val_categorical_accuracy: 0.7737 - 9s/epoch - 120ms/step\n",
      "Epoch 45/46\n",
      "75/75 - 9s - loss: 0.3764 - categorical_accuracy: 0.8487 - val_loss: 0.6150 - val_categorical_accuracy: 0.7631 - 9s/epoch - 119ms/step\n",
      "Epoch 46/46\n",
      "75/75 - 9s - loss: 0.3563 - categorical_accuracy: 0.8567 - val_loss: 0.5892 - val_categorical_accuracy: 0.7641 - 9s/epoch - 119ms/step\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 98, 98, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 49, 49, 10)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 47, 47, 10)        910       \n",
      "                                                                 \n",
      " average_pooling2d_6 (Averag  (None, 23, 23, 10)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 5290)              0         \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 30)                158730    \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 30)                930       \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " dense_27 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,693\n",
      "Trainable params: 161,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5521052479743958\n",
      "Test accuracy: 0.7781569957733154\n"
     ]
    }
   ],
   "source": [
    "train(100,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "35f2e4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/31\n",
      "75/75 - 10s - loss: 1.0515 - categorical_accuracy: 0.4796 - val_loss: 0.9961 - val_categorical_accuracy: 0.4813 - 10s/epoch - 133ms/step\n",
      "Epoch 2/31\n",
      "75/75 - 11s - loss: 0.8764 - categorical_accuracy: 0.5834 - val_loss: 0.8146 - val_categorical_accuracy: 0.6617 - 11s/epoch - 149ms/step\n",
      "Epoch 3/31\n",
      "75/75 - 10s - loss: 0.7750 - categorical_accuracy: 0.6861 - val_loss: 0.7640 - val_categorical_accuracy: 0.6820 - 10s/epoch - 128ms/step\n",
      "Epoch 4/31\n",
      "75/75 - 12s - loss: 0.7041 - categorical_accuracy: 0.7166 - val_loss: 0.6812 - val_categorical_accuracy: 0.7033 - 12s/epoch - 154ms/step\n",
      "Epoch 5/31\n",
      "75/75 - 10s - loss: 0.6454 - categorical_accuracy: 0.7286 - val_loss: 0.6920 - val_categorical_accuracy: 0.6820 - 10s/epoch - 136ms/step\n",
      "Epoch 6/31\n",
      "75/75 - 9s - loss: 0.6156 - categorical_accuracy: 0.7339 - val_loss: 0.6134 - val_categorical_accuracy: 0.7375 - 9s/epoch - 125ms/step\n",
      "Epoch 7/31\n",
      "75/75 - 10s - loss: 0.5824 - categorical_accuracy: 0.7502 - val_loss: 0.6069 - val_categorical_accuracy: 0.7321 - 10s/epoch - 129ms/step\n",
      "Epoch 8/31\n",
      "75/75 - 10s - loss: 0.5606 - categorical_accuracy: 0.7643 - val_loss: 0.5892 - val_categorical_accuracy: 0.7385 - 10s/epoch - 130ms/step\n",
      "Epoch 9/31\n",
      "75/75 - 10s - loss: 0.5406 - categorical_accuracy: 0.7710 - val_loss: 0.6009 - val_categorical_accuracy: 0.7407 - 10s/epoch - 130ms/step\n",
      "Epoch 10/31\n",
      "75/75 - 10s - loss: 0.5350 - categorical_accuracy: 0.7758 - val_loss: 0.5938 - val_categorical_accuracy: 0.7343 - 10s/epoch - 134ms/step\n",
      "Epoch 11/31\n",
      "75/75 - 10s - loss: 0.5144 - categorical_accuracy: 0.7809 - val_loss: 0.5623 - val_categorical_accuracy: 0.7588 - 10s/epoch - 128ms/step\n",
      "Epoch 12/31\n",
      "75/75 - 10s - loss: 0.5007 - categorical_accuracy: 0.7902 - val_loss: 0.5499 - val_categorical_accuracy: 0.7492 - 10s/epoch - 132ms/step\n",
      "Epoch 13/31\n",
      "75/75 - 10s - loss: 0.4965 - categorical_accuracy: 0.7905 - val_loss: 0.5538 - val_categorical_accuracy: 0.7513 - 10s/epoch - 130ms/step\n",
      "Epoch 14/31\n",
      "75/75 - 10s - loss: 0.4939 - categorical_accuracy: 0.7956 - val_loss: 0.5582 - val_categorical_accuracy: 0.7503 - 10s/epoch - 128ms/step\n",
      "Epoch 15/31\n",
      "75/75 - 10s - loss: 0.4773 - categorical_accuracy: 0.8017 - val_loss: 0.6074 - val_categorical_accuracy: 0.7471 - 10s/epoch - 132ms/step\n",
      "Epoch 16/31\n",
      "75/75 - 9s - loss: 0.4737 - categorical_accuracy: 0.7942 - val_loss: 0.5535 - val_categorical_accuracy: 0.7556 - 9s/epoch - 125ms/step\n",
      "Epoch 17/31\n",
      "75/75 - 9s - loss: 0.4620 - categorical_accuracy: 0.8041 - val_loss: 0.5476 - val_categorical_accuracy: 0.7577 - 9s/epoch - 123ms/step\n",
      "Epoch 18/31\n",
      "75/75 - 9s - loss: 0.4587 - categorical_accuracy: 0.8025 - val_loss: 0.5529 - val_categorical_accuracy: 0.7641 - 9s/epoch - 118ms/step\n",
      "Epoch 19/31\n",
      "75/75 - 9s - loss: 0.4493 - categorical_accuracy: 0.8105 - val_loss: 0.5898 - val_categorical_accuracy: 0.7471 - 9s/epoch - 125ms/step\n",
      "Epoch 20/31\n",
      "75/75 - 11s - loss: 0.4481 - categorical_accuracy: 0.8153 - val_loss: 0.5528 - val_categorical_accuracy: 0.7641 - 11s/epoch - 142ms/step\n",
      "Epoch 21/31\n",
      "75/75 - 9s - loss: 0.4222 - categorical_accuracy: 0.8260 - val_loss: 0.5428 - val_categorical_accuracy: 0.7705 - 9s/epoch - 127ms/step\n",
      "Epoch 22/31\n",
      "75/75 - 10s - loss: 0.4255 - categorical_accuracy: 0.8164 - val_loss: 0.6050 - val_categorical_accuracy: 0.7449 - 10s/epoch - 128ms/step\n",
      "Epoch 23/31\n",
      "75/75 - 10s - loss: 0.4073 - categorical_accuracy: 0.8276 - val_loss: 0.5727 - val_categorical_accuracy: 0.7492 - 10s/epoch - 127ms/step\n",
      "Epoch 24/31\n",
      "75/75 - 11s - loss: 0.3948 - categorical_accuracy: 0.8300 - val_loss: 0.5684 - val_categorical_accuracy: 0.7727 - 11s/epoch - 151ms/step\n",
      "Epoch 25/31\n",
      "75/75 - 11s - loss: 0.3814 - categorical_accuracy: 0.8393 - val_loss: 0.5570 - val_categorical_accuracy: 0.7631 - 11s/epoch - 153ms/step\n",
      "Epoch 26/31\n",
      "75/75 - 12s - loss: 0.3795 - categorical_accuracy: 0.8345 - val_loss: 0.5457 - val_categorical_accuracy: 0.7748 - 12s/epoch - 161ms/step\n",
      "Epoch 27/31\n",
      "75/75 - 10s - loss: 0.3691 - categorical_accuracy: 0.8407 - val_loss: 0.6161 - val_categorical_accuracy: 0.7556 - 10s/epoch - 134ms/step\n",
      "Epoch 28/31\n",
      "75/75 - 9s - loss: 0.3548 - categorical_accuracy: 0.8473 - val_loss: 0.6148 - val_categorical_accuracy: 0.7663 - 9s/epoch - 126ms/step\n",
      "Epoch 29/31\n",
      "75/75 - 9s - loss: 0.3603 - categorical_accuracy: 0.8452 - val_loss: 0.5942 - val_categorical_accuracy: 0.7556 - 9s/epoch - 125ms/step\n",
      "Epoch 30/31\n",
      "75/75 - 10s - loss: 0.3489 - categorical_accuracy: 0.8519 - val_loss: 0.5755 - val_categorical_accuracy: 0.7663 - 10s/epoch - 128ms/step\n",
      "Epoch 31/31\n",
      "75/75 - 9s - loss: 0.3339 - categorical_accuracy: 0.8532 - val_loss: 0.5919 - val_categorical_accuracy: 0.7545 - 9s/epoch - 126ms/step\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 98, 98, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 49, 49, 10)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 47, 47, 10)        910       \n",
      "                                                                 \n",
      " average_pooling2d_7 (Averag  (None, 23, 23, 10)       0         \n",
      " ePooling2D)                                                     \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 5290)              0         \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 30)                158730    \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 161,693\n",
      "Trainable params: 161,693\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5491368770599365\n",
      "Test accuracy: 0.7593856453895569\n"
     ]
    }
   ],
   "source": [
    "train(150,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbdb48a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dividor_epoch,batch_len):\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "    dataset, labels, test_size=0.2, random_state=42)\n",
    "    X_train=X_train.reshape(-1,100,100,1)\n",
    "    X_test=X_test.reshape(-1,100,100,1)\n",
    "    Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "    Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "    Inp=layers.Input(shape=(100,100,1))\n",
    "    hidden=layers.Conv2D(10,kernel_size=(3,3),padding='valid',activation='relu')(Inp)\n",
    "    hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "    hidden=layers.Flatten()(hidden)\n",
    "    for i in range(3):\n",
    "        hidden=layers.Dense(30,activation=\"relu\",kernel_regularizer=regularizers.L2(0.0001),kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/76.4, maxval=1/76.4, seed=None))(hidden)\n",
    "        #hidden=layers.Dropout(0.2)(hidden)\n",
    "    output=layers.Dense(3,activation=\"softmax\",kernel_regularizer=regularizers.L2(0.0001))(hidden)\n",
    "    model=keras.Model(Inp,output)\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=tf.keras.metrics.CategoricalAccuracy())\n",
    "    model.fit(X_train,Y_train,validation_split=0.2,epochs=int(len(X_train)/dividor_epoch),batch_size=batch_len,verbose=2)\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cced55a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/46\n",
      "75/75 - 7s - loss: 1.0258 - categorical_accuracy: 0.4785 - val_loss: 0.9269 - val_categorical_accuracy: 0.4813 - 7s/epoch - 89ms/step\n",
      "Epoch 2/46\n",
      "75/75 - 6s - loss: 0.8441 - categorical_accuracy: 0.6336 - val_loss: 0.7818 - val_categorical_accuracy: 0.6510 - 6s/epoch - 82ms/step\n",
      "Epoch 3/46\n",
      "75/75 - 7s - loss: 0.6739 - categorical_accuracy: 0.6974 - val_loss: 0.6918 - val_categorical_accuracy: 0.6905 - 7s/epoch - 96ms/step\n",
      "Epoch 4/46\n",
      "75/75 - 7s - loss: 0.6241 - categorical_accuracy: 0.7219 - val_loss: 0.6351 - val_categorical_accuracy: 0.7097 - 7s/epoch - 90ms/step\n",
      "Epoch 5/46\n",
      "75/75 - 7s - loss: 0.6029 - categorical_accuracy: 0.7353 - val_loss: 0.6116 - val_categorical_accuracy: 0.7353 - 7s/epoch - 87ms/step\n",
      "Epoch 6/46\n",
      "75/75 - 6s - loss: 0.5935 - categorical_accuracy: 0.7454 - val_loss: 0.6148 - val_categorical_accuracy: 0.7268 - 6s/epoch - 83ms/step\n",
      "Epoch 7/46\n",
      "75/75 - 6s - loss: 0.5950 - categorical_accuracy: 0.7494 - val_loss: 0.5982 - val_categorical_accuracy: 0.7513 - 6s/epoch - 84ms/step\n",
      "Epoch 8/46\n",
      "75/75 - 6s - loss: 0.5600 - categorical_accuracy: 0.7716 - val_loss: 0.6068 - val_categorical_accuracy: 0.7396 - 6s/epoch - 85ms/step\n",
      "Epoch 9/46\n",
      "75/75 - 6s - loss: 0.5431 - categorical_accuracy: 0.7806 - val_loss: 0.5841 - val_categorical_accuracy: 0.7481 - 6s/epoch - 81ms/step\n",
      "Epoch 10/46\n",
      "75/75 - 7s - loss: 0.5252 - categorical_accuracy: 0.7870 - val_loss: 0.7141 - val_categorical_accuracy: 0.7022 - 7s/epoch - 95ms/step\n",
      "Epoch 11/46\n",
      "75/75 - 6s - loss: 0.5220 - categorical_accuracy: 0.7852 - val_loss: 0.6269 - val_categorical_accuracy: 0.7215 - 6s/epoch - 83ms/step\n",
      "Epoch 12/46\n",
      "75/75 - 6s - loss: 0.5044 - categorical_accuracy: 0.7948 - val_loss: 0.5729 - val_categorical_accuracy: 0.7492 - 6s/epoch - 82ms/step\n",
      "Epoch 13/46\n",
      "75/75 - 6s - loss: 0.4945 - categorical_accuracy: 0.7982 - val_loss: 0.5480 - val_categorical_accuracy: 0.7652 - 6s/epoch - 85ms/step\n",
      "Epoch 14/46\n",
      "75/75 - 6s - loss: 0.4743 - categorical_accuracy: 0.8127 - val_loss: 0.5458 - val_categorical_accuracy: 0.7652 - 6s/epoch - 82ms/step\n",
      "Epoch 15/46\n",
      "75/75 - 6s - loss: 0.4705 - categorical_accuracy: 0.8110 - val_loss: 0.6336 - val_categorical_accuracy: 0.7439 - 6s/epoch - 84ms/step\n",
      "Epoch 16/46\n",
      "75/75 - 6s - loss: 0.4608 - categorical_accuracy: 0.8220 - val_loss: 0.5626 - val_categorical_accuracy: 0.7631 - 6s/epoch - 82ms/step\n",
      "Epoch 17/46\n",
      "75/75 - 6s - loss: 0.4396 - categorical_accuracy: 0.8308 - val_loss: 0.5843 - val_categorical_accuracy: 0.7535 - 6s/epoch - 82ms/step\n",
      "Epoch 18/46\n",
      "75/75 - 6s - loss: 0.4370 - categorical_accuracy: 0.8252 - val_loss: 0.5670 - val_categorical_accuracy: 0.7663 - 6s/epoch - 84ms/step\n",
      "Epoch 19/46\n",
      "75/75 - 6s - loss: 0.4244 - categorical_accuracy: 0.8300 - val_loss: 0.6083 - val_categorical_accuracy: 0.7556 - 6s/epoch - 83ms/step\n",
      "Epoch 20/46\n",
      "75/75 - 6s - loss: 0.4037 - categorical_accuracy: 0.8460 - val_loss: 0.5563 - val_categorical_accuracy: 0.7812 - 6s/epoch - 84ms/step\n",
      "Epoch 21/46\n",
      "75/75 - 6s - loss: 0.3852 - categorical_accuracy: 0.8535 - val_loss: 0.5598 - val_categorical_accuracy: 0.7759 - 6s/epoch - 81ms/step\n",
      "Epoch 22/46\n",
      "75/75 - 6s - loss: 0.3842 - categorical_accuracy: 0.8495 - val_loss: 0.6479 - val_categorical_accuracy: 0.7663 - 6s/epoch - 84ms/step\n",
      "Epoch 23/46\n",
      "75/75 - 7s - loss: 0.3860 - categorical_accuracy: 0.8524 - val_loss: 0.5829 - val_categorical_accuracy: 0.7748 - 7s/epoch - 88ms/step\n",
      "Epoch 24/46\n",
      "75/75 - 6s - loss: 0.3542 - categorical_accuracy: 0.8695 - val_loss: 0.5901 - val_categorical_accuracy: 0.7705 - 6s/epoch - 81ms/step\n",
      "Epoch 25/46\n",
      "75/75 - 6s - loss: 0.3293 - categorical_accuracy: 0.8796 - val_loss: 0.6216 - val_categorical_accuracy: 0.7759 - 6s/epoch - 85ms/step\n",
      "Epoch 26/46\n",
      "75/75 - 6s - loss: 0.3107 - categorical_accuracy: 0.8922 - val_loss: 0.6263 - val_categorical_accuracy: 0.7695 - 6s/epoch - 82ms/step\n",
      "Epoch 27/46\n",
      "75/75 - 6s - loss: 0.3055 - categorical_accuracy: 0.8898 - val_loss: 0.6550 - val_categorical_accuracy: 0.7577 - 6s/epoch - 83ms/step\n",
      "Epoch 28/46\n",
      "75/75 - 7s - loss: 0.2850 - categorical_accuracy: 0.9063 - val_loss: 0.6795 - val_categorical_accuracy: 0.7588 - 7s/epoch - 89ms/step\n",
      "Epoch 29/46\n",
      "75/75 - 6s - loss: 0.2782 - categorical_accuracy: 0.9069 - val_loss: 0.6757 - val_categorical_accuracy: 0.7673 - 6s/epoch - 82ms/step\n",
      "Epoch 30/46\n",
      "75/75 - 6s - loss: 0.2374 - categorical_accuracy: 0.9287 - val_loss: 0.7164 - val_categorical_accuracy: 0.7695 - 6s/epoch - 84ms/step\n",
      "Epoch 31/46\n",
      "75/75 - 6s - loss: 0.2169 - categorical_accuracy: 0.9397 - val_loss: 0.7741 - val_categorical_accuracy: 0.7716 - 6s/epoch - 83ms/step\n",
      "Epoch 32/46\n",
      "75/75 - 6s - loss: 0.2040 - categorical_accuracy: 0.9448 - val_loss: 0.7672 - val_categorical_accuracy: 0.7641 - 6s/epoch - 81ms/step\n",
      "Epoch 33/46\n",
      "75/75 - 6s - loss: 0.2032 - categorical_accuracy: 0.9426 - val_loss: 0.9097 - val_categorical_accuracy: 0.7577 - 6s/epoch - 86ms/step\n",
      "Epoch 34/46\n",
      "75/75 - 6s - loss: 0.1814 - categorical_accuracy: 0.9560 - val_loss: 0.8625 - val_categorical_accuracy: 0.7268 - 6s/epoch - 83ms/step\n",
      "Epoch 35/46\n",
      "75/75 - 6s - loss: 0.1627 - categorical_accuracy: 0.9632 - val_loss: 0.9461 - val_categorical_accuracy: 0.7620 - 6s/epoch - 82ms/step\n",
      "Epoch 36/46\n",
      "75/75 - 6s - loss: 0.1300 - categorical_accuracy: 0.9816 - val_loss: 0.9348 - val_categorical_accuracy: 0.7673 - 6s/epoch - 85ms/step\n",
      "Epoch 37/46\n",
      "75/75 - 6s - loss: 0.1119 - categorical_accuracy: 0.9864 - val_loss: 0.9926 - val_categorical_accuracy: 0.7652 - 6s/epoch - 82ms/step\n",
      "Epoch 38/46\n",
      "75/75 - 6s - loss: 0.1037 - categorical_accuracy: 0.9875 - val_loss: 1.0103 - val_categorical_accuracy: 0.7631 - 6s/epoch - 85ms/step\n",
      "Epoch 39/46\n",
      "75/75 - 6s - loss: 0.0896 - categorical_accuracy: 0.9957 - val_loss: 1.0606 - val_categorical_accuracy: 0.7695 - 6s/epoch - 83ms/step\n",
      "Epoch 40/46\n",
      "75/75 - 6s - loss: 0.0835 - categorical_accuracy: 0.9952 - val_loss: 1.0711 - val_categorical_accuracy: 0.7652 - 6s/epoch - 82ms/step\n",
      "Epoch 41/46\n",
      "75/75 - 6s - loss: 0.0929 - categorical_accuracy: 0.9885 - val_loss: 1.0742 - val_categorical_accuracy: 0.7663 - 6s/epoch - 85ms/step\n",
      "Epoch 42/46\n",
      "75/75 - 6s - loss: 0.1053 - categorical_accuracy: 0.9848 - val_loss: 1.2272 - val_categorical_accuracy: 0.7684 - 6s/epoch - 83ms/step\n",
      "Epoch 43/46\n",
      "75/75 - 6s - loss: 0.0895 - categorical_accuracy: 0.9909 - val_loss: 1.3015 - val_categorical_accuracy: 0.7577 - 6s/epoch - 84ms/step\n",
      "Epoch 44/46\n",
      "75/75 - 6s - loss: 0.1532 - categorical_accuracy: 0.9648 - val_loss: 1.2976 - val_categorical_accuracy: 0.7364 - 6s/epoch - 81ms/step\n",
      "Epoch 45/46\n",
      "75/75 - 6s - loss: 0.1264 - categorical_accuracy: 0.9789 - val_loss: 1.0777 - val_categorical_accuracy: 0.7481 - 6s/epoch - 82ms/step\n",
      "Epoch 46/46\n",
      "75/75 - 6s - loss: 0.0905 - categorical_accuracy: 0.9944 - val_loss: 1.2346 - val_categorical_accuracy: 0.7599 - 6s/epoch - 85ms/step\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 98, 98, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 49, 49, 10)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 24010)             0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 30)                720330    \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 722,383\n",
      "Trainable params: 722,383\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.2142817974090576\n",
      "Test accuracy: 0.7687713503837585\n"
     ]
    }
   ],
   "source": [
    "train(100,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "56757cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dividor_epoch,batch_len):\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "    dataset, labels, test_size=0.2, random_state=42)\n",
    "    X_train=X_train.reshape(-1,100,100,1)\n",
    "    X_test=X_test.reshape(-1,100,100,1)\n",
    "    Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "    Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "    Inp=layers.Input(shape=(100,100,1))\n",
    "    hidden=layers.Conv2D(10,kernel_size=(3,3),padding='valid',activation='relu')(Inp)\n",
    "    hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "    hidden=layers.Flatten()(hidden)\n",
    "    for i in range(3):\n",
    "        hidden=layers.Dense(30,activation=\"relu\",kernel_regularizer=regularizers.L2(0.0001),kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/math.pow(76.4,math.pow(i+1,-1)), maxval=1/math.pow(76.4,math.pow(i+1,-1)), seed=None))(hidden)\n",
    "        #hidden=layers.Dropout(0.2)(hidden)\n",
    "    output=layers.Dense(3,activation=\"softmax\",kernel_regularizer=regularizers.L2(0.0001),kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/math.pow(76.4,math.pow(4,-1)), maxval=1/math.pow(76.4,math.pow(4,-1)), seed=None))(hidden)\n",
    "    model=keras.Model(Inp,output)\n",
    "    model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=tf.keras.metrics.CategoricalAccuracy())\n",
    "    model.fit(X_train,Y_train,validation_split=0.2,epochs=int(len(X_train)/dividor_epoch),batch_size=batch_len,verbose=2)\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2bb31af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/46\n",
      "75/75 - 8s - loss: 0.8340 - categorical_accuracy: 0.6216 - val_loss: 0.7011 - val_categorical_accuracy: 0.6926 - 8s/epoch - 107ms/step\n",
      "Epoch 2/46\n",
      "75/75 - 9s - loss: 0.6478 - categorical_accuracy: 0.7144 - val_loss: 0.6224 - val_categorical_accuracy: 0.7289 - 9s/epoch - 123ms/step\n",
      "Epoch 3/46\n",
      "75/75 - 8s - loss: 0.6144 - categorical_accuracy: 0.7374 - val_loss: 0.6757 - val_categorical_accuracy: 0.7054 - 8s/epoch - 101ms/step\n",
      "Epoch 4/46\n",
      "75/75 - 7s - loss: 0.5658 - categorical_accuracy: 0.7622 - val_loss: 0.6344 - val_categorical_accuracy: 0.7279 - 7s/epoch - 96ms/step\n",
      "Epoch 5/46\n",
      "75/75 - 7s - loss: 0.5775 - categorical_accuracy: 0.7622 - val_loss: 0.6077 - val_categorical_accuracy: 0.7332 - 7s/epoch - 92ms/step\n",
      "Epoch 6/46\n",
      "75/75 - 7s - loss: 0.5488 - categorical_accuracy: 0.7691 - val_loss: 0.6069 - val_categorical_accuracy: 0.7321 - 7s/epoch - 96ms/step\n",
      "Epoch 7/46\n",
      "75/75 - 7s - loss: 0.5288 - categorical_accuracy: 0.7777 - val_loss: 0.5559 - val_categorical_accuracy: 0.7524 - 7s/epoch - 93ms/step\n",
      "Epoch 8/46\n",
      "75/75 - 6s - loss: 0.5206 - categorical_accuracy: 0.7857 - val_loss: 0.5922 - val_categorical_accuracy: 0.7364 - 6s/epoch - 83ms/step\n",
      "Epoch 9/46\n",
      "75/75 - 6s - loss: 0.5137 - categorical_accuracy: 0.7884 - val_loss: 0.5690 - val_categorical_accuracy: 0.7481 - 6s/epoch - 86ms/step\n",
      "Epoch 10/46\n",
      "75/75 - 7s - loss: 0.4876 - categorical_accuracy: 0.8001 - val_loss: 0.5659 - val_categorical_accuracy: 0.7545 - 7s/epoch - 96ms/step\n",
      "Epoch 11/46\n",
      "75/75 - 8s - loss: 0.4886 - categorical_accuracy: 0.7990 - val_loss: 0.6235 - val_categorical_accuracy: 0.7300 - 8s/epoch - 110ms/step\n",
      "Epoch 12/46\n",
      "75/75 - 7s - loss: 0.4700 - categorical_accuracy: 0.8070 - val_loss: 0.5643 - val_categorical_accuracy: 0.7460 - 7s/epoch - 95ms/step\n",
      "Epoch 13/46\n",
      "75/75 - 8s - loss: 0.4621 - categorical_accuracy: 0.8153 - val_loss: 0.5485 - val_categorical_accuracy: 0.7673 - 8s/epoch - 109ms/step\n",
      "Epoch 14/46\n",
      "75/75 - 7s - loss: 0.4375 - categorical_accuracy: 0.8241 - val_loss: 0.5376 - val_categorical_accuracy: 0.7705 - 7s/epoch - 90ms/step\n",
      "Epoch 15/46\n",
      "75/75 - 7s - loss: 0.4142 - categorical_accuracy: 0.8332 - val_loss: 0.5444 - val_categorical_accuracy: 0.7727 - 7s/epoch - 96ms/step\n",
      "Epoch 16/46\n",
      "75/75 - 7s - loss: 0.4122 - categorical_accuracy: 0.8284 - val_loss: 0.5403 - val_categorical_accuracy: 0.7759 - 7s/epoch - 95ms/step\n",
      "Epoch 17/46\n",
      "75/75 - 7s - loss: 0.3959 - categorical_accuracy: 0.8428 - val_loss: 0.5584 - val_categorical_accuracy: 0.7759 - 7s/epoch - 89ms/step\n",
      "Epoch 18/46\n",
      "75/75 - 7s - loss: 0.3713 - categorical_accuracy: 0.8500 - val_loss: 0.5777 - val_categorical_accuracy: 0.7609 - 7s/epoch - 91ms/step\n",
      "Epoch 19/46\n",
      "75/75 - 8s - loss: 0.3531 - categorical_accuracy: 0.8596 - val_loss: 0.5810 - val_categorical_accuracy: 0.7695 - 8s/epoch - 102ms/step\n",
      "Epoch 20/46\n",
      "75/75 - 9s - loss: 0.3419 - categorical_accuracy: 0.8724 - val_loss: 0.7250 - val_categorical_accuracy: 0.7343 - 9s/epoch - 115ms/step\n",
      "Epoch 21/46\n",
      "75/75 - 7s - loss: 0.3180 - categorical_accuracy: 0.8828 - val_loss: 0.6084 - val_categorical_accuracy: 0.7545 - 7s/epoch - 100ms/step\n",
      "Epoch 22/46\n",
      "75/75 - 7s - loss: 0.2954 - categorical_accuracy: 0.8989 - val_loss: 0.6381 - val_categorical_accuracy: 0.7577 - 7s/epoch - 95ms/step\n",
      "Epoch 23/46\n",
      "75/75 - 7s - loss: 0.2729 - categorical_accuracy: 0.9047 - val_loss: 0.6959 - val_categorical_accuracy: 0.7524 - 7s/epoch - 88ms/step\n",
      "Epoch 24/46\n",
      "75/75 - 7s - loss: 0.2590 - categorical_accuracy: 0.9095 - val_loss: 0.6816 - val_categorical_accuracy: 0.7716 - 7s/epoch - 98ms/step\n",
      "Epoch 25/46\n",
      "75/75 - 7s - loss: 0.2431 - categorical_accuracy: 0.9213 - val_loss: 0.7082 - val_categorical_accuracy: 0.7684 - 7s/epoch - 94ms/step\n",
      "Epoch 26/46\n",
      "75/75 - 9s - loss: 0.2224 - categorical_accuracy: 0.9301 - val_loss: 0.6954 - val_categorical_accuracy: 0.7599 - 9s/epoch - 126ms/step\n",
      "Epoch 27/46\n",
      "75/75 - 7s - loss: 0.2008 - categorical_accuracy: 0.9437 - val_loss: 0.7222 - val_categorical_accuracy: 0.7492 - 7s/epoch - 96ms/step\n",
      "Epoch 28/46\n",
      "75/75 - 8s - loss: 0.1650 - categorical_accuracy: 0.9610 - val_loss: 0.7882 - val_categorical_accuracy: 0.7599 - 8s/epoch - 108ms/step\n",
      "Epoch 29/46\n",
      "75/75 - 9s - loss: 0.1607 - categorical_accuracy: 0.9594 - val_loss: 0.8557 - val_categorical_accuracy: 0.7524 - 9s/epoch - 119ms/step\n",
      "Epoch 30/46\n",
      "75/75 - 8s - loss: 0.1524 - categorical_accuracy: 0.9632 - val_loss: 0.8378 - val_categorical_accuracy: 0.7311 - 8s/epoch - 110ms/step\n",
      "Epoch 31/46\n",
      "75/75 - 7s - loss: 0.1472 - categorical_accuracy: 0.9632 - val_loss: 0.8700 - val_categorical_accuracy: 0.7599 - 7s/epoch - 94ms/step\n",
      "Epoch 32/46\n",
      "75/75 - 9s - loss: 0.1204 - categorical_accuracy: 0.9741 - val_loss: 0.9453 - val_categorical_accuracy: 0.7545 - 9s/epoch - 123ms/step\n",
      "Epoch 33/46\n",
      "75/75 - 7s - loss: 0.0950 - categorical_accuracy: 0.9867 - val_loss: 1.0662 - val_categorical_accuracy: 0.7204 - 7s/epoch - 90ms/step\n",
      "Epoch 34/46\n",
      "75/75 - 8s - loss: 0.1305 - categorical_accuracy: 0.9685 - val_loss: 0.9671 - val_categorical_accuracy: 0.7300 - 8s/epoch - 106ms/step\n",
      "Epoch 35/46\n",
      "75/75 - 8s - loss: 0.0788 - categorical_accuracy: 0.9936 - val_loss: 1.0594 - val_categorical_accuracy: 0.7439 - 8s/epoch - 112ms/step\n",
      "Epoch 36/46\n",
      "75/75 - 8s - loss: 0.0665 - categorical_accuracy: 0.9976 - val_loss: 1.1115 - val_categorical_accuracy: 0.7417 - 8s/epoch - 101ms/step\n",
      "Epoch 37/46\n",
      "75/75 - 7s - loss: 0.0878 - categorical_accuracy: 0.9859 - val_loss: 1.0984 - val_categorical_accuracy: 0.7449 - 7s/epoch - 93ms/step\n",
      "Epoch 38/46\n",
      "75/75 - 7s - loss: 0.0687 - categorical_accuracy: 0.9947 - val_loss: 1.1448 - val_categorical_accuracy: 0.7535 - 7s/epoch - 87ms/step\n",
      "Epoch 39/46\n",
      "75/75 - 6s - loss: 0.0550 - categorical_accuracy: 0.9992 - val_loss: 1.1754 - val_categorical_accuracy: 0.7460 - 6s/epoch - 85ms/step\n",
      "Epoch 40/46\n",
      "75/75 - 6s - loss: 0.0498 - categorical_accuracy: 0.9997 - val_loss: 1.3231 - val_categorical_accuracy: 0.7236 - 6s/epoch - 84ms/step\n",
      "Epoch 41/46\n",
      "75/75 - 7s - loss: 0.0471 - categorical_accuracy: 1.0000 - val_loss: 1.2650 - val_categorical_accuracy: 0.7460 - 7s/epoch - 98ms/step\n",
      "Epoch 42/46\n",
      "75/75 - 7s - loss: 0.0435 - categorical_accuracy: 1.0000 - val_loss: 1.3091 - val_categorical_accuracy: 0.7471 - 7s/epoch - 92ms/step\n",
      "Epoch 43/46\n",
      "75/75 - 8s - loss: 0.0417 - categorical_accuracy: 1.0000 - val_loss: 1.3329 - val_categorical_accuracy: 0.7428 - 8s/epoch - 103ms/step\n",
      "Epoch 44/46\n",
      "75/75 - 8s - loss: 0.0405 - categorical_accuracy: 1.0000 - val_loss: 1.3484 - val_categorical_accuracy: 0.7460 - 8s/epoch - 105ms/step\n",
      "Epoch 45/46\n",
      "75/75 - 9s - loss: 0.0391 - categorical_accuracy: 1.0000 - val_loss: 1.3784 - val_categorical_accuracy: 0.7481 - 9s/epoch - 118ms/step\n",
      "Epoch 46/46\n",
      "75/75 - 9s - loss: 0.0375 - categorical_accuracy: 1.0000 - val_loss: 1.3772 - val_categorical_accuracy: 0.7396 - 9s/epoch - 115ms/step\n",
      "Model: \"model_14\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_17 (InputLayer)       [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 98, 98, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 49, 49, 10)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_16 (Flatten)        (None, 24010)             0         \n",
      "                                                                 \n",
      " dense_62 (Dense)            (None, 30)                720330    \n",
      "                                                                 \n",
      " dense_63 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_64 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_65 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 722,383\n",
      "Trainable params: 722,383\n",
      "Non-trainable params: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Test loss: 1.41386878490448\n",
      "Test accuracy: 0.7517064809799194\n"
     ]
    }
   ],
   "source": [
    "train(100,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00c0369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "def train(dividor_epoch,batch_len):\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "    dataset, labels, test_size=0.2, random_state=42)\n",
    "    X_train=X_train.reshape(-1,100,100,1)\n",
    "    X_test=X_test.reshape(-1,100,100,1)\n",
    "    Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "    Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "    \n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=layers.Conv2D(10,kernel_size=(3,3),padding='valid',activation='relu')(Inp)\n",
    "        hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        for i in range(3):\n",
    "            hidden=layers.Dense(30,activation=\"relu\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/math.pow(76.4,math.pow(i+1,-1)), maxval=1/math.pow(76.4,math.pow(i+1,-1)), seed=None))(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "        output=layers.Dense(3,activation=\"softmax\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/math.pow(76.4,math.pow(4,-1)), maxval=1/math.pow(76.4,math.pow(4,-1)), seed=None))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=[\"accuracy\"])\n",
    "        return model\n",
    "    \n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.2,epochs=int(len(X_train)/dividor_epoch),batch_size=batch_len,verbose=2,callbacks=callbacks_list)\n",
    "    model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc97a1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\manos\\AppData\\Local\\Temp/ipykernel_20532/2202079281.py:32: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/46\n",
      "28/28 - 6s - loss: 0.9926 - accuracy: 0.5142 - 6s/epoch - 219ms/step\n",
      "Epoch 2/46\n",
      "28/28 - 6s - loss: 0.7295 - accuracy: 0.7008 - 6s/epoch - 201ms/step\n",
      "Epoch 3/46\n",
      "28/28 - 6s - loss: 0.5935 - accuracy: 0.7430 - 6s/epoch - 232ms/step\n",
      "Epoch 4/46\n",
      "28/28 - 6s - loss: 0.5621 - accuracy: 0.7562 - 6s/epoch - 215ms/step\n",
      "Epoch 5/46\n",
      "28/28 - 7s - loss: 0.5405 - accuracy: 0.7679 - 7s/epoch - 235ms/step\n",
      "Epoch 6/46\n",
      "28/28 - 6s - loss: 0.5505 - accuracy: 0.7638 - 6s/epoch - 229ms/step\n",
      "Epoch 7/46\n",
      "28/28 - 9s - loss: 0.5296 - accuracy: 0.7753 - 9s/epoch - 307ms/step\n",
      "Epoch 8/46\n",
      "28/28 - 8s - loss: 0.5377 - accuracy: 0.7626 - 8s/epoch - 276ms/step\n",
      "Epoch 9/46\n",
      "28/28 - 8s - loss: 0.4951 - accuracy: 0.7889 - 8s/epoch - 297ms/step\n",
      "Epoch 10/46\n",
      "28/28 - 6s - loss: 0.4975 - accuracy: 0.7914 - 6s/epoch - 213ms/step\n",
      "Epoch 11/46\n",
      "28/28 - 6s - loss: 0.4913 - accuracy: 0.7897 - 6s/epoch - 215ms/step\n",
      "Epoch 12/46\n",
      "28/28 - 6s - loss: 0.4798 - accuracy: 0.7948 - 6s/epoch - 214ms/step\n",
      "Epoch 13/46\n",
      "28/28 - 6s - loss: 0.4891 - accuracy: 0.7958 - 6s/epoch - 207ms/step\n",
      "Epoch 14/46\n",
      "28/28 - 6s - loss: 0.4745 - accuracy: 0.7955 - 6s/epoch - 210ms/step\n",
      "Epoch 15/46\n",
      "28/28 - 6s - loss: 0.4583 - accuracy: 0.8067 - 6s/epoch - 224ms/step\n",
      "Epoch 16/46\n",
      "28/28 - 6s - loss: 0.4498 - accuracy: 0.8089 - 6s/epoch - 213ms/step\n",
      "Epoch 17/46\n",
      "28/28 - 6s - loss: 0.4671 - accuracy: 0.7989 - 6s/epoch - 217ms/step\n",
      "Epoch 18/46\n",
      "28/28 - 6s - loss: 0.4354 - accuracy: 0.8128 - 6s/epoch - 211ms/step\n",
      "Epoch 19/46\n",
      "28/28 - 6s - loss: 0.4317 - accuracy: 0.8160 - 6s/epoch - 211ms/step\n",
      "Epoch 20/46\n",
      "28/28 - 6s - loss: 0.4213 - accuracy: 0.8184 - 6s/epoch - 216ms/step\n",
      "Epoch 21/46\n",
      "28/28 - 6s - loss: 0.4135 - accuracy: 0.8216 - 6s/epoch - 218ms/step\n",
      "Epoch 22/46\n",
      "28/28 - 6s - loss: 0.4059 - accuracy: 0.8258 - 6s/epoch - 210ms/step\n",
      "Epoch 23/46\n",
      "28/28 - 6s - loss: 0.3999 - accuracy: 0.8304 - 6s/epoch - 217ms/step\n",
      "Epoch 24/46\n",
      "28/28 - 6s - loss: 0.3975 - accuracy: 0.8367 - 6s/epoch - 211ms/step\n",
      "Epoch 25/46\n",
      "28/28 - 6s - loss: 0.3966 - accuracy: 0.8294 - 6s/epoch - 220ms/step\n",
      "Epoch 26/46\n",
      "28/28 - 6s - loss: 0.3944 - accuracy: 0.8350 - 6s/epoch - 228ms/step\n",
      "Epoch 27/46\n",
      "28/28 - 6s - loss: 0.3654 - accuracy: 0.8402 - 6s/epoch - 211ms/step\n",
      "Epoch 28/46\n",
      "28/28 - 6s - loss: 0.3563 - accuracy: 0.8468 - 6s/epoch - 223ms/step\n",
      "Epoch 29/46\n",
      "28/28 - 6s - loss: 0.3530 - accuracy: 0.8492 - 6s/epoch - 211ms/step\n",
      "Epoch 30/46\n",
      "28/28 - 6s - loss: 0.3435 - accuracy: 0.8526 - 6s/epoch - 217ms/step\n",
      "Epoch 31/46\n",
      "28/28 - 6s - loss: 0.3338 - accuracy: 0.8594 - 6s/epoch - 223ms/step\n",
      "Epoch 32/46\n",
      "28/28 - 7s - loss: 0.3280 - accuracy: 0.8626 - 7s/epoch - 235ms/step\n",
      "Epoch 33/46\n",
      "28/28 - 7s - loss: 0.3118 - accuracy: 0.8697 - 7s/epoch - 254ms/step\n",
      "Epoch 34/46\n",
      "28/28 - 6s - loss: 0.3064 - accuracy: 0.8734 - 6s/epoch - 212ms/step\n",
      "Epoch 35/46\n",
      "28/28 - 6s - loss: 0.3012 - accuracy: 0.8758 - 6s/epoch - 214ms/step\n",
      "Epoch 36/46\n",
      "28/28 - 6s - loss: 0.2879 - accuracy: 0.8792 - 6s/epoch - 218ms/step\n",
      "Epoch 37/46\n",
      "28/28 - 6s - loss: 0.2832 - accuracy: 0.8814 - 6s/epoch - 209ms/step\n",
      "Epoch 38/46\n",
      "28/28 - 7s - loss: 0.2727 - accuracy: 0.8890 - 7s/epoch - 250ms/step\n",
      "Epoch 39/46\n",
      "28/28 - 6s - loss: 0.2707 - accuracy: 0.8895 - 6s/epoch - 215ms/step\n",
      "Epoch 40/46\n",
      "28/28 - 6s - loss: 0.2660 - accuracy: 0.8912 - 6s/epoch - 209ms/step\n",
      "Epoch 41/46\n",
      "28/28 - 6s - loss: 0.2516 - accuracy: 0.8968 - 6s/epoch - 216ms/step\n",
      "Epoch 42/46\n",
      "28/28 - 6s - loss: 0.2398 - accuracy: 0.9063 - 6s/epoch - 207ms/step\n",
      "Epoch 43/46\n",
      "28/28 - 6s - loss: 0.2217 - accuracy: 0.9117 - 6s/epoch - 211ms/step\n",
      "Epoch 44/46\n",
      "28/28 - 6s - loss: 0.2150 - accuracy: 0.9190 - 6s/epoch - 217ms/step\n",
      "Epoch 45/46\n",
      "28/28 - 6s - loss: 0.2178 - accuracy: 0.9124 - 6s/epoch - 213ms/step\n",
      "Epoch 46/46\n",
      "28/28 - 6s - loss: 0.2014 - accuracy: 0.9209 - 6s/epoch - 218ms/step\n",
      "4/4 - 0s - loss: 0.6959 - accuracy: 0.7406 - 493ms/epoch - 123ms/step\n",
      "Epoch 1/46\n",
      "28/28 - 6s - loss: 1.0108 - accuracy: 0.4849 - 6s/epoch - 220ms/step\n",
      "Epoch 2/46\n",
      "28/28 - 6s - loss: 0.8244 - accuracy: 0.6591 - 6s/epoch - 209ms/step\n",
      "Epoch 3/46\n",
      "28/28 - 7s - loss: 0.6771 - accuracy: 0.7040 - 7s/epoch - 253ms/step\n",
      "Epoch 4/46\n",
      "28/28 - 7s - loss: 0.5829 - accuracy: 0.7545 - 7s/epoch - 251ms/step\n",
      "Epoch 5/46\n",
      "28/28 - 7s - loss: 0.5509 - accuracy: 0.7657 - 7s/epoch - 263ms/step\n",
      "Epoch 6/46\n",
      "28/28 - 6s - loss: 0.5602 - accuracy: 0.7528 - 6s/epoch - 222ms/step\n",
      "Epoch 7/46\n",
      "28/28 - 6s - loss: 0.5337 - accuracy: 0.7743 - 6s/epoch - 222ms/step\n",
      "Epoch 8/46\n",
      "28/28 - 7s - loss: 0.5248 - accuracy: 0.7728 - 7s/epoch - 249ms/step\n",
      "Epoch 9/46\n",
      "28/28 - 6s - loss: 0.5441 - accuracy: 0.7679 - 6s/epoch - 230ms/step\n",
      "Epoch 10/46\n",
      "28/28 - 6s - loss: 0.5096 - accuracy: 0.7821 - 6s/epoch - 217ms/step\n",
      "Epoch 11/46\n",
      "28/28 - 6s - loss: 0.5070 - accuracy: 0.7823 - 6s/epoch - 218ms/step\n",
      "Epoch 12/46\n",
      "28/28 - 6s - loss: 0.4991 - accuracy: 0.7857 - 6s/epoch - 210ms/step\n",
      "Epoch 13/46\n",
      "28/28 - 6s - loss: 0.4823 - accuracy: 0.7984 - 6s/epoch - 200ms/step\n",
      "Epoch 14/46\n",
      "28/28 - 6s - loss: 0.4701 - accuracy: 0.8009 - 6s/epoch - 199ms/step\n",
      "Epoch 15/46\n",
      "28/28 - 6s - loss: 0.4724 - accuracy: 0.7997 - 6s/epoch - 206ms/step\n",
      "Epoch 16/46\n",
      "28/28 - 6s - loss: 0.4659 - accuracy: 0.8006 - 6s/epoch - 200ms/step\n",
      "Epoch 17/46\n",
      "28/28 - 6s - loss: 0.4474 - accuracy: 0.8092 - 6s/epoch - 197ms/step\n",
      "Epoch 18/46\n",
      "28/28 - 6s - loss: 0.4389 - accuracy: 0.8145 - 6s/epoch - 208ms/step\n",
      "Epoch 19/46\n",
      "28/28 - 6s - loss: 0.4388 - accuracy: 0.8080 - 6s/epoch - 200ms/step\n",
      "Epoch 20/46\n",
      "28/28 - 6s - loss: 0.4465 - accuracy: 0.8097 - 6s/epoch - 198ms/step\n",
      "Epoch 21/46\n",
      "28/28 - 6s - loss: 0.4188 - accuracy: 0.8180 - 6s/epoch - 205ms/step\n",
      "Epoch 22/46\n",
      "28/28 - 6s - loss: 0.4156 - accuracy: 0.8209 - 6s/epoch - 201ms/step\n",
      "Epoch 23/46\n",
      "28/28 - 6s - loss: 0.4049 - accuracy: 0.8294 - 6s/epoch - 202ms/step\n",
      "Epoch 24/46\n",
      "28/28 - 6s - loss: 0.3913 - accuracy: 0.8338 - 6s/epoch - 203ms/step\n",
      "Epoch 25/46\n",
      "28/28 - 5s - loss: 0.3796 - accuracy: 0.8370 - 5s/epoch - 195ms/step\n",
      "Epoch 26/46\n",
      "28/28 - 6s - loss: 0.3720 - accuracy: 0.8387 - 6s/epoch - 203ms/step\n",
      "Epoch 27/46\n",
      "28/28 - 6s - loss: 0.3971 - accuracy: 0.8277 - 6s/epoch - 200ms/step\n",
      "Epoch 28/46\n",
      "28/28 - 6s - loss: 0.3542 - accuracy: 0.8511 - 6s/epoch - 198ms/step\n",
      "Epoch 29/46\n",
      "28/28 - 7s - loss: 0.3552 - accuracy: 0.8485 - 7s/epoch - 245ms/step\n",
      "Epoch 30/46\n",
      "28/28 - 6s - loss: 0.3349 - accuracy: 0.8553 - 6s/epoch - 215ms/step\n",
      "Epoch 31/46\n",
      "28/28 - 6s - loss: 0.3206 - accuracy: 0.8631 - 6s/epoch - 199ms/step\n",
      "Epoch 32/46\n",
      "28/28 - 6s - loss: 0.3086 - accuracy: 0.8675 - 6s/epoch - 205ms/step\n",
      "Epoch 33/46\n",
      "28/28 - 6s - loss: 0.3236 - accuracy: 0.8651 - 6s/epoch - 197ms/step\n",
      "Epoch 34/46\n",
      "28/28 - 6s - loss: 0.2971 - accuracy: 0.8753 - 6s/epoch - 201ms/step\n",
      "Epoch 35/46\n",
      "28/28 - 6s - loss: 0.2864 - accuracy: 0.8814 - 6s/epoch - 209ms/step\n",
      "Epoch 36/46\n",
      "28/28 - 6s - loss: 0.2755 - accuracy: 0.8856 - 6s/epoch - 209ms/step\n",
      "Epoch 37/46\n",
      "28/28 - 6s - loss: 0.2675 - accuracy: 0.8934 - 6s/epoch - 209ms/step\n",
      "Epoch 38/46\n",
      "28/28 - 6s - loss: 0.2851 - accuracy: 0.8812 - 6s/epoch - 199ms/step\n",
      "Epoch 39/46\n",
      "28/28 - 6s - loss: 0.2518 - accuracy: 0.8982 - 6s/epoch - 205ms/step\n",
      "Epoch 40/46\n",
      "28/28 - 7s - loss: 0.2368 - accuracy: 0.9078 - 7s/epoch - 232ms/step\n",
      "Epoch 41/46\n",
      "28/28 - 6s - loss: 0.2245 - accuracy: 0.9117 - 6s/epoch - 199ms/step\n",
      "Epoch 42/46\n",
      "28/28 - 6s - loss: 0.2208 - accuracy: 0.9139 - 6s/epoch - 199ms/step\n",
      "Epoch 43/46\n",
      "28/28 - 6s - loss: 0.2231 - accuracy: 0.9100 - 6s/epoch - 203ms/step\n",
      "Epoch 44/46\n",
      "28/28 - 6s - loss: 0.2010 - accuracy: 0.9239 - 6s/epoch - 199ms/step\n",
      "Epoch 45/46\n",
      "28/28 - 6s - loss: 0.1977 - accuracy: 0.9197 - 6s/epoch - 209ms/step\n",
      "Epoch 46/46\n",
      "28/28 - 6s - loss: 0.1896 - accuracy: 0.9292 - 6s/epoch - 226ms/step\n",
      "4/4 - 0s - loss: 0.7103 - accuracy: 0.7491 - 447ms/epoch - 112ms/step\n",
      "Epoch 1/46\n",
      "28/28 - 6s - loss: 1.0440 - accuracy: 0.4595 - 6s/epoch - 216ms/step\n",
      "Epoch 2/46\n",
      "28/28 - 6s - loss: 0.8410 - accuracy: 0.6210 - 6s/epoch - 209ms/step\n",
      "Epoch 3/46\n",
      "28/28 - 6s - loss: 0.6600 - accuracy: 0.7196 - 6s/epoch - 198ms/step\n",
      "Epoch 4/46\n",
      "28/28 - 6s - loss: 0.5746 - accuracy: 0.7562 - 6s/epoch - 200ms/step\n",
      "Epoch 5/46\n",
      "28/28 - 6s - loss: 0.5686 - accuracy: 0.7548 - 6s/epoch - 207ms/step\n",
      "Epoch 6/46\n",
      "28/28 - 6s - loss: 0.5342 - accuracy: 0.7711 - 6s/epoch - 198ms/step\n",
      "Epoch 7/46\n",
      "28/28 - 5s - loss: 0.5343 - accuracy: 0.7660 - 5s/epoch - 195ms/step\n",
      "Epoch 8/46\n",
      "28/28 - 6s - loss: 0.5188 - accuracy: 0.7721 - 6s/epoch - 207ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/46\n",
      "28/28 - 6s - loss: 0.5107 - accuracy: 0.7804 - 6s/epoch - 200ms/step\n",
      "Epoch 10/46\n",
      "28/28 - 6s - loss: 0.5029 - accuracy: 0.7867 - 6s/epoch - 200ms/step\n",
      "Epoch 11/46\n",
      "28/28 - 6s - loss: 0.4995 - accuracy: 0.7887 - 6s/epoch - 206ms/step\n",
      "Epoch 12/46\n",
      "28/28 - 6s - loss: 0.4817 - accuracy: 0.7958 - 6s/epoch - 204ms/step\n",
      "Epoch 13/46\n",
      "28/28 - 6s - loss: 0.4858 - accuracy: 0.7906 - 6s/epoch - 206ms/step\n",
      "Epoch 14/46\n",
      "28/28 - 6s - loss: 0.4593 - accuracy: 0.8055 - 6s/epoch - 213ms/step\n",
      "Epoch 15/46\n",
      "28/28 - 6s - loss: 0.4599 - accuracy: 0.8048 - 6s/epoch - 199ms/step\n",
      "Epoch 16/46\n",
      "28/28 - 6s - loss: 0.4443 - accuracy: 0.8114 - 6s/epoch - 207ms/step\n",
      "Epoch 17/46\n",
      "28/28 - 6s - loss: 0.4454 - accuracy: 0.8141 - 6s/epoch - 198ms/step\n",
      "Epoch 18/46\n",
      "28/28 - 6s - loss: 0.4274 - accuracy: 0.8119 - 6s/epoch - 228ms/step\n",
      "Epoch 19/46\n",
      "28/28 - 6s - loss: 0.4209 - accuracy: 0.8243 - 6s/epoch - 217ms/step\n",
      "Epoch 20/46\n",
      "28/28 - 6s - loss: 0.4158 - accuracy: 0.8287 - 6s/epoch - 224ms/step\n",
      "Epoch 21/46\n",
      "28/28 - 7s - loss: 0.3994 - accuracy: 0.8324 - 7s/epoch - 245ms/step\n",
      "Epoch 22/46\n",
      "28/28 - 6s - loss: 0.3864 - accuracy: 0.8319 - 6s/epoch - 219ms/step\n",
      "Epoch 23/46\n",
      "28/28 - 6s - loss: 0.3792 - accuracy: 0.8409 - 6s/epoch - 199ms/step\n",
      "Epoch 24/46\n",
      "28/28 - 6s - loss: 0.3678 - accuracy: 0.8441 - 6s/epoch - 213ms/step\n",
      "Epoch 25/46\n",
      "28/28 - 6s - loss: 0.3597 - accuracy: 0.8468 - 6s/epoch - 204ms/step\n",
      "Epoch 26/46\n",
      "28/28 - 6s - loss: 0.3557 - accuracy: 0.8490 - 6s/epoch - 202ms/step\n",
      "Epoch 27/46\n",
      "28/28 - 6s - loss: 0.3339 - accuracy: 0.8602 - 6s/epoch - 209ms/step\n",
      "Epoch 28/46\n",
      "28/28 - 6s - loss: 0.3323 - accuracy: 0.8587 - 6s/epoch - 201ms/step\n",
      "Epoch 29/46\n",
      "28/28 - 6s - loss: 0.3233 - accuracy: 0.8624 - 6s/epoch - 202ms/step\n",
      "Epoch 30/46\n",
      "28/28 - 6s - loss: 0.3009 - accuracy: 0.8770 - 6s/epoch - 207ms/step\n",
      "Epoch 31/46\n",
      "28/28 - 6s - loss: 0.3066 - accuracy: 0.8760 - 6s/epoch - 203ms/step\n",
      "Epoch 32/46\n",
      "28/28 - 6s - loss: 0.3044 - accuracy: 0.8763 - 6s/epoch - 200ms/step\n",
      "Epoch 33/46\n",
      "28/28 - 6s - loss: 0.2773 - accuracy: 0.8873 - 6s/epoch - 206ms/step\n",
      "Epoch 34/46\n",
      "28/28 - 6s - loss: 0.2684 - accuracy: 0.8890 - 6s/epoch - 203ms/step\n",
      "Epoch 35/46\n",
      "28/28 - 6s - loss: 0.2597 - accuracy: 0.8897 - 6s/epoch - 211ms/step\n",
      "Epoch 36/46\n",
      "28/28 - 6s - loss: 0.2378 - accuracy: 0.9048 - 6s/epoch - 209ms/step\n",
      "Epoch 37/46\n",
      "28/28 - 6s - loss: 0.2369 - accuracy: 0.9056 - 6s/epoch - 203ms/step\n",
      "Epoch 38/46\n",
      "28/28 - 6s - loss: 0.2350 - accuracy: 0.9043 - 6s/epoch - 209ms/step\n",
      "Epoch 39/46\n",
      "28/28 - 5s - loss: 0.2090 - accuracy: 0.9151 - 5s/epoch - 196ms/step\n",
      "Epoch 40/46\n",
      "28/28 - 6s - loss: 0.2170 - accuracy: 0.9112 - 6s/epoch - 200ms/step\n",
      "Epoch 41/46\n",
      "28/28 - 6s - loss: 0.1948 - accuracy: 0.9263 - 6s/epoch - 209ms/step\n",
      "Epoch 42/46\n",
      "28/28 - 6s - loss: 0.1877 - accuracy: 0.9258 - 6s/epoch - 211ms/step\n",
      "Epoch 43/46\n",
      "28/28 - 6s - loss: 0.1624 - accuracy: 0.9383 - 6s/epoch - 211ms/step\n",
      "Epoch 44/46\n",
      "28/28 - 6s - loss: 0.1498 - accuracy: 0.9463 - 6s/epoch - 210ms/step\n",
      "Epoch 45/46\n",
      "28/28 - 6s - loss: 0.1388 - accuracy: 0.9505 - 6s/epoch - 203ms/step\n",
      "Epoch 46/46\n",
      "28/28 - 6s - loss: 0.1314 - accuracy: 0.9531 - 6s/epoch - 206ms/step\n",
      "4/4 - 1s - loss: 0.6349 - accuracy: 0.7901 - 567ms/epoch - 142ms/step\n",
      "Epoch 1/46\n",
      "28/28 - 6s - loss: 0.9636 - accuracy: 0.5281 - 6s/epoch - 216ms/step\n",
      "Epoch 2/46\n",
      "28/28 - 6s - loss: 0.7505 - accuracy: 0.6698 - 6s/epoch - 199ms/step\n",
      "Epoch 3/46\n",
      "28/28 - 6s - loss: 0.6548 - accuracy: 0.7162 - 6s/epoch - 202ms/step\n",
      "Epoch 4/46\n",
      "28/28 - 6s - loss: 0.5869 - accuracy: 0.7499 - 6s/epoch - 202ms/step\n",
      "Epoch 5/46\n",
      "28/28 - 6s - loss: 0.5483 - accuracy: 0.7616 - 6s/epoch - 213ms/step\n",
      "Epoch 6/46\n",
      "28/28 - 6s - loss: 0.5391 - accuracy: 0.7709 - 6s/epoch - 209ms/step\n",
      "Epoch 7/46\n",
      "28/28 - 6s - loss: 0.5274 - accuracy: 0.7728 - 6s/epoch - 202ms/step\n",
      "Epoch 8/46\n",
      "28/28 - 6s - loss: 0.5335 - accuracy: 0.7745 - 6s/epoch - 201ms/step\n",
      "Epoch 9/46\n",
      "28/28 - 6s - loss: 0.5122 - accuracy: 0.7823 - 6s/epoch - 209ms/step\n",
      "Epoch 10/46\n",
      "28/28 - 6s - loss: 0.5002 - accuracy: 0.7887 - 6s/epoch - 199ms/step\n",
      "Epoch 11/46\n",
      "28/28 - 6s - loss: 0.4953 - accuracy: 0.7884 - 6s/epoch - 201ms/step\n",
      "Epoch 12/46\n",
      "28/28 - 6s - loss: 0.4754 - accuracy: 0.7965 - 6s/epoch - 205ms/step\n",
      "Epoch 13/46\n",
      "28/28 - 6s - loss: 0.4626 - accuracy: 0.7984 - 6s/epoch - 201ms/step\n",
      "Epoch 14/46\n",
      "28/28 - 6s - loss: 0.4910 - accuracy: 0.7916 - 6s/epoch - 206ms/step\n",
      "Epoch 15/46\n",
      "28/28 - 6s - loss: 0.4663 - accuracy: 0.8004 - 6s/epoch - 202ms/step\n",
      "Epoch 16/46\n",
      "28/28 - 6s - loss: 0.4503 - accuracy: 0.8004 - 6s/epoch - 201ms/step\n",
      "Epoch 17/46\n",
      "28/28 - 6s - loss: 0.4406 - accuracy: 0.8089 - 6s/epoch - 207ms/step\n",
      "Epoch 18/46\n",
      "28/28 - 6s - loss: 0.4319 - accuracy: 0.8160 - 6s/epoch - 197ms/step\n",
      "Epoch 19/46\n",
      "28/28 - 6s - loss: 0.4234 - accuracy: 0.8221 - 6s/epoch - 201ms/step\n",
      "Epoch 20/46\n",
      "28/28 - 6s - loss: 0.4296 - accuracy: 0.8172 - 6s/epoch - 212ms/step\n",
      "Epoch 21/46\n",
      "28/28 - 6s - loss: 0.4083 - accuracy: 0.8255 - 6s/epoch - 203ms/step\n",
      "Epoch 22/46\n",
      "28/28 - 6s - loss: 0.3998 - accuracy: 0.8311 - 6s/epoch - 202ms/step\n",
      "Epoch 23/46\n",
      "28/28 - 6s - loss: 0.3906 - accuracy: 0.8343 - 6s/epoch - 208ms/step\n",
      "Epoch 24/46\n",
      "28/28 - 6s - loss: 0.3764 - accuracy: 0.8414 - 6s/epoch - 201ms/step\n",
      "Epoch 25/46\n",
      "28/28 - 6s - loss: 0.3726 - accuracy: 0.8438 - 6s/epoch - 201ms/step\n",
      "Epoch 26/46\n",
      "28/28 - 6s - loss: 0.3646 - accuracy: 0.8443 - 6s/epoch - 208ms/step\n",
      "Epoch 27/46\n",
      "28/28 - 6s - loss: 0.3472 - accuracy: 0.8536 - 6s/epoch - 202ms/step\n",
      "Epoch 28/46\n",
      "28/28 - 6s - loss: 0.3564 - accuracy: 0.8448 - 6s/epoch - 205ms/step\n",
      "Epoch 29/46\n",
      "28/28 - 6s - loss: 0.3477 - accuracy: 0.8558 - 6s/epoch - 201ms/step\n",
      "Epoch 30/46\n",
      "28/28 - 6s - loss: 0.3392 - accuracy: 0.8538 - 6s/epoch - 204ms/step\n",
      "Epoch 31/46\n",
      "28/28 - 6s - loss: 0.3232 - accuracy: 0.8624 - 6s/epoch - 210ms/step\n",
      "Epoch 32/46\n",
      "28/28 - 6s - loss: 0.3138 - accuracy: 0.8694 - 6s/epoch - 201ms/step\n",
      "Epoch 33/46\n",
      "28/28 - 6s - loss: 0.3198 - accuracy: 0.8616 - 6s/epoch - 197ms/step\n",
      "Epoch 34/46\n",
      "28/28 - 6s - loss: 0.2921 - accuracy: 0.8751 - 6s/epoch - 208ms/step\n",
      "Epoch 35/46\n",
      "28/28 - 6s - loss: 0.2890 - accuracy: 0.8804 - 6s/epoch - 206ms/step\n",
      "Epoch 36/46\n",
      "28/28 - 6s - loss: 0.2696 - accuracy: 0.8902 - 6s/epoch - 201ms/step\n",
      "Epoch 37/46\n",
      "28/28 - 6s - loss: 0.2576 - accuracy: 0.8992 - 6s/epoch - 217ms/step\n",
      "Epoch 38/46\n",
      "28/28 - 6s - loss: 0.2594 - accuracy: 0.8956 - 6s/epoch - 219ms/step\n",
      "Epoch 39/46\n",
      "28/28 - 6s - loss: 0.2390 - accuracy: 0.9100 - 6s/epoch - 214ms/step\n",
      "Epoch 40/46\n",
      "28/28 - 6s - loss: 0.2297 - accuracy: 0.9117 - 6s/epoch - 202ms/step\n",
      "Epoch 41/46\n",
      "28/28 - 6s - loss: 0.2172 - accuracy: 0.9180 - 6s/epoch - 198ms/step\n",
      "Epoch 42/46\n",
      "28/28 - 6s - loss: 0.2115 - accuracy: 0.9183 - 6s/epoch - 214ms/step\n",
      "Epoch 43/46\n",
      "28/28 - 6s - loss: 0.1985 - accuracy: 0.9261 - 6s/epoch - 201ms/step\n",
      "Epoch 44/46\n",
      "28/28 - 6s - loss: 0.1942 - accuracy: 0.9219 - 6s/epoch - 203ms/step\n",
      "Epoch 45/46\n",
      "28/28 - 7s - loss: 0.1761 - accuracy: 0.9327 - 7s/epoch - 241ms/step\n",
      "Epoch 46/46\n",
      "28/28 - 6s - loss: 0.1749 - accuracy: 0.9341 - 6s/epoch - 207ms/step\n",
      "4/4 - 0s - loss: 0.7193 - accuracy: 0.7611 - 394ms/epoch - 99ms/step\n",
      "Epoch 1/46\n",
      "28/28 - 6s - loss: 1.0011 - accuracy: 0.5040 - 6s/epoch - 224ms/step\n",
      "Epoch 2/46\n",
      "28/28 - 6s - loss: 0.7376 - accuracy: 0.6770 - 6s/epoch - 199ms/step\n",
      "Epoch 3/46\n",
      "28/28 - 5s - loss: 0.6132 - accuracy: 0.7363 - 5s/epoch - 196ms/step\n",
      "Epoch 4/46\n",
      "28/28 - 6s - loss: 0.5577 - accuracy: 0.7624 - 6s/epoch - 203ms/step\n",
      "Epoch 5/46\n",
      "28/28 - 6s - loss: 0.5638 - accuracy: 0.7524 - 6s/epoch - 200ms/step\n",
      "Epoch 6/46\n",
      "28/28 - 6s - loss: 0.5334 - accuracy: 0.7721 - 6s/epoch - 199ms/step\n",
      "Epoch 7/46\n",
      "28/28 - 6s - loss: 0.5482 - accuracy: 0.7658 - 6s/epoch - 210ms/step\n",
      "Epoch 8/46\n",
      "28/28 - 6s - loss: 0.5251 - accuracy: 0.7780 - 6s/epoch - 200ms/step\n",
      "Epoch 9/46\n",
      "28/28 - 6s - loss: 0.4921 - accuracy: 0.7856 - 6s/epoch - 201ms/step\n",
      "Epoch 10/46\n",
      "28/28 - 6s - loss: 0.4802 - accuracy: 0.7951 - 6s/epoch - 210ms/step\n",
      "Epoch 11/46\n",
      "28/28 - 5s - loss: 0.4771 - accuracy: 0.7946 - 5s/epoch - 194ms/step\n",
      "Epoch 12/46\n",
      "28/28 - 6s - loss: 0.4683 - accuracy: 0.8058 - 6s/epoch - 198ms/step\n",
      "Epoch 13/46\n",
      "28/28 - 6s - loss: 0.4562 - accuracy: 0.8021 - 6s/epoch - 209ms/step\n",
      "Epoch 14/46\n",
      "28/28 - 6s - loss: 0.4807 - accuracy: 0.7934 - 6s/epoch - 200ms/step\n",
      "Epoch 15/46\n",
      "28/28 - 6s - loss: 0.4483 - accuracy: 0.8082 - 6s/epoch - 203ms/step\n",
      "Epoch 16/46\n",
      "28/28 - 6s - loss: 0.4335 - accuracy: 0.8102 - 6s/epoch - 205ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/46\n",
      "28/28 - 6s - loss: 0.4382 - accuracy: 0.8092 - 6s/epoch - 196ms/step\n",
      "Epoch 18/46\n",
      "28/28 - 6s - loss: 0.4723 - accuracy: 0.7941 - 6s/epoch - 204ms/step\n",
      "Epoch 19/46\n",
      "28/28 - 6s - loss: 0.4478 - accuracy: 0.8039 - 6s/epoch - 201ms/step\n",
      "Epoch 20/46\n",
      "28/28 - 6s - loss: 0.4323 - accuracy: 0.8139 - 6s/epoch - 200ms/step\n",
      "Epoch 21/46\n",
      "28/28 - 6s - loss: 0.4159 - accuracy: 0.8258 - 6s/epoch - 208ms/step\n",
      "Epoch 22/46\n",
      "28/28 - 6s - loss: 0.4010 - accuracy: 0.8256 - 6s/epoch - 201ms/step\n",
      "Epoch 23/46\n",
      "28/28 - 6s - loss: 0.3763 - accuracy: 0.8378 - 6s/epoch - 200ms/step\n",
      "Epoch 24/46\n",
      "28/28 - 6s - loss: 0.3743 - accuracy: 0.8346 - 6s/epoch - 206ms/step\n",
      "Epoch 25/46\n",
      "28/28 - 5s - loss: 0.3849 - accuracy: 0.8356 - 5s/epoch - 195ms/step\n",
      "Epoch 26/46\n",
      "28/28 - 6s - loss: 0.3805 - accuracy: 0.8348 - 6s/epoch - 204ms/step\n",
      "Epoch 27/46\n",
      "28/28 - 6s - loss: 0.3486 - accuracy: 0.8514 - 6s/epoch - 206ms/step\n",
      "Epoch 28/46\n",
      "28/28 - 6s - loss: 0.3397 - accuracy: 0.8587 - 6s/epoch - 199ms/step\n",
      "Epoch 29/46\n",
      "28/28 - 6s - loss: 0.3319 - accuracy: 0.8644 - 6s/epoch - 200ms/step\n",
      "Epoch 30/46\n",
      "28/28 - 6s - loss: 0.3154 - accuracy: 0.8656 - 6s/epoch - 209ms/step\n",
      "Epoch 31/46\n",
      "28/28 - 6s - loss: 0.3101 - accuracy: 0.8692 - 6s/epoch - 199ms/step\n",
      "Epoch 32/46\n",
      "28/28 - 6s - loss: 0.3004 - accuracy: 0.8705 - 6s/epoch - 199ms/step\n",
      "Epoch 33/46\n",
      "28/28 - 6s - loss: 0.2817 - accuracy: 0.8873 - 6s/epoch - 200ms/step\n",
      "Epoch 34/46\n",
      "28/28 - 6s - loss: 0.2885 - accuracy: 0.8817 - 6s/epoch - 202ms/step\n",
      "Epoch 35/46\n",
      "28/28 - 6s - loss: 0.2699 - accuracy: 0.8936 - 6s/epoch - 208ms/step\n",
      "Epoch 36/46\n",
      "28/28 - 6s - loss: 0.2530 - accuracy: 0.8966 - 6s/epoch - 199ms/step\n",
      "Epoch 37/46\n",
      "28/28 - 6s - loss: 0.2527 - accuracy: 0.8985 - 6s/epoch - 200ms/step\n",
      "Epoch 38/46\n",
      "28/28 - 6s - loss: 0.2393 - accuracy: 0.9014 - 6s/epoch - 209ms/step\n",
      "Epoch 39/46\n",
      "28/28 - 6s - loss: 0.2511 - accuracy: 0.8980 - 6s/epoch - 200ms/step\n",
      "Epoch 40/46\n",
      "28/28 - 5s - loss: 0.2196 - accuracy: 0.9180 - 5s/epoch - 196ms/step\n",
      "Epoch 41/46\n",
      "28/28 - 6s - loss: 0.2221 - accuracy: 0.9153 - 6s/epoch - 204ms/step\n",
      "Epoch 42/46\n",
      "28/28 - 6s - loss: 0.1950 - accuracy: 0.9271 - 6s/epoch - 200ms/step\n",
      "Epoch 43/46\n",
      "28/28 - 6s - loss: 0.1863 - accuracy: 0.9351 - 6s/epoch - 201ms/step\n",
      "Epoch 44/46\n",
      "28/28 - 6s - loss: 0.1876 - accuracy: 0.9319 - 6s/epoch - 205ms/step\n",
      "Epoch 45/46\n",
      "28/28 - 6s - loss: 0.1650 - accuracy: 0.9427 - 6s/epoch - 199ms/step\n",
      "Epoch 46/46\n",
      "28/28 - 6s - loss: 0.1751 - accuracy: 0.9366 - 6s/epoch - 198ms/step\n",
      "4/4 - 1s - loss: 0.7128 - accuracy: 0.7658 - 500ms/epoch - 125ms/step\n",
      "Epoch 1/46\n",
      "28/28 - 6s - loss: 1.0230 - accuracy: 0.4816 - 6s/epoch - 219ms/step\n",
      "Epoch 2/46\n",
      "28/28 - 6s - loss: 0.7906 - accuracy: 0.6509 - 6s/epoch - 205ms/step\n",
      "Epoch 3/46\n",
      "28/28 - 6s - loss: 0.6396 - accuracy: 0.7233 - 6s/epoch - 209ms/step\n",
      "Epoch 4/46\n",
      "28/28 - 6s - loss: 0.5766 - accuracy: 0.7492 - 6s/epoch - 201ms/step\n",
      "Epoch 5/46\n",
      "28/28 - 6s - loss: 0.5603 - accuracy: 0.7529 - 6s/epoch - 208ms/step\n",
      "Epoch 6/46\n",
      "28/28 - 6s - loss: 0.5465 - accuracy: 0.7629 - 6s/epoch - 205ms/step\n",
      "Epoch 7/46\n",
      "28/28 - 6s - loss: 0.5338 - accuracy: 0.7692 - 6s/epoch - 197ms/step\n",
      "Epoch 8/46\n",
      "28/28 - 6s - loss: 0.5259 - accuracy: 0.7702 - 6s/epoch - 207ms/step\n",
      "Epoch 9/46\n",
      "28/28 - 6s - loss: 0.5333 - accuracy: 0.7760 - 6s/epoch - 200ms/step\n",
      "Epoch 10/46\n",
      "28/28 - 6s - loss: 0.4996 - accuracy: 0.7860 - 6s/epoch - 200ms/step\n",
      "Epoch 11/46\n",
      "28/28 - 6s - loss: 0.4905 - accuracy: 0.7914 - 6s/epoch - 208ms/step\n",
      "Epoch 12/46\n",
      "28/28 - 6s - loss: 0.4929 - accuracy: 0.7895 - 6s/epoch - 202ms/step\n",
      "Epoch 13/46\n",
      "28/28 - 5s - loss: 0.4758 - accuracy: 0.7970 - 5s/epoch - 196ms/step\n",
      "Epoch 14/46\n",
      "28/28 - 6s - loss: 0.4630 - accuracy: 0.8019 - 6s/epoch - 204ms/step\n",
      "Epoch 15/46\n",
      "28/28 - 6s - loss: 0.4864 - accuracy: 0.7926 - 6s/epoch - 198ms/step\n",
      "Epoch 16/46\n",
      "28/28 - 6s - loss: 0.4555 - accuracy: 0.8075 - 6s/epoch - 199ms/step\n",
      "Epoch 17/46\n",
      "28/28 - 6s - loss: 0.4460 - accuracy: 0.8119 - 6s/epoch - 213ms/step\n",
      "Epoch 18/46\n",
      "28/28 - 6s - loss: 0.4260 - accuracy: 0.8253 - 6s/epoch - 203ms/step\n",
      "Epoch 19/46\n",
      "28/28 - 6s - loss: 0.4146 - accuracy: 0.8243 - 6s/epoch - 205ms/step\n",
      "Epoch 20/46\n",
      "28/28 - 6s - loss: 0.4163 - accuracy: 0.8212 - 6s/epoch - 208ms/step\n",
      "Epoch 21/46\n",
      "28/28 - 6s - loss: 0.4239 - accuracy: 0.8195 - 6s/epoch - 201ms/step\n",
      "Epoch 22/46\n",
      "28/28 - 6s - loss: 0.4035 - accuracy: 0.8285 - 6s/epoch - 203ms/step\n",
      "Epoch 23/46\n",
      "28/28 - 6s - loss: 0.3784 - accuracy: 0.8380 - 6s/epoch - 201ms/step\n",
      "Epoch 24/46\n",
      "28/28 - 6s - loss: 0.3749 - accuracy: 0.8397 - 6s/epoch - 199ms/step\n",
      "Epoch 25/46\n",
      "28/28 - 6s - loss: 0.3582 - accuracy: 0.8497 - 6s/epoch - 210ms/step\n",
      "Epoch 26/46\n",
      "28/28 - 6s - loss: 0.3687 - accuracy: 0.8417 - 6s/epoch - 201ms/step\n",
      "Epoch 27/46\n",
      "28/28 - 6s - loss: 0.3476 - accuracy: 0.8536 - 6s/epoch - 202ms/step\n",
      "Epoch 28/46\n",
      "28/28 - 6s - loss: 0.3381 - accuracy: 0.8548 - 6s/epoch - 206ms/step\n",
      "Epoch 29/46\n",
      "28/28 - 6s - loss: 0.3440 - accuracy: 0.8546 - 6s/epoch - 200ms/step\n",
      "Epoch 30/46\n",
      "28/28 - 6s - loss: 0.3231 - accuracy: 0.8636 - 6s/epoch - 199ms/step\n",
      "Epoch 31/46\n",
      "28/28 - 6s - loss: 0.3080 - accuracy: 0.8678 - 6s/epoch - 210ms/step\n",
      "Epoch 32/46\n",
      "28/28 - 6s - loss: 0.2824 - accuracy: 0.8848 - 6s/epoch - 202ms/step\n",
      "Epoch 33/46\n",
      "28/28 - 6s - loss: 0.2832 - accuracy: 0.8822 - 6s/epoch - 202ms/step\n",
      "Epoch 34/46\n",
      "28/28 - 6s - loss: 0.2726 - accuracy: 0.8875 - 6s/epoch - 204ms/step\n",
      "Epoch 35/46\n",
      "28/28 - 6s - loss: 0.2544 - accuracy: 0.8970 - 6s/epoch - 202ms/step\n",
      "Epoch 36/46\n",
      "28/28 - 6s - loss: 0.2351 - accuracy: 0.9071 - 6s/epoch - 208ms/step\n",
      "Epoch 37/46\n",
      "28/28 - 6s - loss: 0.2373 - accuracy: 0.9017 - 6s/epoch - 200ms/step\n",
      "Epoch 38/46\n",
      "28/28 - 6s - loss: 0.2135 - accuracy: 0.9134 - 6s/epoch - 201ms/step\n",
      "Epoch 39/46\n",
      "28/28 - 6s - loss: 0.2044 - accuracy: 0.9197 - 6s/epoch - 209ms/step\n",
      "Epoch 40/46\n",
      "28/28 - 6s - loss: 0.1849 - accuracy: 0.9290 - 6s/epoch - 201ms/step\n",
      "Epoch 41/46\n",
      "28/28 - 6s - loss: 0.1775 - accuracy: 0.9329 - 6s/epoch - 203ms/step\n",
      "Epoch 42/46\n",
      "28/28 - 6s - loss: 0.1795 - accuracy: 0.9305 - 6s/epoch - 211ms/step\n",
      "Epoch 43/46\n",
      "28/28 - 6s - loss: 0.1823 - accuracy: 0.9319 - 6s/epoch - 200ms/step\n",
      "Epoch 44/46\n",
      "28/28 - 6s - loss: 0.1665 - accuracy: 0.9366 - 6s/epoch - 201ms/step\n",
      "Epoch 45/46\n",
      "28/28 - 6s - loss: 0.1464 - accuracy: 0.9466 - 6s/epoch - 208ms/step\n",
      "Epoch 46/46\n",
      "28/28 - 6s - loss: 0.1224 - accuracy: 0.9573 - 6s/epoch - 201ms/step\n",
      "4/4 - 0s - loss: 0.7525 - accuracy: 0.7470 - 465ms/epoch - 116ms/step\n",
      "Epoch 1/46\n",
      "28/28 - 6s - loss: 0.9995 - accuracy: 0.5004 - 6s/epoch - 219ms/step\n",
      "Epoch 2/46\n",
      "28/28 - 6s - loss: 0.7226 - accuracy: 0.6846 - 6s/epoch - 204ms/step\n",
      "Epoch 3/46\n",
      "28/28 - 6s - loss: 0.6102 - accuracy: 0.7399 - 6s/epoch - 201ms/step\n",
      "Epoch 4/46\n",
      "28/28 - 6s - loss: 0.5775 - accuracy: 0.7529 - 6s/epoch - 209ms/step\n",
      "Epoch 5/46\n",
      "28/28 - 6s - loss: 0.5541 - accuracy: 0.7636 - 6s/epoch - 200ms/step\n",
      "Epoch 6/46\n",
      "28/28 - 6s - loss: 0.5342 - accuracy: 0.7719 - 6s/epoch - 203ms/step\n",
      "Epoch 7/46\n",
      "28/28 - 6s - loss: 0.5317 - accuracy: 0.7738 - 6s/epoch - 211ms/step\n",
      "Epoch 8/46\n",
      "28/28 - 6s - loss: 0.5334 - accuracy: 0.7756 - 6s/epoch - 203ms/step\n",
      "Epoch 9/46\n",
      "28/28 - 6s - loss: 0.5337 - accuracy: 0.7653 - 6s/epoch - 212ms/step\n",
      "Epoch 10/46\n",
      "28/28 - 6s - loss: 0.5323 - accuracy: 0.7717 - 6s/epoch - 216ms/step\n",
      "Epoch 11/46\n",
      "28/28 - 6s - loss: 0.5063 - accuracy: 0.7843 - 6s/epoch - 210ms/step\n",
      "Epoch 12/46\n",
      "28/28 - 6s - loss: 0.5173 - accuracy: 0.7743 - 6s/epoch - 205ms/step\n",
      "Epoch 13/46\n",
      "28/28 - 6s - loss: 0.4955 - accuracy: 0.7904 - 6s/epoch - 209ms/step\n",
      "Epoch 14/46\n",
      "28/28 - 6s - loss: 0.4993 - accuracy: 0.7856 - 6s/epoch - 206ms/step\n",
      "Epoch 15/46\n",
      "28/28 - 6s - loss: 0.4951 - accuracy: 0.7951 - 6s/epoch - 209ms/step\n",
      "Epoch 16/46\n",
      "28/28 - 6s - loss: 0.4902 - accuracy: 0.7946 - 6s/epoch - 202ms/step\n",
      "Epoch 17/46\n",
      "28/28 - 6s - loss: 0.4728 - accuracy: 0.7997 - 6s/epoch - 209ms/step\n",
      "Epoch 18/46\n",
      "28/28 - 6s - loss: 0.4834 - accuracy: 0.7934 - 6s/epoch - 211ms/step\n",
      "Epoch 19/46\n",
      "28/28 - 6s - loss: 0.4763 - accuracy: 0.7965 - 6s/epoch - 204ms/step\n",
      "Epoch 20/46\n",
      "28/28 - 6s - loss: 0.4803 - accuracy: 0.7990 - 6s/epoch - 205ms/step\n",
      "Epoch 21/46\n",
      "28/28 - 6s - loss: 0.4473 - accuracy: 0.8104 - 6s/epoch - 210ms/step\n",
      "Epoch 22/46\n",
      "28/28 - 6s - loss: 0.4495 - accuracy: 0.8134 - 6s/epoch - 204ms/step\n",
      "Epoch 23/46\n",
      "28/28 - 6s - loss: 0.4452 - accuracy: 0.8146 - 6s/epoch - 203ms/step\n",
      "Epoch 24/46\n",
      "28/28 - 6s - loss: 0.4450 - accuracy: 0.8163 - 6s/epoch - 208ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/46\n",
      "28/28 - 6s - loss: 0.4336 - accuracy: 0.8178 - 6s/epoch - 203ms/step\n",
      "Epoch 26/46\n",
      "28/28 - 6s - loss: 0.4389 - accuracy: 0.8112 - 6s/epoch - 209ms/step\n",
      "Epoch 27/46\n",
      "28/28 - 6s - loss: 0.4254 - accuracy: 0.8222 - 6s/epoch - 203ms/step\n",
      "Epoch 28/46\n",
      "28/28 - 6s - loss: 0.4046 - accuracy: 0.8300 - 6s/epoch - 209ms/step\n",
      "Epoch 29/46\n",
      "28/28 - 6s - loss: 0.4147 - accuracy: 0.8261 - 6s/epoch - 218ms/step\n",
      "Epoch 30/46\n",
      "28/28 - 6s - loss: 0.3974 - accuracy: 0.8322 - 6s/epoch - 203ms/step\n",
      "Epoch 31/46\n",
      "28/28 - 6s - loss: 0.4278 - accuracy: 0.8180 - 6s/epoch - 205ms/step\n",
      "Epoch 32/46\n",
      "28/28 - 6s - loss: 0.3828 - accuracy: 0.8419 - 6s/epoch - 210ms/step\n",
      "Epoch 33/46\n",
      "28/28 - 6s - loss: 0.3754 - accuracy: 0.8436 - 6s/epoch - 201ms/step\n",
      "Epoch 34/46\n",
      "28/28 - 6s - loss: 0.3667 - accuracy: 0.8465 - 6s/epoch - 205ms/step\n",
      "Epoch 35/46\n",
      "28/28 - 6s - loss: 0.3681 - accuracy: 0.8461 - 6s/epoch - 208ms/step\n",
      "Epoch 36/46\n",
      "28/28 - 6s - loss: 0.3449 - accuracy: 0.8531 - 6s/epoch - 203ms/step\n",
      "Epoch 37/46\n",
      "28/28 - 6s - loss: 0.3375 - accuracy: 0.8619 - 6s/epoch - 211ms/step\n",
      "Epoch 38/46\n",
      "28/28 - 6s - loss: 0.3415 - accuracy: 0.8551 - 6s/epoch - 206ms/step\n",
      "Epoch 39/46\n",
      "28/28 - 6s - loss: 0.3467 - accuracy: 0.8558 - 6s/epoch - 203ms/step\n",
      "Epoch 40/46\n",
      "28/28 - 6s - loss: 0.3215 - accuracy: 0.8705 - 6s/epoch - 213ms/step\n",
      "Epoch 41/46\n",
      "28/28 - 6s - loss: 0.3165 - accuracy: 0.8744 - 6s/epoch - 205ms/step\n",
      "Epoch 42/46\n",
      "28/28 - 6s - loss: 0.2933 - accuracy: 0.8819 - 6s/epoch - 201ms/step\n",
      "Epoch 43/46\n",
      "28/28 - 6s - loss: 0.2930 - accuracy: 0.8797 - 6s/epoch - 209ms/step\n",
      "Epoch 44/46\n",
      "28/28 - 6s - loss: 0.2814 - accuracy: 0.8895 - 6s/epoch - 203ms/step\n",
      "Epoch 45/46\n",
      "28/28 - 6s - loss: 0.2685 - accuracy: 0.8909 - 6s/epoch - 203ms/step\n",
      "Epoch 46/46\n",
      "28/28 - 6s - loss: 0.2539 - accuracy: 0.9005 - 6s/epoch - 211ms/step\n",
      "4/4 - 0s - loss: 0.4820 - accuracy: 0.8000 - 429ms/epoch - 107ms/step\n",
      "Epoch 1/46\n",
      "28/28 - 6s - loss: 1.0074 - accuracy: 0.5511 - 6s/epoch - 212ms/step\n",
      "Epoch 2/46\n",
      "28/28 - 6s - loss: 0.7374 - accuracy: 0.6802 - 6s/epoch - 205ms/step\n",
      "Epoch 3/46\n",
      "28/28 - 6s - loss: 0.5970 - accuracy: 0.7265 - 6s/epoch - 205ms/step\n",
      "Epoch 4/46\n",
      "28/28 - 5s - loss: 0.5573 - accuracy: 0.7580 - 5s/epoch - 196ms/step\n",
      "Epoch 5/46\n",
      "28/28 - 6s - loss: 0.5897 - accuracy: 0.7387 - 6s/epoch - 208ms/step\n",
      "Epoch 6/46\n",
      "28/28 - 6s - loss: 0.5280 - accuracy: 0.7668 - 6s/epoch - 200ms/step\n",
      "Epoch 7/46\n",
      "28/28 - 6s - loss: 0.5131 - accuracy: 0.7780 - 6s/epoch - 198ms/step\n",
      "Epoch 8/46\n",
      "28/28 - 6s - loss: 0.4989 - accuracy: 0.7863 - 6s/epoch - 208ms/step\n",
      "Epoch 9/46\n",
      "28/28 - 6s - loss: 0.4954 - accuracy: 0.7821 - 6s/epoch - 201ms/step\n",
      "Epoch 10/46\n",
      "28/28 - 5s - loss: 0.4937 - accuracy: 0.7873 - 5s/epoch - 196ms/step\n",
      "Epoch 11/46\n",
      "28/28 - 6s - loss: 0.4854 - accuracy: 0.7953 - 6s/epoch - 205ms/step\n",
      "Epoch 12/46\n",
      "28/28 - 6s - loss: 0.4681 - accuracy: 0.7978 - 6s/epoch - 202ms/step\n",
      "Epoch 13/46\n",
      "28/28 - 6s - loss: 0.4571 - accuracy: 0.8053 - 6s/epoch - 200ms/step\n",
      "Epoch 14/46\n",
      "28/28 - 6s - loss: 0.4476 - accuracy: 0.8063 - 6s/epoch - 209ms/step\n",
      "Epoch 15/46\n",
      "28/28 - 6s - loss: 0.4333 - accuracy: 0.8134 - 6s/epoch - 211ms/step\n",
      "Epoch 16/46\n",
      "28/28 - 6s - loss: 0.4329 - accuracy: 0.8161 - 6s/epoch - 208ms/step\n",
      "Epoch 17/46\n",
      "28/28 - 6s - loss: 0.4174 - accuracy: 0.8158 - 6s/epoch - 199ms/step\n",
      "Epoch 18/46\n",
      "28/28 - 6s - loss: 0.4109 - accuracy: 0.8239 - 6s/epoch - 200ms/step\n",
      "Epoch 19/46\n",
      "28/28 - 6s - loss: 0.4124 - accuracy: 0.8261 - 6s/epoch - 212ms/step\n",
      "Epoch 20/46\n",
      "28/28 - 6s - loss: 0.3847 - accuracy: 0.8361 - 6s/epoch - 197ms/step\n",
      "Epoch 21/46\n",
      "28/28 - 6s - loss: 0.3771 - accuracy: 0.8419 - 6s/epoch - 204ms/step\n",
      "Epoch 22/46\n",
      "28/28 - 6s - loss: 0.3641 - accuracy: 0.8478 - 6s/epoch - 211ms/step\n",
      "Epoch 23/46\n",
      "28/28 - 6s - loss: 0.3497 - accuracy: 0.8534 - 6s/epoch - 201ms/step\n",
      "Epoch 24/46\n",
      "28/28 - 6s - loss: 0.3348 - accuracy: 0.8570 - 6s/epoch - 198ms/step\n",
      "Epoch 25/46\n",
      "28/28 - 6s - loss: 0.3248 - accuracy: 0.8587 - 6s/epoch - 206ms/step\n",
      "Epoch 26/46\n",
      "28/28 - 6s - loss: 0.3228 - accuracy: 0.8597 - 6s/epoch - 201ms/step\n",
      "Epoch 27/46\n",
      "28/28 - 6s - loss: 0.3181 - accuracy: 0.8658 - 6s/epoch - 202ms/step\n",
      "Epoch 28/46\n",
      "28/28 - 6s - loss: 0.3039 - accuracy: 0.8709 - 6s/epoch - 205ms/step\n",
      "Epoch 29/46\n",
      "28/28 - 6s - loss: 0.2842 - accuracy: 0.8792 - 6s/epoch - 202ms/step\n",
      "Epoch 30/46\n",
      "28/28 - 6s - loss: 0.2654 - accuracy: 0.8897 - 6s/epoch - 203ms/step\n",
      "Epoch 31/46\n",
      "28/28 - 6s - loss: 0.2545 - accuracy: 0.8934 - 6s/epoch - 204ms/step\n",
      "Epoch 32/46\n",
      "28/28 - 6s - loss: 0.2492 - accuracy: 0.9000 - 6s/epoch - 199ms/step\n",
      "Epoch 33/46\n",
      "28/28 - 6s - loss: 0.2295 - accuracy: 0.9075 - 6s/epoch - 209ms/step\n",
      "Epoch 34/46\n",
      "28/28 - 6s - loss: 0.2155 - accuracy: 0.9131 - 6s/epoch - 198ms/step\n",
      "Epoch 35/46\n",
      "28/28 - 6s - loss: 0.2126 - accuracy: 0.9144 - 6s/epoch - 197ms/step\n",
      "Epoch 36/46\n",
      "28/28 - 6s - loss: 0.2030 - accuracy: 0.9190 - 6s/epoch - 204ms/step\n",
      "Epoch 37/46\n",
      "28/28 - 6s - loss: 0.1928 - accuracy: 0.9268 - 6s/epoch - 198ms/step\n",
      "Epoch 38/46\n",
      "28/28 - 6s - loss: 0.1822 - accuracy: 0.9275 - 6s/epoch - 200ms/step\n",
      "Epoch 39/46\n",
      "28/28 - 6s - loss: 0.1614 - accuracy: 0.9354 - 6s/epoch - 210ms/step\n",
      "Epoch 40/46\n",
      "28/28 - 6s - loss: 0.1662 - accuracy: 0.9354 - 6s/epoch - 203ms/step\n",
      "Epoch 41/46\n",
      "28/28 - 6s - loss: 0.1605 - accuracy: 0.9414 - 6s/epoch - 201ms/step\n",
      "Epoch 42/46\n",
      "28/28 - 6s - loss: 0.1362 - accuracy: 0.9529 - 6s/epoch - 205ms/step\n",
      "Epoch 43/46\n",
      "28/28 - 6s - loss: 0.1362 - accuracy: 0.9478 - 6s/epoch - 198ms/step\n",
      "Epoch 44/46\n",
      "28/28 - 6s - loss: 0.1277 - accuracy: 0.9576 - 6s/epoch - 198ms/step\n",
      "Epoch 45/46\n",
      "28/28 - 6s - loss: 0.1020 - accuracy: 0.9678 - 6s/epoch - 205ms/step\n",
      "Epoch 46/46\n",
      "28/28 - 6s - loss: 0.0988 - accuracy: 0.9678 - 6s/epoch - 199ms/step\n",
      "4/4 - 0s - loss: 0.9419 - accuracy: 0.7248 - 393ms/epoch - 98ms/step\n",
      "MLP: 75.98% (2.36%)\n",
      "Epoch 1/46\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.48132, saving model to weights.hdf5\n",
      "25/25 - 7s - loss: 1.0543 - accuracy: 0.4558 - val_loss: 1.0171 - val_accuracy: 0.4813 - 7s/epoch - 289ms/step\n",
      "Epoch 2/46\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.48132 to 0.63607, saving model to weights.hdf5\n",
      "25/25 - 6s - loss: 0.9309 - accuracy: 0.5594 - val_loss: 0.8413 - val_accuracy: 0.6361 - 6s/epoch - 228ms/step\n",
      "Epoch 3/46\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.63607 to 0.68623, saving model to weights.hdf5\n",
      "25/25 - 6s - loss: 0.7190 - accuracy: 0.6805 - val_loss: 0.6991 - val_accuracy: 0.6862 - 6s/epoch - 238ms/step\n",
      "Epoch 4/46\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.68623 to 0.71185, saving model to weights.hdf5\n",
      "25/25 - 6s - loss: 0.6311 - accuracy: 0.7187 - val_loss: 0.6368 - val_accuracy: 0.7118 - 6s/epoch - 233ms/step\n",
      "Epoch 5/46\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.71185 to 0.73106, saving model to weights.hdf5\n",
      "25/25 - 6s - loss: 0.5772 - accuracy: 0.7545 - val_loss: 0.6063 - val_accuracy: 0.7311 - 6s/epoch - 229ms/step\n",
      "Epoch 6/46\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.73106 to 0.73319, saving model to weights.hdf5\n",
      "25/25 - 6s - loss: 0.5530 - accuracy: 0.7643 - val_loss: 0.5991 - val_accuracy: 0.7332 - 6s/epoch - 231ms/step\n",
      "Epoch 7/46\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.73319 to 0.75133, saving model to weights.hdf5\n",
      "25/25 - 6s - loss: 0.5232 - accuracy: 0.7806 - val_loss: 0.5606 - val_accuracy: 0.7513 - 6s/epoch - 238ms/step\n",
      "Epoch 8/46\n",
      "\n",
      "Epoch 8: val_accuracy did not improve from 0.75133\n",
      "25/25 - 6s - loss: 0.5210 - accuracy: 0.7857 - val_loss: 0.5865 - val_accuracy: 0.7385 - 6s/epoch - 228ms/step\n",
      "Epoch 9/46\n",
      "\n",
      "Epoch 9: val_accuracy did not improve from 0.75133\n",
      "25/25 - 6s - loss: 0.5310 - accuracy: 0.7753 - val_loss: 0.6089 - val_accuracy: 0.7257 - 6s/epoch - 230ms/step\n",
      "Epoch 10/46\n",
      "\n",
      "Epoch 10: val_accuracy did not improve from 0.75133\n",
      "25/25 - 6s - loss: 0.5222 - accuracy: 0.7798 - val_loss: 0.5737 - val_accuracy: 0.7460 - 6s/epoch - 222ms/step\n",
      "Epoch 11/46\n",
      "\n",
      "Epoch 11: val_accuracy improved from 0.75133 to 0.75240, saving model to weights.hdf5\n",
      "25/25 - 6s - loss: 0.4972 - accuracy: 0.7905 - val_loss: 0.5502 - val_accuracy: 0.7524 - 6s/epoch - 234ms/step\n",
      "Epoch 12/46\n",
      "\n",
      "Epoch 12: val_accuracy improved from 0.75240 to 0.75774, saving model to weights.hdf5\n",
      "25/25 - 6s - loss: 0.4874 - accuracy: 0.7937 - val_loss: 0.5444 - val_accuracy: 0.7577 - 6s/epoch - 239ms/step\n",
      "Epoch 13/46\n",
      "\n",
      "Epoch 13: val_accuracy did not improve from 0.75774\n",
      "25/25 - 6s - loss: 0.4917 - accuracy: 0.7889 - val_loss: 0.5553 - val_accuracy: 0.7577 - 6s/epoch - 225ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/46\n",
      "\n",
      "Epoch 14: val_accuracy improved from 0.75774 to 0.75880, saving model to weights.hdf5\n",
      "25/25 - 6s - loss: 0.4813 - accuracy: 0.7956 - val_loss: 0.5462 - val_accuracy: 0.7588 - 6s/epoch - 232ms/step\n",
      "Epoch 15/46\n",
      "\n",
      "Epoch 15: val_accuracy improved from 0.75880 to 0.76414, saving model to weights.hdf5\n",
      "25/25 - 6s - loss: 0.4697 - accuracy: 0.8030 - val_loss: 0.5257 - val_accuracy: 0.7641 - 6s/epoch - 244ms/step\n",
      "Epoch 16/46\n",
      "\n",
      "Epoch 16: val_accuracy did not improve from 0.76414\n",
      "25/25 - 6s - loss: 0.4615 - accuracy: 0.8076 - val_loss: 0.5301 - val_accuracy: 0.7609 - 6s/epoch - 222ms/step\n",
      "Epoch 17/46\n",
      "\n",
      "Epoch 17: val_accuracy did not improve from 0.76414\n",
      "25/25 - 6s - loss: 0.4488 - accuracy: 0.8070 - val_loss: 0.5245 - val_accuracy: 0.7567 - 6s/epoch - 225ms/step\n",
      "Epoch 18/46\n",
      "\n",
      "Epoch 18: val_accuracy did not improve from 0.76414\n",
      "25/25 - 6s - loss: 0.4423 - accuracy: 0.8164 - val_loss: 0.5167 - val_accuracy: 0.7631 - 6s/epoch - 232ms/step\n",
      "Epoch 19/46\n",
      "\n",
      "Epoch 19: val_accuracy improved from 0.76414 to 0.77268, saving model to weights.hdf5\n",
      "25/25 - 6s - loss: 0.4444 - accuracy: 0.8118 - val_loss: 0.5197 - val_accuracy: 0.7727 - 6s/epoch - 232ms/step\n",
      "Epoch 20/46\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 0.77268\n",
      "25/25 - 6s - loss: 0.4343 - accuracy: 0.8127 - val_loss: 0.5187 - val_accuracy: 0.7673 - 6s/epoch - 231ms/step\n",
      "Epoch 21/46\n",
      "\n",
      "Epoch 21: val_accuracy did not improve from 0.77268\n",
      "25/25 - 6s - loss: 0.4233 - accuracy: 0.8196 - val_loss: 0.5534 - val_accuracy: 0.7492 - 6s/epoch - 232ms/step\n",
      "Epoch 22/46\n",
      "\n",
      "Epoch 22: val_accuracy did not improve from 0.77268\n",
      "25/25 - 6s - loss: 0.4255 - accuracy: 0.8257 - val_loss: 0.5356 - val_accuracy: 0.7684 - 6s/epoch - 229ms/step\n",
      "Epoch 23/46\n",
      "\n",
      "Epoch 23: val_accuracy did not improve from 0.77268\n",
      "25/25 - 6s - loss: 0.4058 - accuracy: 0.8271 - val_loss: 0.5223 - val_accuracy: 0.7673 - 6s/epoch - 235ms/step\n",
      "Epoch 24/46\n",
      "\n",
      "Epoch 24: val_accuracy did not improve from 0.77268\n",
      "25/25 - 6s - loss: 0.4120 - accuracy: 0.8199 - val_loss: 0.5592 - val_accuracy: 0.7545 - 6s/epoch - 232ms/step\n",
      "Epoch 25/46\n",
      "\n",
      "Epoch 25: val_accuracy did not improve from 0.77268\n",
      "25/25 - 6s - loss: 0.4000 - accuracy: 0.8260 - val_loss: 0.5195 - val_accuracy: 0.7716 - 6s/epoch - 225ms/step\n",
      "Epoch 26/46\n",
      "\n",
      "Epoch 26: val_accuracy did not improve from 0.77268\n",
      "25/25 - 6s - loss: 0.3957 - accuracy: 0.8348 - val_loss: 0.5421 - val_accuracy: 0.7684 - 6s/epoch - 232ms/step\n",
      "Epoch 27/46\n",
      "\n",
      "Epoch 27: val_accuracy improved from 0.77268 to 0.77588, saving model to weights.hdf5\n",
      "25/25 - 6s - loss: 0.3857 - accuracy: 0.8359 - val_loss: 0.5104 - val_accuracy: 0.7759 - 6s/epoch - 237ms/step\n",
      "Epoch 28/46\n",
      "\n",
      "Epoch 28: val_accuracy did not improve from 0.77588\n",
      "25/25 - 6s - loss: 0.3635 - accuracy: 0.8415 - val_loss: 0.5207 - val_accuracy: 0.7737 - 6s/epoch - 226ms/step\n",
      "Epoch 29/46\n",
      "\n",
      "Epoch 29: val_accuracy did not improve from 0.77588\n",
      "25/25 - 6s - loss: 0.3688 - accuracy: 0.8449 - val_loss: 0.5286 - val_accuracy: 0.7652 - 6s/epoch - 237ms/step\n",
      "Epoch 30/46\n",
      "\n",
      "Epoch 30: val_accuracy improved from 0.77588 to 0.77908, saving model to weights.hdf5\n",
      "25/25 - 6s - loss: 0.3548 - accuracy: 0.8447 - val_loss: 0.5366 - val_accuracy: 0.7791 - 6s/epoch - 232ms/step\n",
      "Epoch 31/46\n",
      "\n",
      "Epoch 31: val_accuracy did not improve from 0.77908\n",
      "25/25 - 6s - loss: 0.3537 - accuracy: 0.8503 - val_loss: 0.5530 - val_accuracy: 0.7716 - 6s/epoch - 230ms/step\n",
      "Epoch 32/46\n",
      "\n",
      "Epoch 32: val_accuracy did not improve from 0.77908\n",
      "25/25 - 6s - loss: 0.3340 - accuracy: 0.8626 - val_loss: 0.5278 - val_accuracy: 0.7748 - 6s/epoch - 230ms/step\n",
      "Epoch 33/46\n",
      "\n",
      "Epoch 33: val_accuracy did not improve from 0.77908\n",
      "25/25 - 6s - loss: 0.3176 - accuracy: 0.8644 - val_loss: 0.5372 - val_accuracy: 0.7652 - 6s/epoch - 229ms/step\n",
      "Epoch 34/46\n",
      "\n",
      "Epoch 34: val_accuracy did not improve from 0.77908\n",
      "25/25 - 6s - loss: 0.3148 - accuracy: 0.8714 - val_loss: 0.5353 - val_accuracy: 0.7759 - 6s/epoch - 234ms/step\n",
      "Epoch 35/46\n",
      "\n",
      "Epoch 35: val_accuracy did not improve from 0.77908\n",
      "25/25 - 6s - loss: 0.3110 - accuracy: 0.8695 - val_loss: 0.5396 - val_accuracy: 0.7716 - 6s/epoch - 227ms/step\n",
      "Epoch 36/46\n",
      "\n",
      "Epoch 36: val_accuracy did not improve from 0.77908\n",
      "25/25 - 6s - loss: 0.2921 - accuracy: 0.8847 - val_loss: 0.5857 - val_accuracy: 0.7791 - 6s/epoch - 227ms/step\n",
      "Epoch 37/46\n",
      "\n",
      "Epoch 37: val_accuracy did not improve from 0.77908\n",
      "25/25 - 6s - loss: 0.2911 - accuracy: 0.8879 - val_loss: 0.5476 - val_accuracy: 0.7737 - 6s/epoch - 233ms/step\n",
      "Epoch 38/46\n",
      "\n",
      "Epoch 38: val_accuracy did not improve from 0.77908\n",
      "25/25 - 6s - loss: 0.2840 - accuracy: 0.8836 - val_loss: 0.5597 - val_accuracy: 0.7769 - 6s/epoch - 228ms/step\n",
      "Epoch 39/46\n",
      "\n",
      "Epoch 39: val_accuracy did not improve from 0.77908\n",
      "25/25 - 6s - loss: 0.2713 - accuracy: 0.8898 - val_loss: 0.5895 - val_accuracy: 0.7673 - 6s/epoch - 225ms/step\n",
      "Epoch 40/46\n",
      "\n",
      "Epoch 40: val_accuracy did not improve from 0.77908\n",
      "25/25 - 6s - loss: 0.2638 - accuracy: 0.8927 - val_loss: 0.5702 - val_accuracy: 0.7727 - 6s/epoch - 233ms/step\n",
      "Epoch 41/46\n",
      "\n",
      "Epoch 41: val_accuracy did not improve from 0.77908\n",
      "25/25 - 6s - loss: 0.2494 - accuracy: 0.8999 - val_loss: 0.5930 - val_accuracy: 0.7641 - 6s/epoch - 223ms/step\n",
      "Epoch 42/46\n",
      "\n",
      "Epoch 42: val_accuracy did not improve from 0.77908\n",
      "25/25 - 6s - loss: 0.2437 - accuracy: 0.9037 - val_loss: 0.5916 - val_accuracy: 0.7673 - 6s/epoch - 227ms/step\n",
      "Epoch 43/46\n",
      "\n",
      "Epoch 43: val_accuracy did not improve from 0.77908\n",
      "25/25 - 6s - loss: 0.2276 - accuracy: 0.9077 - val_loss: 0.6081 - val_accuracy: 0.7609 - 6s/epoch - 235ms/step\n",
      "Epoch 44/46\n",
      "\n",
      "Epoch 44: val_accuracy did not improve from 0.77908\n",
      "25/25 - 6s - loss: 0.2274 - accuracy: 0.9114 - val_loss: 0.6240 - val_accuracy: 0.7673 - 6s/epoch - 226ms/step\n",
      "Epoch 45/46\n",
      "\n",
      "Epoch 45: val_accuracy did not improve from 0.77908\n",
      "25/25 - 6s - loss: 0.2203 - accuracy: 0.9130 - val_loss: 0.6459 - val_accuracy: 0.7567 - 6s/epoch - 235ms/step\n",
      "Epoch 46/46\n",
      "\n",
      "Epoch 46: val_accuracy did not improve from 0.77908\n",
      "25/25 - 6s - loss: 0.1978 - accuracy: 0.9282 - val_loss: 0.6329 - val_accuracy: 0.7471 - 6s/epoch - 226ms/step\n",
      "Model: \"model_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_22 (InputLayer)       [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 98, 98, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 49, 49, 10)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 24010)             0         \n",
      "                                                                 \n",
      " dense_84 (Dense)            (None, 30)                720330    \n",
      "                                                                 \n",
      " dense_85 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_86 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_87 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 722,383\n",
      "Trainable params: 722,383\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5348971486091614\n",
      "Test accuracy: 0.7747440338134766\n"
     ]
    }
   ],
   "source": [
    "train(100,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8b9a145",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "def train(epochs_num,batch_len):\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "    dataset, labels, test_size=0.2, random_state=42)\n",
    "    X_train=X_train.reshape(-1,100,100,1)\n",
    "    X_test=X_test.reshape(-1,100,100,1)\n",
    "    Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "    Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "    \n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(2):\n",
    "            hidden=layers.Conv2D(10,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(1,1))(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        for i in range(5):\n",
    "            hidden=layers.Dense(30,activation=\"relu\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/math.pow(76.4,math.pow(i+1,-1)), maxval=1/math.pow(76.4,math.pow(i+1,-1)), seed=None))(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "        output=layers.Dense(3,activation=\"softmax\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/math.pow(76.4,math.pow(4,-1)), maxval=1/math.pow(76.4,math.pow(4,-1)), seed=None))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=[\"accuracy\"])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.2,epochs=epochs_num,batch_size=batch_len,verbose=2)\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b5da09f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "19/19 - 28s - loss: 1.0171 - accuracy: 0.5044 - val_loss: 0.8950 - val_accuracy: 0.6339 - 28s/epoch - 1s/step\n",
      "Epoch 2/30\n",
      "19/19 - 26s - loss: 0.7742 - accuracy: 0.6595 - val_loss: 0.7092 - val_accuracy: 0.6948 - 26s/epoch - 1s/step\n",
      "Epoch 3/30\n",
      "19/19 - 26s - loss: 0.6319 - accuracy: 0.7238 - val_loss: 0.6364 - val_accuracy: 0.7182 - 26s/epoch - 1s/step\n",
      "Epoch 4/30\n",
      "19/19 - 26s - loss: 0.5573 - accuracy: 0.7670 - val_loss: 0.5801 - val_accuracy: 0.7449 - 26s/epoch - 1s/step\n",
      "Epoch 5/30\n",
      "19/19 - 25s - loss: 0.5644 - accuracy: 0.7713 - val_loss: 0.6047 - val_accuracy: 0.7460 - 25s/epoch - 1s/step\n",
      "Epoch 6/30\n",
      "19/19 - 26s - loss: 0.5452 - accuracy: 0.7697 - val_loss: 0.5508 - val_accuracy: 0.7631 - 26s/epoch - 1s/step\n",
      "Epoch 7/30\n",
      "19/19 - 26s - loss: 0.5079 - accuracy: 0.7857 - val_loss: 0.5617 - val_accuracy: 0.7577 - 26s/epoch - 1s/step\n",
      "Epoch 8/30\n",
      "19/19 - 26s - loss: 0.5032 - accuracy: 0.7881 - val_loss: 0.5327 - val_accuracy: 0.7673 - 26s/epoch - 1s/step\n",
      "Epoch 9/30\n",
      "19/19 - 27s - loss: 0.4800 - accuracy: 0.8017 - val_loss: 0.5738 - val_accuracy: 0.7492 - 27s/epoch - 1s/step\n",
      "Epoch 10/30\n",
      "19/19 - 26s - loss: 0.4836 - accuracy: 0.7924 - val_loss: 0.5964 - val_accuracy: 0.7460 - 26s/epoch - 1s/step\n",
      "Epoch 11/30\n",
      "19/19 - 26s - loss: 0.4748 - accuracy: 0.8006 - val_loss: 0.5343 - val_accuracy: 0.7673 - 26s/epoch - 1s/step\n",
      "Epoch 12/30\n",
      "19/19 - 26s - loss: 0.4564 - accuracy: 0.8036 - val_loss: 0.5182 - val_accuracy: 0.7727 - 26s/epoch - 1s/step\n",
      "Epoch 13/30\n",
      "19/19 - 26s - loss: 0.4448 - accuracy: 0.8070 - val_loss: 0.5590 - val_accuracy: 0.7567 - 26s/epoch - 1s/step\n",
      "Epoch 14/30\n",
      "19/19 - 27s - loss: 0.4403 - accuracy: 0.8159 - val_loss: 0.5588 - val_accuracy: 0.7471 - 27s/epoch - 1s/step\n",
      "Epoch 15/30\n",
      "19/19 - 27s - loss: 0.4397 - accuracy: 0.8127 - val_loss: 0.5218 - val_accuracy: 0.7769 - 27s/epoch - 1s/step\n",
      "Epoch 16/30\n",
      "19/19 - 25s - loss: 0.4165 - accuracy: 0.8252 - val_loss: 0.5205 - val_accuracy: 0.7801 - 25s/epoch - 1s/step\n",
      "Epoch 17/30\n",
      "19/19 - 26s - loss: 0.3998 - accuracy: 0.8313 - val_loss: 0.5525 - val_accuracy: 0.7727 - 26s/epoch - 1s/step\n",
      "Epoch 18/30\n",
      "19/19 - 26s - loss: 0.3964 - accuracy: 0.8335 - val_loss: 0.5396 - val_accuracy: 0.7705 - 26s/epoch - 1s/step\n",
      "Epoch 19/30\n",
      "19/19 - 25s - loss: 0.3745 - accuracy: 0.8423 - val_loss: 0.5404 - val_accuracy: 0.7631 - 25s/epoch - 1s/step\n",
      "Epoch 20/30\n",
      "19/19 - 26s - loss: 0.3708 - accuracy: 0.8412 - val_loss: 0.5506 - val_accuracy: 0.7641 - 26s/epoch - 1s/step\n",
      "Epoch 21/30\n",
      "19/19 - 26s - loss: 0.3625 - accuracy: 0.8460 - val_loss: 0.5572 - val_accuracy: 0.7620 - 26s/epoch - 1s/step\n",
      "Epoch 22/30\n",
      "19/19 - 26s - loss: 0.3444 - accuracy: 0.8513 - val_loss: 0.5665 - val_accuracy: 0.7652 - 26s/epoch - 1s/step\n",
      "Epoch 23/30\n",
      "19/19 - 26s - loss: 0.3430 - accuracy: 0.8508 - val_loss: 0.5691 - val_accuracy: 0.7577 - 26s/epoch - 1s/step\n",
      "Epoch 24/30\n",
      "19/19 - 26s - loss: 0.3359 - accuracy: 0.8586 - val_loss: 0.5641 - val_accuracy: 0.7684 - 26s/epoch - 1s/step\n",
      "Epoch 25/30\n",
      "19/19 - 26s - loss: 0.2994 - accuracy: 0.8740 - val_loss: 0.5904 - val_accuracy: 0.7620 - 26s/epoch - 1s/step\n",
      "Epoch 26/30\n",
      "19/19 - 26s - loss: 0.2941 - accuracy: 0.8791 - val_loss: 0.5833 - val_accuracy: 0.7620 - 26s/epoch - 1s/step\n",
      "Epoch 27/30\n",
      "19/19 - 26s - loss: 0.2854 - accuracy: 0.8759 - val_loss: 0.6172 - val_accuracy: 0.7535 - 26s/epoch - 1s/step\n",
      "Epoch 28/30\n",
      "19/19 - 26s - loss: 0.2610 - accuracy: 0.8940 - val_loss: 0.6503 - val_accuracy: 0.7439 - 26s/epoch - 1s/step\n",
      "Epoch 29/30\n",
      "19/19 - 26s - loss: 0.2791 - accuracy: 0.8826 - val_loss: 0.6522 - val_accuracy: 0.7449 - 26s/epoch - 1s/step\n",
      "Epoch 30/30\n",
      "19/19 - 26s - loss: 0.2633 - accuracy: 0.8871 - val_loss: 0.6090 - val_accuracy: 0.7577 - 26s/epoch - 1s/step\n",
      "Model: \"model_31\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_32 (InputLayer)       [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 98, 98, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 97, 97, 10)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 95, 95, 10)        910       \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 94, 94, 10)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_31 (Flatten)        (None, 88360)             0         \n",
      "                                                                 \n",
      " dense_130 (Dense)           (None, 30)                2650830   \n",
      "                                                                 \n",
      " dense_131 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_132 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_133 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_134 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_135 (Dense)           (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,655,653\n",
      "Trainable params: 2,655,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.6171047687530518\n",
      "Test accuracy: 0.7662116289138794\n"
     ]
    }
   ],
   "source": [
    "train(30,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8028810e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "19/19 - 27s - loss: 1.0437 - accuracy: 0.4662 - val_loss: 0.9704 - val_accuracy: 0.4888 - 27s/epoch - 1s/step\n",
      "Epoch 2/15\n",
      "19/19 - 29s - loss: 0.8498 - accuracy: 0.6317 - val_loss: 0.7418 - val_accuracy: 0.6606 - 29s/epoch - 2s/step\n",
      "Epoch 3/15\n",
      "19/19 - 25s - loss: 0.6978 - accuracy: 0.6867 - val_loss: 0.6830 - val_accuracy: 0.6884 - 25s/epoch - 1s/step\n",
      "Epoch 4/15\n",
      "19/19 - 25s - loss: 0.6259 - accuracy: 0.7232 - val_loss: 0.6188 - val_accuracy: 0.7022 - 25s/epoch - 1s/step\n",
      "Epoch 5/15\n",
      "19/19 - 25s - loss: 0.5738 - accuracy: 0.7355 - val_loss: 0.5877 - val_accuracy: 0.7289 - 25s/epoch - 1s/step\n",
      "Epoch 6/15\n",
      "19/19 - 26s - loss: 0.5967 - accuracy: 0.7310 - val_loss: 0.6840 - val_accuracy: 0.6873 - 26s/epoch - 1s/step\n",
      "Epoch 7/15\n",
      "19/19 - 25s - loss: 0.5986 - accuracy: 0.7353 - val_loss: 0.5805 - val_accuracy: 0.7524 - 25s/epoch - 1s/step\n",
      "Epoch 8/15\n",
      "19/19 - 25s - loss: 0.5703 - accuracy: 0.7491 - val_loss: 0.6242 - val_accuracy: 0.7097 - 25s/epoch - 1s/step\n",
      "Epoch 9/15\n",
      "19/19 - 25s - loss: 0.5395 - accuracy: 0.7646 - val_loss: 0.5619 - val_accuracy: 0.7439 - 25s/epoch - 1s/step\n",
      "Epoch 10/15\n",
      "19/19 - 25s - loss: 0.5143 - accuracy: 0.7812 - val_loss: 0.6077 - val_accuracy: 0.7353 - 25s/epoch - 1s/step\n",
      "Epoch 11/15\n",
      "19/19 - 25s - loss: 0.5043 - accuracy: 0.7836 - val_loss: 0.5394 - val_accuracy: 0.7620 - 25s/epoch - 1s/step\n",
      "Epoch 12/15\n",
      "19/19 - 25s - loss: 0.4896 - accuracy: 0.7902 - val_loss: 0.5531 - val_accuracy: 0.7524 - 25s/epoch - 1s/step\n",
      "Epoch 13/15\n",
      "19/19 - 25s - loss: 0.4908 - accuracy: 0.8004 - val_loss: 0.5298 - val_accuracy: 0.7705 - 25s/epoch - 1s/step\n",
      "Epoch 14/15\n",
      "19/19 - 26s - loss: 0.4848 - accuracy: 0.7974 - val_loss: 0.5354 - val_accuracy: 0.7695 - 26s/epoch - 1s/step\n",
      "Epoch 15/15\n",
      "19/19 - 26s - loss: 0.4696 - accuracy: 0.8001 - val_loss: 0.5464 - val_accuracy: 0.7652 - 26s/epoch - 1s/step\n",
      "Model: \"model_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_33 (InputLayer)       [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 98, 98, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPoolin  (None, 97, 97, 10)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 95, 95, 10)        910       \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPoolin  (None, 94, 94, 10)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_32 (Flatten)        (None, 88360)             0         \n",
      "                                                                 \n",
      " dense_136 (Dense)           (None, 30)                2650830   \n",
      "                                                                 \n",
      " dense_137 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_138 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_139 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_140 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_141 (Dense)           (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,655,653\n",
      "Trainable params: 2,655,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5533056855201721\n",
      "Test accuracy: 0.76450514793396\n"
     ]
    }
   ],
   "source": [
    "train(15,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37443053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "19/19 - 25s - loss: 1.0676 - accuracy: 0.4486 - val_loss: 1.0430 - val_accuracy: 0.4813 - 25s/epoch - 1s/step\n",
      "Epoch 2/60\n",
      "19/19 - 25s - loss: 0.9329 - accuracy: 0.5687 - val_loss: 0.8455 - val_accuracy: 0.6478 - 25s/epoch - 1s/step\n",
      "Epoch 3/60\n",
      "19/19 - 25s - loss: 0.7314 - accuracy: 0.6709 - val_loss: 0.6763 - val_accuracy: 0.6649 - 25s/epoch - 1s/step\n",
      "Epoch 4/60\n",
      "19/19 - 27s - loss: 0.5931 - accuracy: 0.7294 - val_loss: 0.6178 - val_accuracy: 0.7257 - 27s/epoch - 1s/step\n",
      "Epoch 5/60\n",
      "19/19 - 32s - loss: 0.5389 - accuracy: 0.7732 - val_loss: 0.5820 - val_accuracy: 0.7407 - 32s/epoch - 2s/step\n",
      "Epoch 6/60\n",
      "19/19 - 27s - loss: 0.5116 - accuracy: 0.7817 - val_loss: 0.5535 - val_accuracy: 0.7449 - 27s/epoch - 1s/step\n",
      "Epoch 7/60\n",
      "19/19 - 28s - loss: 0.5156 - accuracy: 0.7750 - val_loss: 0.6455 - val_accuracy: 0.7033 - 28s/epoch - 1s/step\n",
      "Epoch 8/60\n",
      "19/19 - 29s - loss: 0.4926 - accuracy: 0.7916 - val_loss: 0.5501 - val_accuracy: 0.7588 - 29s/epoch - 2s/step\n",
      "Epoch 9/60\n",
      "19/19 - 32s - loss: 0.4689 - accuracy: 0.7977 - val_loss: 0.5397 - val_accuracy: 0.7631 - 32s/epoch - 2s/step\n",
      "Epoch 10/60\n",
      "19/19 - 29s - loss: 0.4544 - accuracy: 0.8041 - val_loss: 0.5289 - val_accuracy: 0.7673 - 29s/epoch - 2s/step\n",
      "Epoch 11/60\n",
      "19/19 - 27s - loss: 0.4316 - accuracy: 0.8143 - val_loss: 0.5268 - val_accuracy: 0.7684 - 27s/epoch - 1s/step\n",
      "Epoch 12/60\n",
      "19/19 - 26s - loss: 0.4219 - accuracy: 0.8177 - val_loss: 0.5207 - val_accuracy: 0.7748 - 26s/epoch - 1s/step\n",
      "Epoch 13/60\n",
      "19/19 - 26s - loss: 0.4024 - accuracy: 0.8287 - val_loss: 0.5646 - val_accuracy: 0.7609 - 26s/epoch - 1s/step\n",
      "Epoch 14/60\n",
      "19/19 - 27s - loss: 0.3942 - accuracy: 0.8348 - val_loss: 0.5363 - val_accuracy: 0.7727 - 27s/epoch - 1s/step\n",
      "Epoch 15/60\n",
      "19/19 - 26s - loss: 0.3687 - accuracy: 0.8377 - val_loss: 0.5567 - val_accuracy: 0.7684 - 26s/epoch - 1s/step\n",
      "Epoch 16/60\n",
      "19/19 - 26s - loss: 0.3550 - accuracy: 0.8444 - val_loss: 0.5655 - val_accuracy: 0.7609 - 26s/epoch - 1s/step\n",
      "Epoch 17/60\n",
      "19/19 - 27s - loss: 0.3387 - accuracy: 0.8559 - val_loss: 0.6491 - val_accuracy: 0.7385 - 27s/epoch - 1s/step\n",
      "Epoch 18/60\n",
      "19/19 - 26s - loss: 0.3460 - accuracy: 0.8481 - val_loss: 0.6235 - val_accuracy: 0.7503 - 26s/epoch - 1s/step\n",
      "Epoch 19/60\n",
      "19/19 - 26s - loss: 0.3238 - accuracy: 0.8586 - val_loss: 0.6321 - val_accuracy: 0.7524 - 26s/epoch - 1s/step\n",
      "Epoch 20/60\n",
      "19/19 - 27s - loss: 0.2987 - accuracy: 0.8732 - val_loss: 0.6039 - val_accuracy: 0.7471 - 27s/epoch - 1s/step\n",
      "Epoch 21/60\n",
      "19/19 - 26s - loss: 0.2961 - accuracy: 0.8767 - val_loss: 0.6168 - val_accuracy: 0.7567 - 26s/epoch - 1s/step\n",
      "Epoch 22/60\n",
      "19/19 - 26s - loss: 0.2669 - accuracy: 0.8924 - val_loss: 0.6328 - val_accuracy: 0.7609 - 26s/epoch - 1s/step\n",
      "Epoch 23/60\n",
      "19/19 - 27s - loss: 0.2576 - accuracy: 0.8975 - val_loss: 0.6972 - val_accuracy: 0.7449 - 27s/epoch - 1s/step\n",
      "Epoch 24/60\n",
      "19/19 - 29s - loss: 0.2575 - accuracy: 0.8986 - val_loss: 0.7089 - val_accuracy: 0.7300 - 29s/epoch - 2s/step\n",
      "Epoch 25/60\n",
      "19/19 - 26s - loss: 0.2619 - accuracy: 0.8986 - val_loss: 0.6539 - val_accuracy: 0.7524 - 26s/epoch - 1s/step\n",
      "Epoch 26/60\n",
      "19/19 - 27s - loss: 0.2254 - accuracy: 0.9111 - val_loss: 0.7096 - val_accuracy: 0.7407 - 27s/epoch - 1s/step\n",
      "Epoch 27/60\n",
      "19/19 - 28s - loss: 0.2148 - accuracy: 0.9162 - val_loss: 0.8260 - val_accuracy: 0.7524 - 28s/epoch - 1s/step\n",
      "Epoch 28/60\n",
      "19/19 - 25s - loss: 0.2126 - accuracy: 0.9191 - val_loss: 0.7736 - val_accuracy: 0.7311 - 25s/epoch - 1s/step\n",
      "Epoch 29/60\n",
      "19/19 - 25s - loss: 0.1838 - accuracy: 0.9327 - val_loss: 0.7764 - val_accuracy: 0.7182 - 25s/epoch - 1s/step\n",
      "Epoch 30/60\n",
      "19/19 - 25s - loss: 0.1723 - accuracy: 0.9362 - val_loss: 0.7647 - val_accuracy: 0.7492 - 25s/epoch - 1s/step\n",
      "Epoch 31/60\n",
      "19/19 - 26s - loss: 0.1547 - accuracy: 0.9437 - val_loss: 0.8109 - val_accuracy: 0.7492 - 26s/epoch - 1s/step\n",
      "Epoch 32/60\n",
      "19/19 - 26s - loss: 0.1384 - accuracy: 0.9496 - val_loss: 0.8342 - val_accuracy: 0.7364 - 26s/epoch - 1s/step\n",
      "Epoch 33/60\n",
      "19/19 - 25s - loss: 0.1149 - accuracy: 0.9640 - val_loss: 0.9377 - val_accuracy: 0.7364 - 25s/epoch - 1s/step\n",
      "Epoch 34/60\n",
      "19/19 - 25s - loss: 0.1033 - accuracy: 0.9672 - val_loss: 0.9669 - val_accuracy: 0.7481 - 25s/epoch - 1s/step\n",
      "Epoch 35/60\n",
      "19/19 - 25s - loss: 0.0984 - accuracy: 0.9696 - val_loss: 0.9705 - val_accuracy: 0.7545 - 25s/epoch - 1s/step\n",
      "Epoch 36/60\n",
      "19/19 - 25s - loss: 0.1251 - accuracy: 0.9490 - val_loss: 1.0162 - val_accuracy: 0.7300 - 25s/epoch - 1s/step\n",
      "Epoch 37/60\n",
      "19/19 - 25s - loss: 0.0826 - accuracy: 0.9746 - val_loss: 1.0322 - val_accuracy: 0.7460 - 25s/epoch - 1s/step\n",
      "Epoch 38/60\n",
      "19/19 - 25s - loss: 0.0723 - accuracy: 0.9784 - val_loss: 1.0625 - val_accuracy: 0.7481 - 25s/epoch - 1s/step\n",
      "Epoch 39/60\n",
      "19/19 - 25s - loss: 0.0558 - accuracy: 0.9861 - val_loss: 1.1020 - val_accuracy: 0.7471 - 25s/epoch - 1s/step\n",
      "Epoch 40/60\n",
      "19/19 - 25s - loss: 0.0411 - accuracy: 0.9917 - val_loss: 1.1580 - val_accuracy: 0.7481 - 25s/epoch - 1s/step\n",
      "Epoch 41/60\n",
      "19/19 - 25s - loss: 0.0360 - accuracy: 0.9909 - val_loss: 1.2808 - val_accuracy: 0.7481 - 25s/epoch - 1s/step\n",
      "Epoch 42/60\n",
      "19/19 - 25s - loss: 0.0413 - accuracy: 0.9907 - val_loss: 1.2797 - val_accuracy: 0.7492 - 25s/epoch - 1s/step\n",
      "Epoch 43/60\n",
      "19/19 - 25s - loss: 0.0255 - accuracy: 0.9963 - val_loss: 1.3313 - val_accuracy: 0.7535 - 25s/epoch - 1s/step\n",
      "Epoch 44/60\n",
      "19/19 - 25s - loss: 0.0198 - accuracy: 0.9971 - val_loss: 1.3737 - val_accuracy: 0.7375 - 25s/epoch - 1s/step\n",
      "Epoch 45/60\n",
      "19/19 - 25s - loss: 0.0161 - accuracy: 0.9979 - val_loss: 1.3555 - val_accuracy: 0.7428 - 25s/epoch - 1s/step\n",
      "Epoch 46/60\n",
      "19/19 - 26s - loss: 0.0125 - accuracy: 0.9973 - val_loss: 1.3358 - val_accuracy: 0.7311 - 26s/epoch - 1s/step\n",
      "Epoch 47/60\n",
      "19/19 - 28s - loss: 0.0104 - accuracy: 0.9984 - val_loss: 1.4919 - val_accuracy: 0.7385 - 28s/epoch - 1s/step\n",
      "Epoch 48/60\n",
      "19/19 - 28s - loss: 0.0086 - accuracy: 0.9992 - val_loss: 1.4278 - val_accuracy: 0.7417 - 28s/epoch - 1s/step\n",
      "Epoch 49/60\n",
      "19/19 - 29s - loss: 0.0078 - accuracy: 0.9989 - val_loss: 1.4868 - val_accuracy: 0.7417 - 29s/epoch - 2s/step\n",
      "Epoch 50/60\n",
      "19/19 - 27s - loss: 0.0059 - accuracy: 0.9992 - val_loss: 1.5559 - val_accuracy: 0.7471 - 27s/epoch - 1s/step\n",
      "Epoch 51/60\n",
      "19/19 - 28s - loss: 0.0048 - accuracy: 0.9992 - val_loss: 1.6127 - val_accuracy: 0.7439 - 28s/epoch - 1s/step\n",
      "Epoch 52/60\n",
      "19/19 - 27s - loss: 0.0036 - accuracy: 0.9995 - val_loss: 1.6806 - val_accuracy: 0.7396 - 27s/epoch - 1s/step\n",
      "Epoch 53/60\n",
      "19/19 - 28s - loss: 0.0032 - accuracy: 0.9995 - val_loss: 1.7015 - val_accuracy: 0.7311 - 28s/epoch - 1s/step\n",
      "Epoch 54/60\n",
      "19/19 - 27s - loss: 0.0025 - accuracy: 0.9995 - val_loss: 1.7333 - val_accuracy: 0.7396 - 27s/epoch - 1s/step\n",
      "Epoch 55/60\n",
      "19/19 - 27s - loss: 0.0017 - accuracy: 0.9997 - val_loss: 1.7749 - val_accuracy: 0.7449 - 27s/epoch - 1s/step\n",
      "Epoch 56/60\n",
      "19/19 - 27s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.8508 - val_accuracy: 0.7513 - 27s/epoch - 1s/step\n",
      "Epoch 57/60\n",
      "19/19 - 27s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.7745 - val_accuracy: 0.7460 - 27s/epoch - 1s/step\n",
      "Epoch 58/60\n",
      "19/19 - 28s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.9191 - val_accuracy: 0.7396 - 28s/epoch - 1s/step\n",
      "Epoch 59/60\n",
      "19/19 - 25s - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.9222 - val_accuracy: 0.7353 - 25s/epoch - 1s/step\n",
      "Epoch 60/60\n",
      "19/19 - 25s - loss: 7.6556e-04 - accuracy: 1.0000 - val_loss: 1.9017 - val_accuracy: 0.7375 - 25s/epoch - 1s/step\n",
      "Model: \"model_33\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_34 (InputLayer)       [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 98, 98, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPoolin  (None, 97, 97, 10)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 95, 95, 10)        910       \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 94, 94, 10)       0         \n",
      " g2D)                                                            \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " flatten_33 (Flatten)        (None, 88360)             0         \n",
      "                                                                 \n",
      " dense_142 (Dense)           (None, 30)                2650830   \n",
      "                                                                 \n",
      " dense_143 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_144 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_145 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_146 (Dense)           (None, 30)                930       \n",
      "                                                                 \n",
      " dense_147 (Dense)           (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,655,653\n",
      "Trainable params: 2,655,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 1.9275410175323486\n",
      "Test accuracy: 0.755972683429718\n"
     ]
    }
   ],
   "source": [
    "train(60,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a57b59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "def train(epochs_num,batch_len):\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "    dataset, labels, test_size=0.2, random_state=42)\n",
    "    X_train=X_train.reshape(-1,100,100,1)\n",
    "    X_test=X_test.reshape(-1,100,100,1)\n",
    "    Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "    Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "    \n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(2):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(1,1))(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        for i in range(5):\n",
    "            hidden=layers.Dense(30,activation=\"relu\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/math.pow(76.4,math.pow(i+1,-1)), maxval=1/math.pow(76.4,math.pow(i+1,-1)), seed=None))(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "        output=layers.Dense(3,activation=\"softmax\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/math.pow(76.4,math.pow(4,-1)), maxval=1/math.pow(76.4,math.pow(4,-1)), seed=None))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=[\"accuracy\"])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.2,epochs=epochs_num,batch_size=batch_len,verbose=2)\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d7a6dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "19/19 - 32s - loss: 1.0113 - accuracy: 0.4865 - val_loss: 0.9157 - val_accuracy: 0.5699 - 32s/epoch - 2s/step\n",
      "Epoch 2/60\n",
      "19/19 - 25s - loss: 0.8094 - accuracy: 0.6624 - val_loss: 0.6993 - val_accuracy: 0.6830 - 25s/epoch - 1s/step\n",
      "Epoch 3/60\n",
      "19/19 - 25s - loss: 0.6403 - accuracy: 0.7091 - val_loss: 0.6464 - val_accuracy: 0.7097 - 25s/epoch - 1s/step\n",
      "Epoch 4/60\n",
      "19/19 - 25s - loss: 0.5786 - accuracy: 0.7379 - val_loss: 0.6600 - val_accuracy: 0.6926 - 25s/epoch - 1s/step\n",
      "Epoch 5/60\n",
      "19/19 - 26s - loss: 0.5446 - accuracy: 0.7678 - val_loss: 0.5890 - val_accuracy: 0.7268 - 26s/epoch - 1s/step\n",
      "Epoch 6/60\n",
      "19/19 - 25s - loss: 0.5068 - accuracy: 0.7884 - val_loss: 0.5718 - val_accuracy: 0.7481 - 25s/epoch - 1s/step\n",
      "Epoch 7/60\n",
      "19/19 - 25s - loss: 0.5008 - accuracy: 0.7873 - val_loss: 0.5889 - val_accuracy: 0.7257 - 25s/epoch - 1s/step\n",
      "Epoch 8/60\n",
      "19/19 - 25s - loss: 0.4805 - accuracy: 0.7948 - val_loss: 0.5375 - val_accuracy: 0.7609 - 25s/epoch - 1s/step\n",
      "Epoch 9/60\n",
      "19/19 - 25s - loss: 0.4515 - accuracy: 0.8097 - val_loss: 0.5367 - val_accuracy: 0.7695 - 25s/epoch - 1s/step\n",
      "Epoch 10/60\n",
      "19/19 - 26s - loss: 0.4299 - accuracy: 0.8140 - val_loss: 0.5459 - val_accuracy: 0.7684 - 26s/epoch - 1s/step\n",
      "Epoch 11/60\n",
      "19/19 - 25s - loss: 0.4110 - accuracy: 0.8217 - val_loss: 0.5690 - val_accuracy: 0.7567 - 25s/epoch - 1s/step\n",
      "Epoch 12/60\n",
      "19/19 - 25s - loss: 0.4017 - accuracy: 0.8332 - val_loss: 0.5886 - val_accuracy: 0.7513 - 25s/epoch - 1s/step\n",
      "Epoch 13/60\n",
      "19/19 - 25s - loss: 0.3661 - accuracy: 0.8369 - val_loss: 0.5471 - val_accuracy: 0.7695 - 25s/epoch - 1s/step\n",
      "Epoch 14/60\n",
      "19/19 - 25s - loss: 0.3536 - accuracy: 0.8484 - val_loss: 0.5513 - val_accuracy: 0.7791 - 25s/epoch - 1s/step\n",
      "Epoch 15/60\n",
      "19/19 - 25s - loss: 0.3178 - accuracy: 0.8588 - val_loss: 0.6126 - val_accuracy: 0.7577 - 25s/epoch - 1s/step\n",
      "Epoch 16/60\n",
      "19/19 - 25s - loss: 0.3079 - accuracy: 0.8668 - val_loss: 0.5836 - val_accuracy: 0.7631 - 25s/epoch - 1s/step\n",
      "Epoch 17/60\n",
      "19/19 - 26s - loss: 0.2792 - accuracy: 0.8834 - val_loss: 0.6693 - val_accuracy: 0.7279 - 26s/epoch - 1s/step\n",
      "Epoch 18/60\n",
      "19/19 - 25s - loss: 0.2911 - accuracy: 0.8748 - val_loss: 0.7002 - val_accuracy: 0.7439 - 25s/epoch - 1s/step\n",
      "Epoch 19/60\n",
      "19/19 - 25s - loss: 0.2447 - accuracy: 0.8962 - val_loss: 0.7228 - val_accuracy: 0.7247 - 25s/epoch - 1s/step\n",
      "Epoch 20/60\n",
      "19/19 - 25s - loss: 0.2385 - accuracy: 0.9007 - val_loss: 0.7005 - val_accuracy: 0.7652 - 25s/epoch - 1s/step\n",
      "Epoch 21/60\n",
      "19/19 - 28s - loss: 0.2072 - accuracy: 0.9165 - val_loss: 0.7258 - val_accuracy: 0.7375 - 28s/epoch - 1s/step\n",
      "Epoch 22/60\n",
      "19/19 - 34s - loss: 0.1939 - accuracy: 0.9269 - val_loss: 0.7556 - val_accuracy: 0.7556 - 34s/epoch - 2s/step\n",
      "Epoch 23/60\n",
      "19/19 - 30s - loss: 0.1668 - accuracy: 0.9405 - val_loss: 0.8337 - val_accuracy: 0.7439 - 30s/epoch - 2s/step\n",
      "Epoch 24/60\n",
      "19/19 - 28s - loss: 0.1941 - accuracy: 0.9223 - val_loss: 0.7673 - val_accuracy: 0.7556 - 28s/epoch - 1s/step\n",
      "Epoch 25/60\n",
      "19/19 - 26s - loss: 0.1435 - accuracy: 0.9472 - val_loss: 0.9215 - val_accuracy: 0.7182 - 26s/epoch - 1s/step\n",
      "Epoch 26/60\n",
      "19/19 - 25s - loss: 0.1418 - accuracy: 0.9472 - val_loss: 0.8836 - val_accuracy: 0.7417 - 25s/epoch - 1s/step\n",
      "Epoch 27/60\n",
      "19/19 - 27s - loss: 0.1194 - accuracy: 0.9568 - val_loss: 0.9529 - val_accuracy: 0.7353 - 27s/epoch - 1s/step\n",
      "Epoch 28/60\n",
      "19/19 - 33s - loss: 0.1367 - accuracy: 0.9416 - val_loss: 0.8743 - val_accuracy: 0.7343 - 33s/epoch - 2s/step\n",
      "Epoch 29/60\n",
      "19/19 - 28s - loss: 0.1015 - accuracy: 0.9664 - val_loss: 0.9857 - val_accuracy: 0.7311 - 28s/epoch - 1s/step\n",
      "Epoch 30/60\n",
      "19/19 - 29s - loss: 0.0698 - accuracy: 0.9800 - val_loss: 1.0434 - val_accuracy: 0.7343 - 29s/epoch - 2s/step\n",
      "Epoch 31/60\n",
      "19/19 - 28s - loss: 0.0765 - accuracy: 0.9762 - val_loss: 1.0627 - val_accuracy: 0.7321 - 28s/epoch - 1s/step\n",
      "Epoch 32/60\n",
      "19/19 - 29s - loss: 0.0523 - accuracy: 0.9880 - val_loss: 1.1108 - val_accuracy: 0.7407 - 29s/epoch - 2s/step\n",
      "Epoch 33/60\n",
      "19/19 - 29s - loss: 0.0416 - accuracy: 0.9901 - val_loss: 1.2280 - val_accuracy: 0.7321 - 29s/epoch - 2s/step\n",
      "Epoch 34/60\n",
      "19/19 - 29s - loss: 0.0436 - accuracy: 0.9904 - val_loss: 1.1875 - val_accuracy: 0.7353 - 29s/epoch - 2s/step\n",
      "Epoch 35/60\n",
      "19/19 - 28s - loss: 0.0325 - accuracy: 0.9931 - val_loss: 1.2879 - val_accuracy: 0.7343 - 28s/epoch - 1s/step\n",
      "Epoch 36/60\n",
      "19/19 - 31s - loss: 0.0349 - accuracy: 0.9917 - val_loss: 1.3735 - val_accuracy: 0.7353 - 31s/epoch - 2s/step\n",
      "Epoch 37/60\n",
      "19/19 - 32s - loss: 0.0225 - accuracy: 0.9957 - val_loss: 1.3982 - val_accuracy: 0.7343 - 32s/epoch - 2s/step\n",
      "Epoch 38/60\n",
      "19/19 - 28s - loss: 0.0160 - accuracy: 0.9973 - val_loss: 1.4273 - val_accuracy: 0.7204 - 28s/epoch - 1s/step\n",
      "Epoch 39/60\n",
      "19/19 - 27s - loss: 0.0119 - accuracy: 0.9992 - val_loss: 1.5457 - val_accuracy: 0.7300 - 27s/epoch - 1s/step\n",
      "Epoch 40/60\n",
      "19/19 - 27s - loss: 0.0087 - accuracy: 0.9992 - val_loss: 1.5802 - val_accuracy: 0.7321 - 27s/epoch - 1s/step\n",
      "Epoch 41/60\n",
      "19/19 - 27s - loss: 0.0068 - accuracy: 0.9992 - val_loss: 1.6064 - val_accuracy: 0.7225 - 27s/epoch - 1s/step\n",
      "Epoch 42/60\n",
      "19/19 - 26s - loss: 0.0050 - accuracy: 0.9995 - val_loss: 1.6861 - val_accuracy: 0.7321 - 26s/epoch - 1s/step\n",
      "Epoch 43/60\n",
      "19/19 - 27s - loss: 0.0047 - accuracy: 0.9997 - val_loss: 1.6779 - val_accuracy: 0.7257 - 27s/epoch - 1s/step\n",
      "Epoch 44/60\n",
      "19/19 - 28s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.7302 - val_accuracy: 0.7279 - 28s/epoch - 1s/step\n",
      "Epoch 45/60\n",
      "19/19 - 27s - loss: 0.0024 - accuracy: 1.0000 - val_loss: 1.7861 - val_accuracy: 0.7268 - 27s/epoch - 1s/step\n",
      "Epoch 46/60\n",
      "19/19 - 27s - loss: 0.0016 - accuracy: 1.0000 - val_loss: 1.8364 - val_accuracy: 0.7300 - 27s/epoch - 1s/step\n",
      "Epoch 47/60\n",
      "19/19 - 26s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.8658 - val_accuracy: 0.7311 - 26s/epoch - 1s/step\n",
      "Epoch 48/60\n",
      "19/19 - 26s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.9116 - val_accuracy: 0.7311 - 26s/epoch - 1s/step\n",
      "Epoch 49/60\n",
      "19/19 - 25s - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.9227 - val_accuracy: 0.7343 - 25s/epoch - 1s/step\n",
      "Epoch 50/60\n",
      "19/19 - 26s - loss: 0.0011 - accuracy: 1.0000 - val_loss: 1.9243 - val_accuracy: 0.7321 - 26s/epoch - 1s/step\n",
      "Epoch 51/60\n",
      "19/19 - 26s - loss: 9.1965e-04 - accuracy: 1.0000 - val_loss: 1.9412 - val_accuracy: 0.7236 - 26s/epoch - 1s/step\n",
      "Epoch 52/60\n",
      "19/19 - 25s - loss: 7.7367e-04 - accuracy: 1.0000 - val_loss: 1.9769 - val_accuracy: 0.7247 - 25s/epoch - 1s/step\n",
      "Epoch 53/60\n",
      "19/19 - 26s - loss: 6.7614e-04 - accuracy: 1.0000 - val_loss: 2.0152 - val_accuracy: 0.7343 - 26s/epoch - 1s/step\n",
      "Epoch 54/60\n",
      "19/19 - 25s - loss: 6.3161e-04 - accuracy: 1.0000 - val_loss: 2.0161 - val_accuracy: 0.7247 - 25s/epoch - 1s/step\n",
      "Epoch 55/60\n",
      "19/19 - 26s - loss: 5.5458e-04 - accuracy: 1.0000 - val_loss: 2.0385 - val_accuracy: 0.7247 - 26s/epoch - 1s/step\n",
      "Epoch 56/60\n",
      "19/19 - 26s - loss: 5.1227e-04 - accuracy: 1.0000 - val_loss: 2.0560 - val_accuracy: 0.7268 - 26s/epoch - 1s/step\n",
      "Epoch 57/60\n",
      "19/19 - 26s - loss: 4.8520e-04 - accuracy: 1.0000 - val_loss: 2.0884 - val_accuracy: 0.7321 - 26s/epoch - 1s/step\n",
      "Epoch 58/60\n",
      "19/19 - 26s - loss: 4.6530e-04 - accuracy: 1.0000 - val_loss: 2.0835 - val_accuracy: 0.7268 - 26s/epoch - 1s/step\n",
      "Epoch 59/60\n",
      "19/19 - 26s - loss: 4.3590e-04 - accuracy: 1.0000 - val_loss: 2.1108 - val_accuracy: 0.7300 - 26s/epoch - 1s/step\n",
      "Epoch 60/60\n",
      "19/19 - 26s - loss: 3.9370e-04 - accuracy: 1.0000 - val_loss: 2.1133 - val_accuracy: 0.7257 - 26s/epoch - 1s/step\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 98, 98, 10)        100       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 97, 97, 10)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 95, 95, 10)        910       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 94, 94, 10)       0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 88360)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 30)                2650830   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,655,653\n",
      "Trainable params: 2,655,653\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 2.068443536758423\n",
      "Test accuracy: 0.73549485206604\n"
     ]
    }
   ],
   "source": [
    "train(60,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3dbade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "def train(epochs_num,batch_len):\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "    dataset, labels, test_size=0.2, random_state=42)\n",
    "    X_train=X_train.reshape(-1,100,100,1)\n",
    "    X_test=X_test.reshape(-1,100,100,1)\n",
    "    Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "    Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "    \n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(3):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        for i in range(3):\n",
    "            hidden=layers.Dense(30,activation=\"relu\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/math.pow(76.4,math.pow(i+1,-1)), maxval=1/math.pow(76.4,math.pow(i+1,-1)), seed=None))(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "        output=layers.Dense(3,activation=\"softmax\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/math.pow(76.4,math.pow(4,-1)), maxval=1/math.pow(76.4,math.pow(4,-1)), seed=None))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=[\"accuracy\"])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.2,epochs=epochs_num,batch_size=batch_len,verbose=2)\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41b99d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/46\n",
      "75/75 - 33s - loss: 1.0611 - accuracy: 0.4790 - val_loss: 1.0444 - val_accuracy: 0.4813 - 33s/epoch - 437ms/step\n",
      "Epoch 2/46\n",
      "75/75 - 34s - loss: 0.9259 - accuracy: 0.5559 - val_loss: 0.8252 - val_accuracy: 0.6425 - 34s/epoch - 452ms/step\n",
      "Epoch 3/46\n",
      "75/75 - 34s - loss: 0.7602 - accuracy: 0.6763 - val_loss: 0.7358 - val_accuracy: 0.6670 - 34s/epoch - 454ms/step\n",
      "Epoch 4/46\n",
      "75/75 - 41s - loss: 0.6930 - accuracy: 0.6832 - val_loss: 0.7397 - val_accuracy: 0.6692 - 41s/epoch - 548ms/step\n",
      "Epoch 5/46\n",
      "75/75 - 36s - loss: 0.6633 - accuracy: 0.7126 - val_loss: 0.6562 - val_accuracy: 0.7140 - 36s/epoch - 476ms/step\n",
      "Epoch 6/46\n",
      "75/75 - 34s - loss: 0.6149 - accuracy: 0.7345 - val_loss: 0.6279 - val_accuracy: 0.7247 - 34s/epoch - 454ms/step\n",
      "Epoch 7/46\n",
      "75/75 - 31s - loss: 0.5842 - accuracy: 0.7494 - val_loss: 0.6083 - val_accuracy: 0.7407 - 31s/epoch - 415ms/step\n",
      "Epoch 8/46\n",
      "75/75 - 31s - loss: 0.5653 - accuracy: 0.7598 - val_loss: 0.5859 - val_accuracy: 0.7567 - 31s/epoch - 413ms/step\n",
      "Epoch 9/46\n",
      "75/75 - 31s - loss: 0.5458 - accuracy: 0.7702 - val_loss: 0.5686 - val_accuracy: 0.7599 - 31s/epoch - 414ms/step\n",
      "Epoch 10/46\n",
      "75/75 - 31s - loss: 0.5180 - accuracy: 0.7860 - val_loss: 0.5544 - val_accuracy: 0.7663 - 31s/epoch - 414ms/step\n",
      "Epoch 11/46\n",
      "75/75 - 33s - loss: 0.5019 - accuracy: 0.7913 - val_loss: 0.5557 - val_accuracy: 0.7545 - 33s/epoch - 436ms/step\n",
      "Epoch 12/46\n",
      "75/75 - 32s - loss: 0.4918 - accuracy: 0.7988 - val_loss: 0.5602 - val_accuracy: 0.7695 - 32s/epoch - 428ms/step\n",
      "Epoch 13/46\n",
      "75/75 - 36s - loss: 0.4779 - accuracy: 0.7972 - val_loss: 0.5567 - val_accuracy: 0.7577 - 36s/epoch - 475ms/step\n",
      "Epoch 14/46\n",
      "75/75 - 30s - loss: 0.4735 - accuracy: 0.8025 - val_loss: 0.5974 - val_accuracy: 0.7652 - 30s/epoch - 399ms/step\n",
      "Epoch 15/46\n",
      "75/75 - 28s - loss: 0.4570 - accuracy: 0.8094 - val_loss: 0.5749 - val_accuracy: 0.7577 - 28s/epoch - 372ms/step\n",
      "Epoch 16/46\n",
      "75/75 - 28s - loss: 0.4669 - accuracy: 0.8065 - val_loss: 0.5487 - val_accuracy: 0.7705 - 28s/epoch - 368ms/step\n",
      "Epoch 17/46\n",
      "75/75 - 28s - loss: 0.4548 - accuracy: 0.8127 - val_loss: 0.5535 - val_accuracy: 0.7759 - 28s/epoch - 370ms/step\n",
      "Epoch 18/46\n",
      "75/75 - 28s - loss: 0.4434 - accuracy: 0.8169 - val_loss: 0.6019 - val_accuracy: 0.7471 - 28s/epoch - 371ms/step\n",
      "Epoch 19/46\n",
      "75/75 - 28s - loss: 0.4274 - accuracy: 0.8236 - val_loss: 0.5530 - val_accuracy: 0.7684 - 28s/epoch - 378ms/step\n",
      "Epoch 20/46\n",
      "75/75 - 28s - loss: 0.4305 - accuracy: 0.8241 - val_loss: 0.5592 - val_accuracy: 0.7695 - 28s/epoch - 367ms/step\n",
      "Epoch 21/46\n",
      "75/75 - 28s - loss: 0.4198 - accuracy: 0.8233 - val_loss: 0.5555 - val_accuracy: 0.7535 - 28s/epoch - 370ms/step\n",
      "Epoch 22/46\n",
      "75/75 - 29s - loss: 0.4086 - accuracy: 0.8295 - val_loss: 0.5441 - val_accuracy: 0.7791 - 29s/epoch - 381ms/step\n",
      "Epoch 23/46\n",
      "75/75 - 28s - loss: 0.3996 - accuracy: 0.8345 - val_loss: 0.5541 - val_accuracy: 0.7599 - 28s/epoch - 377ms/step\n",
      "Epoch 24/46\n",
      "75/75 - 28s - loss: 0.3995 - accuracy: 0.8361 - val_loss: 0.5375 - val_accuracy: 0.7716 - 28s/epoch - 374ms/step\n",
      "Epoch 25/46\n",
      "75/75 - 28s - loss: 0.4003 - accuracy: 0.8385 - val_loss: 0.5603 - val_accuracy: 0.7663 - 28s/epoch - 374ms/step\n",
      "Epoch 26/46\n",
      "75/75 - 28s - loss: 0.3877 - accuracy: 0.8415 - val_loss: 0.5392 - val_accuracy: 0.7727 - 28s/epoch - 368ms/step\n",
      "Epoch 27/46\n",
      "75/75 - 28s - loss: 0.3695 - accuracy: 0.8505 - val_loss: 0.5748 - val_accuracy: 0.7684 - 28s/epoch - 369ms/step\n",
      "Epoch 28/46\n",
      "75/75 - 27s - loss: 0.3760 - accuracy: 0.8476 - val_loss: 0.5390 - val_accuracy: 0.7716 - 27s/epoch - 365ms/step\n",
      "Epoch 29/46\n",
      "75/75 - 28s - loss: 0.3514 - accuracy: 0.8580 - val_loss: 0.5896 - val_accuracy: 0.7748 - 28s/epoch - 371ms/step\n",
      "Epoch 30/46\n",
      "75/75 - 28s - loss: 0.3429 - accuracy: 0.8602 - val_loss: 0.5976 - val_accuracy: 0.7631 - 28s/epoch - 373ms/step\n",
      "Epoch 31/46\n",
      "75/75 - 28s - loss: 0.3412 - accuracy: 0.8634 - val_loss: 0.6104 - val_accuracy: 0.7588 - 28s/epoch - 379ms/step\n",
      "Epoch 32/46\n",
      "75/75 - 28s - loss: 0.3322 - accuracy: 0.8679 - val_loss: 0.6080 - val_accuracy: 0.7641 - 28s/epoch - 373ms/step\n",
      "Epoch 33/46\n",
      "75/75 - 28s - loss: 0.3118 - accuracy: 0.8772 - val_loss: 0.6133 - val_accuracy: 0.7577 - 28s/epoch - 371ms/step\n",
      "Epoch 34/46\n",
      "75/75 - 28s - loss: 0.3194 - accuracy: 0.8714 - val_loss: 0.5876 - val_accuracy: 0.7599 - 28s/epoch - 373ms/step\n",
      "Epoch 35/46\n",
      "75/75 - 28s - loss: 0.3206 - accuracy: 0.8719 - val_loss: 0.7069 - val_accuracy: 0.7407 - 28s/epoch - 371ms/step\n",
      "Epoch 36/46\n",
      "75/75 - 28s - loss: 0.3169 - accuracy: 0.8727 - val_loss: 0.6190 - val_accuracy: 0.7620 - 28s/epoch - 370ms/step\n",
      "Epoch 37/46\n",
      "75/75 - 30s - loss: 0.2965 - accuracy: 0.8764 - val_loss: 0.6453 - val_accuracy: 0.7588 - 30s/epoch - 395ms/step\n",
      "Epoch 38/46\n",
      "75/75 - 53s - loss: 0.2980 - accuracy: 0.8820 - val_loss: 0.6240 - val_accuracy: 0.7652 - 53s/epoch - 707ms/step\n",
      "Epoch 39/46\n",
      "75/75 - 48s - loss: 0.2796 - accuracy: 0.8900 - val_loss: 0.7206 - val_accuracy: 0.7321 - 48s/epoch - 645ms/step\n",
      "Epoch 40/46\n",
      "75/75 - 32s - loss: 0.2618 - accuracy: 0.9013 - val_loss: 0.6992 - val_accuracy: 0.7385 - 32s/epoch - 432ms/step\n",
      "Epoch 41/46\n",
      "75/75 - 34s - loss: 0.2626 - accuracy: 0.8956 - val_loss: 0.7798 - val_accuracy: 0.7471 - 34s/epoch - 456ms/step\n",
      "Epoch 42/46\n",
      "75/75 - 31s - loss: 0.2621 - accuracy: 0.8935 - val_loss: 0.7006 - val_accuracy: 0.7492 - 31s/epoch - 416ms/step\n",
      "Epoch 43/46\n",
      "75/75 - 30s - loss: 0.2417 - accuracy: 0.9063 - val_loss: 0.7049 - val_accuracy: 0.7428 - 30s/epoch - 396ms/step\n",
      "Epoch 44/46\n",
      "75/75 - 29s - loss: 0.2310 - accuracy: 0.9119 - val_loss: 0.7744 - val_accuracy: 0.7449 - 29s/epoch - 381ms/step\n",
      "Epoch 45/46\n",
      "75/75 - 28s - loss: 0.2153 - accuracy: 0.9173 - val_loss: 0.7800 - val_accuracy: 0.7481 - 28s/epoch - 376ms/step\n",
      "Epoch 46/46\n",
      "75/75 - 28s - loss: 0.2122 - accuracy: 0.9165 - val_loss: 0.7750 - val_accuracy: 0.7513 - 28s/epoch - 380ms/step\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 49, 49, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 23, 23, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 10, 10, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.6870231628417969\n",
      "Test accuracy: 0.7696245908737183\n"
     ]
    }
   ],
   "source": [
    "train(46,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7283786b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/23\n",
      "38/38 - 43s - loss: 1.0651 - accuracy: 0.4753 - val_loss: 1.0548 - val_accuracy: 0.4813 - 43s/epoch - 1s/step\n",
      "Epoch 2/23\n",
      "38/38 - 34s - loss: 1.0274 - accuracy: 0.4935 - val_loss: 0.9048 - val_accuracy: 0.5667 - 34s/epoch - 900ms/step\n",
      "Epoch 3/23\n",
      "38/38 - 30s - loss: 0.7542 - accuracy: 0.6571 - val_loss: 0.7358 - val_accuracy: 0.6756 - 30s/epoch - 799ms/step\n",
      "Epoch 4/23\n",
      "38/38 - 28s - loss: 0.6681 - accuracy: 0.7062 - val_loss: 0.6755 - val_accuracy: 0.7054 - 28s/epoch - 731ms/step\n",
      "Epoch 5/23\n",
      "38/38 - 28s - loss: 0.6233 - accuracy: 0.7310 - val_loss: 0.6627 - val_accuracy: 0.7172 - 28s/epoch - 724ms/step\n",
      "Epoch 6/23\n",
      "38/38 - 28s - loss: 0.6181 - accuracy: 0.7395 - val_loss: 0.6496 - val_accuracy: 0.7225 - 28s/epoch - 731ms/step\n",
      "Epoch 7/23\n",
      "38/38 - 27s - loss: 0.5820 - accuracy: 0.7545 - val_loss: 0.6026 - val_accuracy: 0.7279 - 27s/epoch - 716ms/step\n",
      "Epoch 8/23\n",
      "38/38 - 29s - loss: 0.5502 - accuracy: 0.7694 - val_loss: 0.6086 - val_accuracy: 0.7300 - 29s/epoch - 754ms/step\n",
      "Epoch 9/23\n",
      "38/38 - 30s - loss: 0.5472 - accuracy: 0.7716 - val_loss: 0.5628 - val_accuracy: 0.7471 - 30s/epoch - 789ms/step\n",
      "Epoch 10/23\n",
      "38/38 - 28s - loss: 0.5203 - accuracy: 0.7812 - val_loss: 0.5607 - val_accuracy: 0.7545 - 28s/epoch - 748ms/step\n",
      "Epoch 11/23\n",
      "38/38 - 28s - loss: 0.5067 - accuracy: 0.7884 - val_loss: 0.5631 - val_accuracy: 0.7567 - 28s/epoch - 728ms/step\n",
      "Epoch 12/23\n",
      "38/38 - 27s - loss: 0.5029 - accuracy: 0.7841 - val_loss: 0.5605 - val_accuracy: 0.7556 - 27s/epoch - 720ms/step\n",
      "Epoch 13/23\n",
      "38/38 - 28s - loss: 0.5026 - accuracy: 0.7900 - val_loss: 0.5413 - val_accuracy: 0.7599 - 28s/epoch - 730ms/step\n",
      "Epoch 14/23\n",
      "38/38 - 27s - loss: 0.4891 - accuracy: 0.7945 - val_loss: 0.5579 - val_accuracy: 0.7556 - 27s/epoch - 721ms/step\n",
      "Epoch 15/23\n",
      "38/38 - 27s - loss: 0.4818 - accuracy: 0.7934 - val_loss: 0.5505 - val_accuracy: 0.7513 - 27s/epoch - 714ms/step\n",
      "Epoch 16/23\n",
      "38/38 - 29s - loss: 0.4785 - accuracy: 0.7926 - val_loss: 0.5360 - val_accuracy: 0.7567 - 29s/epoch - 761ms/step\n",
      "Epoch 17/23\n",
      "38/38 - 29s - loss: 0.4696 - accuracy: 0.8020 - val_loss: 0.5545 - val_accuracy: 0.7588 - 29s/epoch - 761ms/step\n",
      "Epoch 18/23\n",
      "38/38 - 29s - loss: 0.4626 - accuracy: 0.8057 - val_loss: 0.5531 - val_accuracy: 0.7684 - 29s/epoch - 750ms/step\n",
      "Epoch 19/23\n",
      "38/38 - 28s - loss: 0.4651 - accuracy: 0.8049 - val_loss: 0.5575 - val_accuracy: 0.7535 - 28s/epoch - 740ms/step\n",
      "Epoch 20/23\n",
      "38/38 - 29s - loss: 0.4500 - accuracy: 0.8078 - val_loss: 0.6169 - val_accuracy: 0.7385 - 29s/epoch - 761ms/step\n",
      "Epoch 21/23\n",
      "38/38 - 29s - loss: 0.4594 - accuracy: 0.7996 - val_loss: 0.5536 - val_accuracy: 0.7609 - 29s/epoch - 757ms/step\n",
      "Epoch 22/23\n",
      "38/38 - 30s - loss: 0.4589 - accuracy: 0.8036 - val_loss: 0.5661 - val_accuracy: 0.7577 - 30s/epoch - 788ms/step\n",
      "Epoch 23/23\n",
      "38/38 - 32s - loss: 0.4462 - accuracy: 0.8092 - val_loss: 0.6019 - val_accuracy: 0.7503 - 32s/epoch - 845ms/step\n",
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_5 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 49, 49, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_12 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_13 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5345878005027771\n",
      "Test accuracy: 0.770477831363678\n"
     ]
    }
   ],
   "source": [
    "train(23,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e90e600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "38/38 - 33s - loss: 1.0723 - accuracy: 0.4724 - val_loss: 1.0674 - val_accuracy: 0.4813 - 33s/epoch - 857ms/step\n",
      "Epoch 2/30\n",
      "38/38 - 28s - loss: 1.0527 - accuracy: 0.4788 - val_loss: 1.0231 - val_accuracy: 0.4813 - 28s/epoch - 734ms/step\n",
      "Epoch 3/30\n",
      "38/38 - 28s - loss: 0.8766 - accuracy: 0.5895 - val_loss: 0.7753 - val_accuracy: 0.6585 - 28s/epoch - 730ms/step\n",
      "Epoch 4/30\n",
      "38/38 - 27s - loss: 0.7053 - accuracy: 0.6856 - val_loss: 0.8068 - val_accuracy: 0.6382 - 27s/epoch - 723ms/step\n",
      "Epoch 5/30\n",
      "38/38 - 28s - loss: 0.6279 - accuracy: 0.7230 - val_loss: 0.6555 - val_accuracy: 0.7033 - 28s/epoch - 725ms/step\n",
      "Epoch 6/30\n",
      "38/38 - 28s - loss: 0.5876 - accuracy: 0.7363 - val_loss: 0.6174 - val_accuracy: 0.7086 - 28s/epoch - 732ms/step\n",
      "Epoch 7/30\n",
      "38/38 - 28s - loss: 0.5686 - accuracy: 0.7566 - val_loss: 0.5928 - val_accuracy: 0.7428 - 28s/epoch - 731ms/step\n",
      "Epoch 8/30\n",
      "38/38 - 28s - loss: 0.5261 - accuracy: 0.7732 - val_loss: 0.5909 - val_accuracy: 0.7407 - 28s/epoch - 736ms/step\n",
      "Epoch 9/30\n",
      "38/38 - 29s - loss: 0.5249 - accuracy: 0.7764 - val_loss: 0.5750 - val_accuracy: 0.7545 - 29s/epoch - 750ms/step\n",
      "Epoch 10/30\n",
      "38/38 - 29s - loss: 0.5054 - accuracy: 0.7865 - val_loss: 0.5668 - val_accuracy: 0.7439 - 29s/epoch - 760ms/step\n",
      "Epoch 11/30\n",
      "38/38 - 28s - loss: 0.5009 - accuracy: 0.7862 - val_loss: 0.5580 - val_accuracy: 0.7620 - 28s/epoch - 731ms/step\n",
      "Epoch 12/30\n",
      "38/38 - 28s - loss: 0.4859 - accuracy: 0.7924 - val_loss: 0.5410 - val_accuracy: 0.7609 - 28s/epoch - 725ms/step\n",
      "Epoch 13/30\n",
      "38/38 - 27s - loss: 0.4711 - accuracy: 0.8001 - val_loss: 0.5428 - val_accuracy: 0.7631 - 27s/epoch - 719ms/step\n",
      "Epoch 14/30\n",
      "38/38 - 28s - loss: 0.4645 - accuracy: 0.7998 - val_loss: 0.5296 - val_accuracy: 0.7652 - 28s/epoch - 734ms/step\n",
      "Epoch 15/30\n",
      "38/38 - 28s - loss: 0.4649 - accuracy: 0.7972 - val_loss: 0.5319 - val_accuracy: 0.7727 - 28s/epoch - 729ms/step\n",
      "Epoch 16/30\n",
      "38/38 - 27s - loss: 0.4588 - accuracy: 0.8065 - val_loss: 0.5303 - val_accuracy: 0.7663 - 27s/epoch - 720ms/step\n",
      "Epoch 17/30\n",
      "38/38 - 27s - loss: 0.4365 - accuracy: 0.8137 - val_loss: 0.5343 - val_accuracy: 0.7695 - 27s/epoch - 724ms/step\n",
      "Epoch 18/30\n",
      "38/38 - 28s - loss: 0.4522 - accuracy: 0.8073 - val_loss: 0.5456 - val_accuracy: 0.7684 - 28s/epoch - 729ms/step\n",
      "Epoch 19/30\n",
      "38/38 - 28s - loss: 0.4307 - accuracy: 0.8191 - val_loss: 0.5280 - val_accuracy: 0.7620 - 28s/epoch - 732ms/step\n",
      "Epoch 20/30\n",
      "38/38 - 28s - loss: 0.4212 - accuracy: 0.8201 - val_loss: 0.5482 - val_accuracy: 0.7652 - 28s/epoch - 735ms/step\n",
      "Epoch 21/30\n",
      "38/38 - 28s - loss: 0.4225 - accuracy: 0.8191 - val_loss: 0.5318 - val_accuracy: 0.7834 - 28s/epoch - 745ms/step\n",
      "Epoch 22/30\n",
      "38/38 - 29s - loss: 0.4127 - accuracy: 0.8215 - val_loss: 0.5242 - val_accuracy: 0.7727 - 29s/epoch - 765ms/step\n",
      "Epoch 23/30\n",
      "38/38 - 28s - loss: 0.4171 - accuracy: 0.8228 - val_loss: 0.5599 - val_accuracy: 0.7748 - 28s/epoch - 740ms/step\n",
      "Epoch 24/30\n",
      "38/38 - 27s - loss: 0.4072 - accuracy: 0.8263 - val_loss: 0.5746 - val_accuracy: 0.7673 - 27s/epoch - 720ms/step\n",
      "Epoch 25/30\n",
      "38/38 - 28s - loss: 0.3987 - accuracy: 0.8268 - val_loss: 0.5961 - val_accuracy: 0.7599 - 28s/epoch - 725ms/step\n",
      "Epoch 26/30\n",
      "38/38 - 28s - loss: 0.4171 - accuracy: 0.8225 - val_loss: 0.5596 - val_accuracy: 0.7567 - 28s/epoch - 724ms/step\n",
      "Epoch 27/30\n",
      "38/38 - 28s - loss: 0.3886 - accuracy: 0.8332 - val_loss: 0.5493 - val_accuracy: 0.7609 - 28s/epoch - 729ms/step\n",
      "Epoch 28/30\n",
      "38/38 - 28s - loss: 0.3790 - accuracy: 0.8369 - val_loss: 0.5581 - val_accuracy: 0.7737 - 28s/epoch - 738ms/step\n",
      "Epoch 29/30\n",
      "38/38 - 28s - loss: 0.3872 - accuracy: 0.8383 - val_loss: 0.5517 - val_accuracy: 0.7769 - 28s/epoch - 733ms/step\n",
      "Epoch 30/30\n",
      "38/38 - 28s - loss: 0.3657 - accuracy: 0.8423 - val_loss: 0.6134 - val_accuracy: 0.7503 - 28s/epoch - 740ms/step\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_14 (MaxPoolin  (None, 49, 49, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_25 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5597209930419922\n",
      "Test accuracy: 0.7781569957733154\n"
     ]
    }
   ],
   "source": [
    "train(30,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac863b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "def train(epochs_num,batch_len):\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "    dataset, labels, test_size=0.2, random_state=42)\n",
    "    X_train=X_train.reshape(-1,100,100,1)\n",
    "    X_test=X_test.reshape(-1,100,100,1)\n",
    "    Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "    Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "    \n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(3):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        for i in range(3):\n",
    "            hidden=layers.Dense(30,activation=\"relu\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/math.pow(76.4,math.pow(i+1,-1)), maxval=1/math.pow(76.4,math.pow(i+1,-1)), seed=None))(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "        output=layers.Dense(3,activation=\"softmax\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/math.pow(76.4,math.pow(4,-1)), maxval=1/math.pow(76.4,math.pow(4,-1)), seed=None))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=[\"accuracy\"])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.2,epochs=epochs_num,batch_size=batch_len,verbose=2,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c769f738",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "38/38 - 43s - loss: 1.0580 - accuracy: 0.4750 - val_loss: 1.0267 - val_accuracy: 0.4813 - 43s/epoch - 1s/step\n",
      "Epoch 2/30\n",
      "38/38 - 35s - loss: 0.8295 - accuracy: 0.6250 - val_loss: 0.7896 - val_accuracy: 0.6371 - 35s/epoch - 924ms/step\n",
      "Epoch 3/30\n",
      "38/38 - 35s - loss: 0.6897 - accuracy: 0.6875 - val_loss: 0.7392 - val_accuracy: 0.6745 - 35s/epoch - 929ms/step\n",
      "Epoch 4/30\n",
      "38/38 - 36s - loss: 0.6460 - accuracy: 0.7091 - val_loss: 0.6633 - val_accuracy: 0.7150 - 36s/epoch - 959ms/step\n",
      "Epoch 5/30\n",
      "38/38 - 37s - loss: 0.6024 - accuracy: 0.7425 - val_loss: 0.6110 - val_accuracy: 0.7535 - 37s/epoch - 985ms/step\n",
      "Epoch 6/30\n",
      "38/38 - 51s - loss: 0.5842 - accuracy: 0.7494 - val_loss: 0.6117 - val_accuracy: 0.7321 - 51s/epoch - 1s/step\n",
      "Epoch 7/30\n",
      "38/38 - 37s - loss: 0.5488 - accuracy: 0.7689 - val_loss: 0.5694 - val_accuracy: 0.7567 - 37s/epoch - 984ms/step\n",
      "Epoch 8/30\n",
      "38/38 - 36s - loss: 0.5375 - accuracy: 0.7774 - val_loss: 0.5781 - val_accuracy: 0.7481 - 36s/epoch - 953ms/step\n",
      "Epoch 9/30\n",
      "38/38 - 33s - loss: 0.5227 - accuracy: 0.7833 - val_loss: 0.5735 - val_accuracy: 0.7471 - 33s/epoch - 861ms/step\n",
      "Epoch 10/30\n",
      "38/38 - 28s - loss: 0.5093 - accuracy: 0.7908 - val_loss: 0.5416 - val_accuracy: 0.7556 - 28s/epoch - 745ms/step\n",
      "Epoch 11/30\n",
      "38/38 - 28s - loss: 0.4869 - accuracy: 0.7996 - val_loss: 0.5448 - val_accuracy: 0.7652 - 28s/epoch - 733ms/step\n",
      "Epoch 12/30\n",
      "38/38 - 28s - loss: 0.4825 - accuracy: 0.8014 - val_loss: 0.5406 - val_accuracy: 0.7609 - 28s/epoch - 738ms/step\n",
      "Epoch 13/30\n",
      "38/38 - 29s - loss: 0.4982 - accuracy: 0.7849 - val_loss: 0.5399 - val_accuracy: 0.7577 - 29s/epoch - 773ms/step\n",
      "Epoch 14/30\n",
      "38/38 - 29s - loss: 0.4764 - accuracy: 0.7969 - val_loss: 0.5439 - val_accuracy: 0.7641 - 29s/epoch - 751ms/step\n",
      "Epoch 15/30\n",
      "38/38 - 28s - loss: 0.4602 - accuracy: 0.8086 - val_loss: 0.5973 - val_accuracy: 0.7567 - 28s/epoch - 739ms/step\n",
      "Epoch 16/30\n",
      "38/38 - 31s - loss: 0.4596 - accuracy: 0.7988 - val_loss: 0.5547 - val_accuracy: 0.7428 - 31s/epoch - 821ms/step\n",
      "Model: \"model_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_7 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 49, 49, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.4949030876159668\n",
      "Test accuracy: 0.7815699577331543\n"
     ]
    }
   ],
   "source": [
    "train(30,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6664a8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "    dataset, labels, test_size=0.2, random_state=42)\n",
    "    X_train=X_train.reshape(-1,100,100,1)\n",
    "    X_test=X_test.reshape(-1,100,100,1)\n",
    "    Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "    Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "    \n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        for i in range(neur_layers):\n",
    "            hidden=layers.Dense(30,activation=\"relu\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/math.pow(76.4,math.pow(i+1,-1)), maxval=1/math.pow(76.4,math.pow(i+1,-1)), seed=None))(hidden)\n",
    "            #hidden=layers.Dropout(0.2)(hidden)\n",
    "        output=layers.Dense(3,activation=\"softmax\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/math.pow(76.4,math.pow(4,-1)), maxval=1/math.pow(76.4,math.pow(4,-1)), seed=None))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=[\"accuracy\"])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.2,epochs=epochs_num,batch_size=batch_len,verbose=2,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8e057c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "38/38 - 38s - loss: 1.0652 - accuracy: 0.4745 - val_loss: 1.0684 - val_accuracy: 0.4813 - 38s/epoch - 989ms/step\n",
      "Epoch 2/30\n",
      "38/38 - 31s - loss: 1.0378 - accuracy: 0.4788 - val_loss: 0.9699 - val_accuracy: 0.4813 - 31s/epoch - 825ms/step\n",
      "Epoch 3/30\n",
      "38/38 - 30s - loss: 0.8444 - accuracy: 0.5914 - val_loss: 0.7955 - val_accuracy: 0.6489 - 30s/epoch - 779ms/step\n",
      "Epoch 4/30\n",
      "38/38 - 30s - loss: 0.6933 - accuracy: 0.6864 - val_loss: 0.8176 - val_accuracy: 0.6371 - 30s/epoch - 778ms/step\n",
      "Epoch 5/30\n",
      "38/38 - 30s - loss: 0.6617 - accuracy: 0.6939 - val_loss: 0.6685 - val_accuracy: 0.6894 - 30s/epoch - 786ms/step\n",
      "Epoch 6/30\n",
      "38/38 - 30s - loss: 0.6170 - accuracy: 0.7166 - val_loss: 0.6352 - val_accuracy: 0.7012 - 30s/epoch - 799ms/step\n",
      "Epoch 7/30\n",
      "38/38 - 31s - loss: 0.6119 - accuracy: 0.7216 - val_loss: 0.6520 - val_accuracy: 0.6916 - 31s/epoch - 820ms/step\n",
      "Epoch 8/30\n",
      "38/38 - 31s - loss: 0.5880 - accuracy: 0.7358 - val_loss: 0.6111 - val_accuracy: 0.7343 - 31s/epoch - 803ms/step\n",
      "Epoch 9/30\n",
      "38/38 - 34s - loss: 0.5705 - accuracy: 0.7435 - val_loss: 0.6018 - val_accuracy: 0.7225 - 34s/epoch - 901ms/step\n",
      "Epoch 10/30\n",
      "38/38 - 29s - loss: 0.5651 - accuracy: 0.7443 - val_loss: 0.6082 - val_accuracy: 0.7279 - 29s/epoch - 769ms/step\n",
      "Epoch 11/30\n",
      "38/38 - 34s - loss: 0.5603 - accuracy: 0.7542 - val_loss: 0.6013 - val_accuracy: 0.7215 - 34s/epoch - 883ms/step\n",
      "Epoch 12/30\n",
      "38/38 - 32s - loss: 0.5284 - accuracy: 0.7670 - val_loss: 0.6022 - val_accuracy: 0.7236 - 32s/epoch - 835ms/step\n",
      "Epoch 13/30\n",
      "38/38 - 31s - loss: 0.5177 - accuracy: 0.7774 - val_loss: 0.5733 - val_accuracy: 0.7364 - 31s/epoch - 813ms/step\n",
      "Epoch 14/30\n",
      "38/38 - 31s - loss: 0.5233 - accuracy: 0.7638 - val_loss: 0.5924 - val_accuracy: 0.7300 - 31s/epoch - 816ms/step\n",
      "Epoch 15/30\n",
      "38/38 - 31s - loss: 0.5002 - accuracy: 0.7838 - val_loss: 0.5623 - val_accuracy: 0.7513 - 31s/epoch - 825ms/step\n",
      "Epoch 16/30\n",
      "38/38 - 29s - loss: 0.5064 - accuracy: 0.7785 - val_loss: 0.5505 - val_accuracy: 0.7513 - 29s/epoch - 764ms/step\n",
      "Epoch 17/30\n",
      "38/38 - 28s - loss: 0.4850 - accuracy: 0.7897 - val_loss: 0.5757 - val_accuracy: 0.7396 - 28s/epoch - 724ms/step\n",
      "Epoch 18/30\n",
      "38/38 - 27s - loss: 0.4882 - accuracy: 0.7913 - val_loss: 0.6009 - val_accuracy: 0.7449 - 27s/epoch - 717ms/step\n",
      "Epoch 19/30\n",
      "38/38 - 28s - loss: 0.4791 - accuracy: 0.7990 - val_loss: 0.5695 - val_accuracy: 0.7471 - 28s/epoch - 733ms/step\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_20 (MaxPoolin  (None, 49, 49, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_27 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_28 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_29 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 30)                76830     \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 124,363\n",
      "Trainable params: 124,363\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.529069185256958\n",
      "Test accuracy: 0.7755972743034363\n"
     ]
    }
   ],
   "source": [
    "train(30,100,3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbe94df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "38/38 - 38s - loss: 1.0690 - accuracy: 0.4788 - val_loss: 1.0566 - val_accuracy: 0.4813 - 38s/epoch - 995ms/step\n",
      "Epoch 2/30\n",
      "38/38 - 35s - loss: 1.0586 - accuracy: 0.4788 - val_loss: 1.0523 - val_accuracy: 0.4813 - 35s/epoch - 910ms/step\n",
      "Epoch 3/30\n",
      "38/38 - 29s - loss: 1.0343 - accuracy: 0.4788 - val_loss: 1.0162 - val_accuracy: 0.4813 - 29s/epoch - 762ms/step\n",
      "Epoch 4/30\n",
      "38/38 - 29s - loss: 0.8367 - accuracy: 0.6272 - val_loss: 0.7831 - val_accuracy: 0.6457 - 29s/epoch - 764ms/step\n",
      "Epoch 5/30\n",
      "38/38 - 33s - loss: 0.7120 - accuracy: 0.6835 - val_loss: 0.7249 - val_accuracy: 0.6841 - 33s/epoch - 869ms/step\n",
      "Epoch 6/30\n",
      "38/38 - 31s - loss: 0.6499 - accuracy: 0.7086 - val_loss: 0.6716 - val_accuracy: 0.6990 - 31s/epoch - 804ms/step\n",
      "Epoch 7/30\n",
      "38/38 - 30s - loss: 0.6365 - accuracy: 0.7155 - val_loss: 0.6428 - val_accuracy: 0.7129 - 30s/epoch - 793ms/step\n",
      "Epoch 8/30\n",
      "38/38 - 32s - loss: 0.5975 - accuracy: 0.7280 - val_loss: 0.6427 - val_accuracy: 0.7118 - 32s/epoch - 852ms/step\n",
      "Epoch 9/30\n",
      "38/38 - 33s - loss: 0.5865 - accuracy: 0.7299 - val_loss: 0.6035 - val_accuracy: 0.7311 - 33s/epoch - 875ms/step\n",
      "Epoch 10/30\n",
      "38/38 - 35s - loss: 0.5718 - accuracy: 0.7409 - val_loss: 0.5987 - val_accuracy: 0.7225 - 35s/epoch - 931ms/step\n",
      "Epoch 11/30\n",
      "38/38 - 34s - loss: 0.5573 - accuracy: 0.7446 - val_loss: 0.6196 - val_accuracy: 0.7193 - 34s/epoch - 892ms/step\n",
      "Epoch 12/30\n",
      "38/38 - 29s - loss: 0.5547 - accuracy: 0.7494 - val_loss: 0.6223 - val_accuracy: 0.7182 - 29s/epoch - 764ms/step\n",
      "Epoch 13/30\n",
      "38/38 - 29s - loss: 0.5288 - accuracy: 0.7718 - val_loss: 0.5735 - val_accuracy: 0.7535 - 29s/epoch - 769ms/step\n",
      "Epoch 14/30\n",
      "38/38 - 29s - loss: 0.5334 - accuracy: 0.7654 - val_loss: 0.5585 - val_accuracy: 0.7492 - 29s/epoch - 765ms/step\n",
      "Epoch 15/30\n",
      "38/38 - 34s - loss: 0.5524 - accuracy: 0.7555 - val_loss: 0.5902 - val_accuracy: 0.7300 - 34s/epoch - 891ms/step\n",
      "Epoch 16/30\n",
      "38/38 - 36s - loss: 0.5134 - accuracy: 0.7683 - val_loss: 0.5583 - val_accuracy: 0.7588 - 36s/epoch - 955ms/step\n",
      "Epoch 17/30\n",
      "38/38 - 30s - loss: 0.5060 - accuracy: 0.7825 - val_loss: 0.5600 - val_accuracy: 0.7503 - 30s/epoch - 797ms/step\n",
      "Epoch 18/30\n",
      "38/38 - 29s - loss: 0.4867 - accuracy: 0.7910 - val_loss: 0.6571 - val_accuracy: 0.7268 - 29s/epoch - 773ms/step\n",
      "Epoch 19/30\n",
      "38/38 - 28s - loss: 0.4860 - accuracy: 0.7916 - val_loss: 0.5662 - val_accuracy: 0.7620 - 28s/epoch - 736ms/step\n",
      "Model: \"model_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_9 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 49, 49, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 4, 4, 40)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 2, 2, 40)          14440     \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 160)               0         \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 30)                4830      \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_40 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 65,873\n",
      "Trainable params: 65,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5547810792922974\n",
      "Test accuracy: 0.76450514793396\n"
     ]
    }
   ],
   "source": [
    "train(30,100,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "689457f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "38/38 - 37s - loss: 1.0714 - accuracy: 0.4716 - val_loss: 1.0568 - val_accuracy: 0.4813 - 37s/epoch - 981ms/step\n",
      "Epoch 2/30\n",
      "38/38 - 28s - loss: 1.0529 - accuracy: 0.4788 - val_loss: 1.0429 - val_accuracy: 0.4813 - 28s/epoch - 736ms/step\n",
      "Epoch 3/30\n",
      "38/38 - 28s - loss: 0.9720 - accuracy: 0.5223 - val_loss: 0.8584 - val_accuracy: 0.6126 - 28s/epoch - 741ms/step\n",
      "Epoch 4/30\n",
      "38/38 - 28s - loss: 0.7759 - accuracy: 0.6557 - val_loss: 0.8098 - val_accuracy: 0.6382 - 28s/epoch - 736ms/step\n",
      "Epoch 5/30\n",
      "38/38 - 28s - loss: 0.6936 - accuracy: 0.6952 - val_loss: 0.7064 - val_accuracy: 0.6926 - 28s/epoch - 728ms/step\n",
      "Epoch 6/30\n",
      "38/38 - 28s - loss: 0.6558 - accuracy: 0.7102 - val_loss: 0.6691 - val_accuracy: 0.7054 - 28s/epoch - 726ms/step\n",
      "Epoch 7/30\n",
      "38/38 - 27s - loss: 0.6182 - accuracy: 0.7256 - val_loss: 0.6700 - val_accuracy: 0.7044 - 27s/epoch - 719ms/step\n",
      "Epoch 8/30\n",
      "38/38 - 28s - loss: 0.6125 - accuracy: 0.7288 - val_loss: 0.6301 - val_accuracy: 0.7129 - 28s/epoch - 728ms/step\n",
      "Epoch 9/30\n",
      "38/38 - 28s - loss: 0.6003 - accuracy: 0.7294 - val_loss: 0.6330 - val_accuracy: 0.6948 - 28s/epoch - 737ms/step\n",
      "Epoch 10/30\n",
      "38/38 - 29s - loss: 0.5864 - accuracy: 0.7395 - val_loss: 0.6603 - val_accuracy: 0.7140 - 29s/epoch - 755ms/step\n",
      "Epoch 11/30\n",
      "38/38 - 29s - loss: 0.5640 - accuracy: 0.7502 - val_loss: 0.5895 - val_accuracy: 0.7407 - 29s/epoch - 758ms/step\n",
      "Epoch 12/30\n",
      "38/38 - 30s - loss: 0.5464 - accuracy: 0.7598 - val_loss: 0.5972 - val_accuracy: 0.7385 - 30s/epoch - 787ms/step\n",
      "Epoch 13/30\n",
      "38/38 - 29s - loss: 0.5352 - accuracy: 0.7675 - val_loss: 0.5686 - val_accuracy: 0.7556 - 29s/epoch - 767ms/step\n",
      "Epoch 14/30\n",
      "38/38 - 30s - loss: 0.5239 - accuracy: 0.7707 - val_loss: 0.5800 - val_accuracy: 0.7449 - 30s/epoch - 785ms/step\n",
      "Epoch 15/30\n",
      "38/38 - 37s - loss: 0.5133 - accuracy: 0.7822 - val_loss: 0.5501 - val_accuracy: 0.7588 - 37s/epoch - 983ms/step\n",
      "Epoch 16/30\n",
      "38/38 - 34s - loss: 0.4820 - accuracy: 0.7905 - val_loss: 0.5463 - val_accuracy: 0.7567 - 34s/epoch - 904ms/step\n",
      "Epoch 17/30\n",
      "38/38 - 32s - loss: 0.4826 - accuracy: 0.7974 - val_loss: 0.5487 - val_accuracy: 0.7631 - 32s/epoch - 839ms/step\n",
      "Epoch 18/30\n",
      "38/38 - 35s - loss: 0.4711 - accuracy: 0.7977 - val_loss: 0.5437 - val_accuracy: 0.7663 - 35s/epoch - 912ms/step\n",
      "Epoch 19/30\n",
      "38/38 - 33s - loss: 0.4646 - accuracy: 0.7948 - val_loss: 0.5411 - val_accuracy: 0.7620 - 33s/epoch - 865ms/step\n",
      "Epoch 20/30\n",
      "38/38 - 30s - loss: 0.4557 - accuracy: 0.7964 - val_loss: 0.5754 - val_accuracy: 0.7460 - 30s/epoch - 789ms/step\n",
      "Epoch 21/30\n",
      "38/38 - 33s - loss: 0.4530 - accuracy: 0.8070 - val_loss: 0.5416 - val_accuracy: 0.7695 - 33s/epoch - 867ms/step\n",
      "Epoch 22/30\n",
      "38/38 - 31s - loss: 0.4498 - accuracy: 0.8044 - val_loss: 0.5536 - val_accuracy: 0.7535 - 31s/epoch - 819ms/step\n",
      "Model: \"model_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_10 (InputLayer)       [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_35 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_27 (MaxPoolin  (None, 49, 49, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_28 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_29 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " max_pooling2d_30 (MaxPoolin  (None, 4, 4, 40)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_39 (Conv2D)          (None, 2, 2, 40)          14440     \n",
      "                                                                 \n",
      " flatten_9 (Flatten)         (None, 160)               0         \n",
      "                                                                 \n",
      " dense_41 (Dense)            (None, 30)                4830      \n",
      "                                                                 \n",
      " dense_42 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_43 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dense_44 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,943\n",
      "Trainable params: 64,943\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5158875584602356\n",
      "Test accuracy: 0.7807167172431946\n"
     ]
    }
   ],
   "source": [
    "train(30,100,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "64588d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "    dataset, labels, test_size=0.2, random_state=42)\n",
    "    X_train=X_train.reshape(-1,100,100,1)\n",
    "    X_test=X_test.reshape(-1,100,100,1)\n",
    "    Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "    Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "    \n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        for i in range(neur_layers):\n",
    "            hidden=layers.Dense(30,activation=\"relu\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/math.pow(76.4,math.pow(i+1,-1)), maxval=1/math.pow(76.4,math.pow(i+1,-1)), seed=None))(hidden)\n",
    "            hidden=layers.Dropout(0.2)(hidden)\n",
    "        output=layers.Dense(3,activation=\"softmax\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/math.pow(76.4,math.pow(4,-1)), maxval=1/math.pow(76.4,math.pow(4,-1)), seed=None))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=[\"accuracy\"])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.2,epochs=epochs_num,batch_size=batch_len,verbose=2,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb6bdef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "38/38 - 37s - loss: 1.0782 - accuracy: 0.4708 - val_loss: 1.0664 - val_accuracy: 0.4813 - 37s/epoch - 985ms/step\n",
      "Epoch 2/30\n",
      "38/38 - 30s - loss: 1.0618 - accuracy: 0.4788 - val_loss: 1.0572 - val_accuracy: 0.4813 - 30s/epoch - 800ms/step\n",
      "Epoch 3/30\n",
      "38/38 - 31s - loss: 1.0558 - accuracy: 0.4788 - val_loss: 1.0547 - val_accuracy: 0.4813 - 31s/epoch - 820ms/step\n",
      "Epoch 4/30\n",
      "38/38 - 31s - loss: 1.0508 - accuracy: 0.4788 - val_loss: 1.0476 - val_accuracy: 0.4813 - 31s/epoch - 827ms/step\n",
      "Epoch 5/30\n",
      "38/38 - 31s - loss: 0.9631 - accuracy: 0.5151 - val_loss: 0.8503 - val_accuracy: 0.6211 - 31s/epoch - 811ms/step\n",
      "Epoch 6/30\n",
      "38/38 - 29s - loss: 0.8121 - accuracy: 0.6317 - val_loss: 0.8067 - val_accuracy: 0.6329 - 29s/epoch - 768ms/step\n",
      "Epoch 7/30\n",
      "38/38 - 29s - loss: 0.7599 - accuracy: 0.6749 - val_loss: 0.7547 - val_accuracy: 0.6414 - 29s/epoch - 771ms/step\n",
      "Epoch 8/30\n",
      "38/38 - 31s - loss: 0.7225 - accuracy: 0.6845 - val_loss: 0.7200 - val_accuracy: 0.6670 - 31s/epoch - 812ms/step\n",
      "Epoch 9/30\n",
      "38/38 - 30s - loss: 0.6996 - accuracy: 0.6904 - val_loss: 0.6848 - val_accuracy: 0.6649 - 30s/epoch - 787ms/step\n",
      "Epoch 10/30\n",
      "38/38 - 29s - loss: 0.6559 - accuracy: 0.7086 - val_loss: 0.6652 - val_accuracy: 0.6990 - 29s/epoch - 770ms/step\n",
      "Epoch 11/30\n",
      "38/38 - 28s - loss: 0.6411 - accuracy: 0.7168 - val_loss: 0.6504 - val_accuracy: 0.7044 - 28s/epoch - 735ms/step\n",
      "Epoch 12/30\n",
      "38/38 - 28s - loss: 0.6321 - accuracy: 0.7166 - val_loss: 0.6626 - val_accuracy: 0.6980 - 28s/epoch - 737ms/step\n",
      "Epoch 13/30\n",
      "38/38 - 28s - loss: 0.6094 - accuracy: 0.7291 - val_loss: 0.6199 - val_accuracy: 0.7129 - 28s/epoch - 729ms/step\n",
      "Epoch 14/30\n",
      "38/38 - 28s - loss: 0.5957 - accuracy: 0.7326 - val_loss: 0.5884 - val_accuracy: 0.7300 - 28s/epoch - 735ms/step\n",
      "Epoch 15/30\n",
      "38/38 - 28s - loss: 0.5868 - accuracy: 0.7334 - val_loss: 0.5913 - val_accuracy: 0.7439 - 28s/epoch - 735ms/step\n",
      "Epoch 16/30\n",
      "38/38 - 28s - loss: 0.5727 - accuracy: 0.7449 - val_loss: 0.6063 - val_accuracy: 0.7140 - 28s/epoch - 730ms/step\n",
      "Epoch 17/30\n",
      "38/38 - 27s - loss: 0.5994 - accuracy: 0.7347 - val_loss: 0.5790 - val_accuracy: 0.7396 - 27s/epoch - 723ms/step\n",
      "Epoch 18/30\n",
      "38/38 - 28s - loss: 0.5568 - accuracy: 0.7529 - val_loss: 0.5654 - val_accuracy: 0.7503 - 28s/epoch - 725ms/step\n",
      "Epoch 19/30\n",
      "38/38 - 28s - loss: 0.5482 - accuracy: 0.7521 - val_loss: 0.5713 - val_accuracy: 0.7620 - 28s/epoch - 735ms/step\n",
      "Epoch 20/30\n",
      "38/38 - 29s - loss: 0.5675 - accuracy: 0.7459 - val_loss: 0.5540 - val_accuracy: 0.7545 - 29s/epoch - 764ms/step\n",
      "Epoch 21/30\n",
      "38/38 - 28s - loss: 0.5528 - accuracy: 0.7537 - val_loss: 0.6070 - val_accuracy: 0.7225 - 28s/epoch - 749ms/step\n",
      "Epoch 22/30\n",
      "38/38 - 28s - loss: 0.5346 - accuracy: 0.7643 - val_loss: 0.5561 - val_accuracy: 0.7620 - 28s/epoch - 742ms/step\n",
      "Epoch 23/30\n",
      "38/38 - 28s - loss: 0.5434 - accuracy: 0.7603 - val_loss: 0.5655 - val_accuracy: 0.7513 - 28s/epoch - 747ms/step\n",
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_31 (MaxPoolin  (None, 49, 49, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_41 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_32 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_42 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_33 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_43 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " max_pooling2d_34 (MaxPoolin  (None, 4, 4, 40)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_44 (Conv2D)          (None, 2, 2, 40)          14440     \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 160)               0         \n",
      "                                                                 \n",
      " dense_45 (Dense)            (None, 30)                4830      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 30)                0         \n",
      "                                                                 \n",
      " dense_46 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 30)                0         \n",
      "                                                                 \n",
      " dense_47 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 30)                0         \n",
      "                                                                 \n",
      " dense_48 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,943\n",
      "Trainable params: 64,943\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5517886877059937\n",
      "Test accuracy: 0.7679181098937988\n"
     ]
    }
   ],
   "source": [
    "train(30,100,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "999e62bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "38/38 - 33s - loss: 1.0684 - accuracy: 0.4782 - val_loss: 1.0600 - val_accuracy: 0.4813 - 33s/epoch - 869ms/step\n",
      "Epoch 2/30\n",
      "38/38 - 29s - loss: 1.0581 - accuracy: 0.4790 - val_loss: 1.0480 - val_accuracy: 0.4813 - 29s/epoch - 765ms/step\n",
      "Epoch 3/30\n",
      "38/38 - 28s - loss: 1.0177 - accuracy: 0.4788 - val_loss: 0.9953 - val_accuracy: 0.4813 - 28s/epoch - 747ms/step\n",
      "Epoch 4/30\n",
      "38/38 - 28s - loss: 0.9029 - accuracy: 0.5236 - val_loss: 0.8472 - val_accuracy: 0.6361 - 28s/epoch - 745ms/step\n",
      "Epoch 5/30\n",
      "38/38 - 29s - loss: 0.7997 - accuracy: 0.6701 - val_loss: 0.7543 - val_accuracy: 0.6542 - 29s/epoch - 753ms/step\n",
      "Epoch 6/30\n",
      "38/38 - 30s - loss: 0.7451 - accuracy: 0.6776 - val_loss: 0.7191 - val_accuracy: 0.6809 - 30s/epoch - 781ms/step\n",
      "Epoch 7/30\n",
      "38/38 - 30s - loss: 0.7102 - accuracy: 0.6920 - val_loss: 0.6855 - val_accuracy: 0.6617 - 30s/epoch - 777ms/step\n",
      "Epoch 8/30\n",
      "38/38 - 28s - loss: 0.6771 - accuracy: 0.6979 - val_loss: 0.7245 - val_accuracy: 0.6510 - 28s/epoch - 748ms/step\n",
      "Epoch 9/30\n",
      "38/38 - 29s - loss: 0.6627 - accuracy: 0.7006 - val_loss: 0.6345 - val_accuracy: 0.6926 - 29s/epoch - 758ms/step\n",
      "Epoch 10/30\n",
      "38/38 - 28s - loss: 0.6309 - accuracy: 0.7174 - val_loss: 0.6255 - val_accuracy: 0.7065 - 28s/epoch - 749ms/step\n",
      "Epoch 11/30\n",
      "38/38 - 29s - loss: 0.6131 - accuracy: 0.7264 - val_loss: 0.6522 - val_accuracy: 0.6884 - 29s/epoch - 763ms/step\n",
      "Epoch 12/30\n",
      "38/38 - 29s - loss: 0.6270 - accuracy: 0.7206 - val_loss: 0.6405 - val_accuracy: 0.7343 - 29s/epoch - 754ms/step\n",
      "Epoch 13/30\n",
      "38/38 - 28s - loss: 0.5913 - accuracy: 0.7449 - val_loss: 0.5909 - val_accuracy: 0.7279 - 28s/epoch - 746ms/step\n",
      "Epoch 14/30\n",
      "38/38 - 28s - loss: 0.5640 - accuracy: 0.7483 - val_loss: 0.5697 - val_accuracy: 0.7535 - 28s/epoch - 741ms/step\n",
      "Epoch 15/30\n",
      "38/38 - 29s - loss: 0.5651 - accuracy: 0.7513 - val_loss: 0.5628 - val_accuracy: 0.7481 - 29s/epoch - 752ms/step\n",
      "Epoch 16/30\n",
      "38/38 - 29s - loss: 0.5479 - accuracy: 0.7558 - val_loss: 0.5412 - val_accuracy: 0.7641 - 29s/epoch - 769ms/step\n",
      "Epoch 17/30\n",
      "38/38 - 29s - loss: 0.5385 - accuracy: 0.7678 - val_loss: 0.5492 - val_accuracy: 0.7577 - 29s/epoch - 763ms/step\n",
      "Epoch 18/30\n",
      "38/38 - 29s - loss: 0.5263 - accuracy: 0.7691 - val_loss: 0.5352 - val_accuracy: 0.7791 - 29s/epoch - 759ms/step\n",
      "Epoch 19/30\n",
      "38/38 - 28s - loss: 0.5070 - accuracy: 0.7865 - val_loss: 0.6116 - val_accuracy: 0.7588 - 28s/epoch - 744ms/step\n",
      "Epoch 20/30\n",
      "38/38 - 28s - loss: 0.5216 - accuracy: 0.7753 - val_loss: 0.5410 - val_accuracy: 0.7737 - 28s/epoch - 746ms/step\n",
      "Epoch 21/30\n",
      "38/38 - 29s - loss: 0.5003 - accuracy: 0.7892 - val_loss: 0.5474 - val_accuracy: 0.7620 - 29s/epoch - 768ms/step\n",
      "Model: \"model_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_12 (InputLayer)       [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_45 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_35 (MaxPoolin  (None, 49, 49, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_46 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_36 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_47 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_37 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_48 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPoolin  (None, 4, 4, 40)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_49 (Conv2D)          (None, 2, 2, 40)          14440     \n",
      "                                                                 \n",
      " flatten_11 (Flatten)        (None, 160)               0         \n",
      "                                                                 \n",
      " dense_49 (Dense)            (None, 30)                4830      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 30)                0         \n",
      "                                                                 \n",
      " dense_50 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 30)                0         \n",
      "                                                                 \n",
      " dense_51 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 30)                0         \n",
      "                                                                 \n",
      " dense_52 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,943\n",
      "Trainable params: 64,943\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5294833183288574\n",
      "Test accuracy: 0.7679181098937988\n"
     ]
    }
   ],
   "source": [
    "train(30,100,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ad8fd701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "    dataset, labels, test_size=0.2, random_state=42)\n",
    "    X_train=X_train.reshape(-1,100,100,1)\n",
    "    X_test=X_test.reshape(-1,100,100,1)\n",
    "    Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "    Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "    \n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "            hidden=layers.Dropout(0.1)(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Dropout(0.2)(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        w=1/76.4\n",
    "        for i in range(neur_layers):\n",
    "            hidden=layers.Dense(30,activation=\"relu\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w,maxval=1/w, seed=None))(hidden)\n",
    "            hidden=layers.Dropout(0.2)(hidden)\n",
    "            w=w*30*0.8\n",
    "        output=layers.Dense(3,activation=\"softmax\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w, maxval=1/w, seed=None))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=[\"accuracy\"])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.2,epochs=epochs_num,batch_size=batch_len,verbose=2,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd993023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "38/38 - 41s - loss: 1.0909 - accuracy: 0.4694 - val_loss: 1.0822 - val_accuracy: 0.4813 - 41s/epoch - 1s/step\n",
      "Epoch 2/30\n",
      "38/38 - 35s - loss: 1.0653 - accuracy: 0.4785 - val_loss: 1.0586 - val_accuracy: 0.4813 - 35s/epoch - 917ms/step\n",
      "Epoch 3/30\n",
      "38/38 - 34s - loss: 1.0647 - accuracy: 0.4785 - val_loss: 1.0591 - val_accuracy: 0.4813 - 34s/epoch - 903ms/step\n",
      "Epoch 4/30\n",
      "38/38 - 33s - loss: 1.0541 - accuracy: 0.4788 - val_loss: 1.0501 - val_accuracy: 0.4813 - 33s/epoch - 876ms/step\n",
      "Epoch 5/30\n",
      "38/38 - 33s - loss: 1.0411 - accuracy: 0.4790 - val_loss: 0.9929 - val_accuracy: 0.4813 - 33s/epoch - 880ms/step\n",
      "Epoch 6/30\n",
      "38/38 - 34s - loss: 0.9480 - accuracy: 0.5431 - val_loss: 0.7982 - val_accuracy: 0.6307 - 34s/epoch - 882ms/step\n",
      "Epoch 7/30\n",
      "38/38 - 33s - loss: 0.8065 - accuracy: 0.6368 - val_loss: 0.7513 - val_accuracy: 0.6542 - 33s/epoch - 877ms/step\n",
      "Epoch 8/30\n",
      "38/38 - 34s - loss: 0.7840 - accuracy: 0.6515 - val_loss: 0.7132 - val_accuracy: 0.6724 - 34s/epoch - 897ms/step\n",
      "Epoch 9/30\n",
      "38/38 - 33s - loss: 0.7076 - accuracy: 0.6744 - val_loss: 0.6634 - val_accuracy: 0.6820 - 33s/epoch - 880ms/step\n",
      "Epoch 10/30\n",
      "38/38 - 33s - loss: 0.6991 - accuracy: 0.6845 - val_loss: 0.6628 - val_accuracy: 0.6809 - 33s/epoch - 880ms/step\n",
      "Epoch 11/30\n",
      "38/38 - 34s - loss: 0.6828 - accuracy: 0.6926 - val_loss: 0.6530 - val_accuracy: 0.6702 - 34s/epoch - 888ms/step\n",
      "Epoch 12/30\n",
      "38/38 - 34s - loss: 0.6657 - accuracy: 0.6931 - val_loss: 0.6442 - val_accuracy: 0.6766 - 34s/epoch - 885ms/step\n",
      "Epoch 13/30\n",
      "38/38 - 34s - loss: 0.6500 - accuracy: 0.6966 - val_loss: 0.6426 - val_accuracy: 0.6798 - 34s/epoch - 899ms/step\n",
      "Epoch 14/30\n",
      "38/38 - 33s - loss: 0.6378 - accuracy: 0.6998 - val_loss: 0.6349 - val_accuracy: 0.6820 - 33s/epoch - 881ms/step\n",
      "Epoch 15/30\n",
      "38/38 - 33s - loss: 0.6346 - accuracy: 0.7016 - val_loss: 0.6388 - val_accuracy: 0.6830 - 33s/epoch - 878ms/step\n",
      "Epoch 16/30\n",
      "38/38 - 33s - loss: 0.6198 - accuracy: 0.7030 - val_loss: 0.6333 - val_accuracy: 0.6841 - 33s/epoch - 877ms/step\n",
      "Epoch 17/30\n",
      "38/38 - 33s - loss: 0.6212 - accuracy: 0.7030 - val_loss: 0.6045 - val_accuracy: 0.6926 - 33s/epoch - 880ms/step\n",
      "Epoch 18/30\n",
      "38/38 - 34s - loss: 0.6200 - accuracy: 0.7086 - val_loss: 0.6303 - val_accuracy: 0.6873 - 34s/epoch - 885ms/step\n",
      "Epoch 19/30\n",
      "38/38 - 33s - loss: 0.6066 - accuracy: 0.7107 - val_loss: 0.5958 - val_accuracy: 0.6916 - 33s/epoch - 876ms/step\n",
      "Epoch 20/30\n",
      "38/38 - 33s - loss: 0.5989 - accuracy: 0.7123 - val_loss: 0.6233 - val_accuracy: 0.6830 - 33s/epoch - 881ms/step\n",
      "Epoch 21/30\n",
      "38/38 - 33s - loss: 0.5784 - accuracy: 0.7240 - val_loss: 0.5997 - val_accuracy: 0.7065 - 33s/epoch - 870ms/step\n",
      "Epoch 22/30\n",
      "38/38 - 33s - loss: 0.5811 - accuracy: 0.7206 - val_loss: 0.6137 - val_accuracy: 0.7182 - 33s/epoch - 867ms/step\n",
      "Model: \"model_12\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_15 (InputLayer)       [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_60 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_47 (MaxPoolin  (None, 49, 49, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 49, 49, 40)        0         \n",
      "                                                                 \n",
      " conv2d_61 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_48 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 23, 23, 40)        0         \n",
      "                                                                 \n",
      " conv2d_62 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_49 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_18 (Dropout)        (None, 10, 10, 40)        0         \n",
      "                                                                 \n",
      " conv2d_63 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " max_pooling2d_50 (MaxPoolin  (None, 4, 4, 40)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 4, 4, 40)          0         \n",
      "                                                                 \n",
      " conv2d_64 (Conv2D)          (None, 2, 2, 40)          14440     \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 2, 2, 40)          0         \n",
      "                                                                 \n",
      " flatten_14 (Flatten)        (None, 160)               0         \n",
      "                                                                 \n",
      " dense_53 (Dense)            (None, 30)                4830      \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 30)                0         \n",
      "                                                                 \n",
      " dense_54 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 30)                0         \n",
      "                                                                 \n",
      " dense_55 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 30)                0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,943\n",
      "Trainable params: 64,943\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5610468983650208\n",
      "Test accuracy: 0.7329351305961609\n"
     ]
    }
   ],
   "source": [
    "train(30,100,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8ff5008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "    dataset, labels, test_size=0.2, random_state=42)\n",
    "    X_train=X_train.reshape(-1,100,100,1)\n",
    "    X_test=X_test.reshape(-1,100,100,1)\n",
    "    Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "    Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "    \n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        w=1/76.4\n",
    "        for i in range(neur_layers):\n",
    "            hidden=layers.Dense(30,activation=\"relu\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w,maxval=1/w, seed=None))(hidden)\n",
    "            hidden=layers.Dropout(0.2)(hidden)\n",
    "            w=w*30*0.8\n",
    "        output=layers.Dense(3,activation=\"softmax\",kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w, maxval=1/w, seed=None))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=[\"accuracy\"])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.2,epochs=epochs_num,batch_size=batch_len,verbose=2,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "31786b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "38/38 - 31s - loss: 1.0333 - accuracy: 0.5028 - val_loss: 0.8423 - val_accuracy: 0.6083 - 31s/epoch - 819ms/step\n",
      "Epoch 2/30\n",
      "38/38 - 29s - loss: 0.7877 - accuracy: 0.6442 - val_loss: 0.7400 - val_accuracy: 0.6553 - 29s/epoch - 764ms/step\n",
      "Epoch 3/30\n",
      "38/38 - 28s - loss: 0.7075 - accuracy: 0.6797 - val_loss: 0.6812 - val_accuracy: 0.6756 - 28s/epoch - 749ms/step\n",
      "Epoch 4/30\n",
      "38/38 - 28s - loss: 0.6664 - accuracy: 0.6968 - val_loss: 0.6795 - val_accuracy: 0.6756 - 28s/epoch - 744ms/step\n",
      "Epoch 5/30\n",
      "38/38 - 29s - loss: 0.6393 - accuracy: 0.7011 - val_loss: 0.6814 - val_accuracy: 0.6809 - 29s/epoch - 754ms/step\n",
      "Epoch 6/30\n",
      "38/38 - 28s - loss: 0.6253 - accuracy: 0.7131 - val_loss: 0.6504 - val_accuracy: 0.7065 - 28s/epoch - 747ms/step\n",
      "Epoch 7/30\n",
      "38/38 - 29s - loss: 0.5918 - accuracy: 0.7310 - val_loss: 0.6529 - val_accuracy: 0.7193 - 29s/epoch - 752ms/step\n",
      "Epoch 8/30\n",
      "38/38 - 29s - loss: 0.5886 - accuracy: 0.7390 - val_loss: 0.6316 - val_accuracy: 0.7257 - 29s/epoch - 753ms/step\n",
      "Epoch 9/30\n",
      "38/38 - 28s - loss: 0.5678 - accuracy: 0.7499 - val_loss: 0.6575 - val_accuracy: 0.7215 - 28s/epoch - 743ms/step\n",
      "Epoch 10/30\n",
      "38/38 - 29s - loss: 0.5629 - accuracy: 0.7563 - val_loss: 0.6181 - val_accuracy: 0.7428 - 29s/epoch - 759ms/step\n",
      "Epoch 11/30\n",
      "38/38 - 29s - loss: 0.5558 - accuracy: 0.7617 - val_loss: 0.6011 - val_accuracy: 0.7407 - 29s/epoch - 765ms/step\n",
      "Epoch 12/30\n",
      "38/38 - 29s - loss: 0.5340 - accuracy: 0.7638 - val_loss: 0.6042 - val_accuracy: 0.7353 - 29s/epoch - 767ms/step\n",
      "Epoch 13/30\n",
      "38/38 - 29s - loss: 0.5184 - accuracy: 0.7716 - val_loss: 0.5741 - val_accuracy: 0.7545 - 29s/epoch - 757ms/step\n",
      "Epoch 14/30\n",
      "38/38 - 28s - loss: 0.5137 - accuracy: 0.7705 - val_loss: 0.6170 - val_accuracy: 0.7375 - 28s/epoch - 740ms/step\n",
      "Epoch 15/30\n",
      "38/38 - 29s - loss: 0.5128 - accuracy: 0.7753 - val_loss: 0.5931 - val_accuracy: 0.7503 - 29s/epoch - 755ms/step\n",
      "Epoch 16/30\n",
      "38/38 - 29s - loss: 0.5117 - accuracy: 0.7721 - val_loss: 0.6180 - val_accuracy: 0.7492 - 29s/epoch - 758ms/step\n",
      "Model: \"model_13\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_16 (InputLayer)       [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_65 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_51 (MaxPoolin  (None, 49, 49, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_66 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_52 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_67 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_53 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " max_pooling2d_54 (MaxPoolin  (None, 4, 4, 40)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 2, 2, 40)          14440     \n",
      "                                                                 \n",
      " flatten_15 (Flatten)        (None, 160)               0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 30)                4830      \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 30)                0         \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 30)                0         \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 30)                0         \n",
      "                                                                 \n",
      " dense_60 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,943\n",
      "Trainable params: 64,943\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 0.5309755206108093\n",
      "Test accuracy: 0.7849829196929932\n"
     ]
    }
   ],
   "source": [
    "train(30,100,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22286af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "    dataset, labels, test_size=0.2, random_state=42)\n",
    "    X_train=X_train.reshape(-1,100,100,1)\n",
    "    X_test=X_test.reshape(-1,100,100,1)\n",
    "    Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "    Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "    \n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        w=1/76.4\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation=\"relu\",kernel_regularizer=regularizers.L2(math.pow(10,-(i+1))),kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w,maxval=1/w, seed=None))(hidden)\n",
    "            hidden=layers.Dropout(0.2)(hidden)\n",
    "            w=w*30*0.8\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation=\"softmax\",kernel_regularizer=regularizers.L2(math.pow(10,-(neur_layers+1))),kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w, maxval=1/w, seed=None))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=[\"accuracy\"])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.2,epochs=epochs_num,batch_size=batch_len,verbose=2,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10b3427f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "38/38 - 31s - loss: 927603.0625 - accuracy: 0.4654 - val_loss: 926880.3125 - val_accuracy: 0.4813 - 31s/epoch - 819ms/step\n",
      "Epoch 2/30\n",
      "38/38 - 29s - loss: 926213.5625 - accuracy: 0.5733 - val_loss: 925491.5000 - val_accuracy: 0.6510 - 29s/epoch - 763ms/step\n",
      "Epoch 3/30\n",
      "38/38 - 28s - loss: 924825.6250 - accuracy: 0.6557 - val_loss: 924104.5000 - val_accuracy: 0.6382 - 28s/epoch - 741ms/step\n",
      "Epoch 4/30\n",
      "38/38 - 28s - loss: 923439.5000 - accuracy: 0.6771 - val_loss: 922719.3750 - val_accuracy: 0.6734 - 28s/epoch - 743ms/step\n",
      "Epoch 5/30\n",
      "38/38 - 29s - loss: 922055.0625 - accuracy: 0.6942 - val_loss: 921335.7500 - val_accuracy: 0.6617 - 29s/epoch - 751ms/step\n",
      "Epoch 6/30\n",
      "38/38 - 28s - loss: 920672.5625 - accuracy: 0.6995 - val_loss: 919954.0625 - val_accuracy: 0.7140 - 28s/epoch - 746ms/step\n",
      "Epoch 7/30\n",
      "38/38 - 28s - loss: 919292.0625 - accuracy: 0.7182 - val_loss: 918574.8750 - val_accuracy: 0.7257 - 28s/epoch - 744ms/step\n",
      "Epoch 8/30\n",
      "38/38 - 28s - loss: 917913.7500 - accuracy: 0.7230 - val_loss: 917197.9375 - val_accuracy: 0.7012 - 28s/epoch - 749ms/step\n",
      "Epoch 9/30\n",
      "38/38 - 29s - loss: 916537.9375 - accuracy: 0.7264 - val_loss: 915823.3125 - val_accuracy: 0.7492 - 29s/epoch - 753ms/step\n",
      "Epoch 10/30\n",
      "38/38 - 29s - loss: 915164.3125 - accuracy: 0.7406 - val_loss: 914450.6250 - val_accuracy: 0.7524 - 29s/epoch - 754ms/step\n",
      "Epoch 11/30\n",
      "38/38 - 28s - loss: 913792.5000 - accuracy: 0.7571 - val_loss: 913079.7500 - val_accuracy: 0.7279 - 28s/epoch - 744ms/step\n",
      "Epoch 12/30\n",
      "38/38 - 28s - loss: 912422.6250 - accuracy: 0.7545 - val_loss: 911710.7500 - val_accuracy: 0.7684 - 28s/epoch - 748ms/step\n",
      "Epoch 13/30\n",
      "38/38 - 29s - loss: 911054.0625 - accuracy: 0.7590 - val_loss: 910343.0625 - val_accuracy: 0.7471 - 29s/epoch - 761ms/step\n",
      "Epoch 14/30\n",
      "38/38 - 28s - loss: 909687.5000 - accuracy: 0.7643 - val_loss: 908977.2500 - val_accuracy: 0.7567 - 28s/epoch - 745ms/step\n",
      "Epoch 15/30\n",
      "38/38 - 29s - loss: 908322.6875 - accuracy: 0.7748 - val_loss: 907613.3750 - val_accuracy: 0.7759 - 29s/epoch - 755ms/step\n",
      "Epoch 16/30\n",
      "38/38 - 28s - loss: 906959.1250 - accuracy: 0.7737 - val_loss: 906251.0000 - val_accuracy: 0.7375 - 28s/epoch - 749ms/step\n",
      "Epoch 17/30\n",
      "38/38 - 29s - loss: 905598.1875 - accuracy: 0.7702 - val_loss: 904890.6250 - val_accuracy: 0.7652 - 29s/epoch - 775ms/step\n",
      "Epoch 18/30\n",
      "38/38 - 29s - loss: 904238.5000 - accuracy: 0.7798 - val_loss: 903532.3125 - val_accuracy: 0.7673 - 29s/epoch - 760ms/step\n",
      "Epoch 19/30\n",
      "38/38 - 28s - loss: 902881.3125 - accuracy: 0.7836 - val_loss: 902176.5625 - val_accuracy: 0.7823 - 28s/epoch - 748ms/step\n",
      "Epoch 20/30\n",
      "38/38 - 28s - loss: 901526.8125 - accuracy: 0.7913 - val_loss: 900823.4375 - val_accuracy: 0.7663 - 28s/epoch - 742ms/step\n",
      "Epoch 21/30\n",
      "38/38 - 29s - loss: 900174.9375 - accuracy: 0.7950 - val_loss: 899472.7500 - val_accuracy: 0.7759 - 29s/epoch - 753ms/step\n",
      "Epoch 22/30\n",
      "38/38 - 28s - loss: 898825.2500 - accuracy: 0.7902 - val_loss: 898124.3125 - val_accuracy: 0.7449 - 28s/epoch - 744ms/step\n",
      "Epoch 23/30\n",
      "38/38 - 28s - loss: 897477.6250 - accuracy: 0.7884 - val_loss: 896777.5625 - val_accuracy: 0.7577 - 28s/epoch - 743ms/step\n",
      "Epoch 24/30\n",
      "38/38 - 29s - loss: 896131.8750 - accuracy: 0.7876 - val_loss: 895432.6250 - val_accuracy: 0.7716 - 29s/epoch - 762ms/step\n",
      "Epoch 25/30\n",
      "38/38 - 28s - loss: 894787.6875 - accuracy: 0.7974 - val_loss: 894089.5000 - val_accuracy: 0.7780 - 28s/epoch - 739ms/step\n",
      "Epoch 26/30\n",
      "38/38 - 28s - loss: 893445.4375 - accuracy: 0.8041 - val_loss: 892748.2500 - val_accuracy: 0.7866 - 28s/epoch - 746ms/step\n",
      "Epoch 27/30\n",
      "38/38 - 28s - loss: 892105.1250 - accuracy: 0.8094 - val_loss: 891408.6875 - val_accuracy: 0.7727 - 28s/epoch - 747ms/step\n",
      "Epoch 28/30\n",
      "38/38 - 28s - loss: 890766.3750 - accuracy: 0.8172 - val_loss: 890070.8750 - val_accuracy: 0.7769 - 28s/epoch - 743ms/step\n",
      "Epoch 29/30\n",
      "38/38 - 28s - loss: 889429.2500 - accuracy: 0.8113 - val_loss: 888734.7500 - val_accuracy: 0.7652 - 28s/epoch - 733ms/step\n",
      "Epoch 30/30\n",
      "38/38 - 28s - loss: 888093.7500 - accuracy: 0.8204 - val_loss: 887399.8125 - val_accuracy: 0.7609 - 28s/epoch - 744ms/step\n",
      "Model: \"model_16\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_21 (InputLayer)       [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_90 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_71 (MaxPoolin  (None, 49, 49, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_91 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_72 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_92 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_73 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_93 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " max_pooling2d_74 (MaxPoolin  (None, 4, 4, 40)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_94 (Conv2D)          (None, 2, 2, 40)          14440     \n",
      "                                                                 \n",
      " flatten_20 (Flatten)        (None, 160)               0         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 30)                4830      \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        (None, 30)                0         \n",
      "                                                                 \n",
      " dense_76 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dropout_40 (Dropout)        (None, 30)                0         \n",
      "                                                                 \n",
      " dense_77 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dropout_41 (Dropout)        (None, 30)                0         \n",
      "                                                                 \n",
      " dense_78 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,943\n",
      "Trainable params: 64,943\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 887399.9375\n",
      "Test accuracy: 0.7798634767532349\n"
     ]
    }
   ],
   "source": [
    "train(30,100,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "cd33e8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "38/38 - 32s - loss: 934699.3750 - accuracy: 0.4678 - val_loss: 933973.6250 - val_accuracy: 0.4813 - 32s/epoch - 855ms/step\n",
      "Epoch 2/60\n",
      "38/38 - 28s - loss: 933304.1250 - accuracy: 0.4796 - val_loss: 932578.8125 - val_accuracy: 0.4909 - 28s/epoch - 734ms/step\n",
      "Epoch 3/60\n",
      "38/38 - 28s - loss: 931910.3125 - accuracy: 0.6210 - val_loss: 931185.9375 - val_accuracy: 0.6756 - 28s/epoch - 745ms/step\n",
      "Epoch 4/60\n",
      "38/38 - 28s - loss: 930518.2500 - accuracy: 0.6696 - val_loss: 929795.1250 - val_accuracy: 0.6681 - 28s/epoch - 737ms/step\n",
      "Epoch 5/60\n",
      "38/38 - 28s - loss: 929127.9375 - accuracy: 0.6832 - val_loss: 928405.7500 - val_accuracy: 0.6596 - 28s/epoch - 743ms/step\n",
      "Epoch 6/60\n",
      "38/38 - 28s - loss: 927739.5000 - accuracy: 0.6931 - val_loss: 927018.2500 - val_accuracy: 0.6798 - 28s/epoch - 735ms/step\n",
      "Epoch 7/60\n",
      "38/38 - 29s - loss: 926353.1875 - accuracy: 0.7014 - val_loss: 925632.8750 - val_accuracy: 0.6830 - 29s/epoch - 755ms/step\n",
      "Epoch 8/60\n",
      "38/38 - 28s - loss: 924969.0625 - accuracy: 0.7080 - val_loss: 924250.1875 - val_accuracy: 0.6916 - 28s/epoch - 745ms/step\n",
      "Epoch 9/60\n",
      "38/38 - 29s - loss: 923587.1875 - accuracy: 0.7078 - val_loss: 922869.2500 - val_accuracy: 0.6969 - 29s/epoch - 756ms/step\n",
      "Epoch 10/60\n",
      "38/38 - 28s - loss: 922207.6875 - accuracy: 0.7262 - val_loss: 921491.1250 - val_accuracy: 0.7257 - 28s/epoch - 742ms/step\n",
      "Epoch 11/60\n",
      "38/38 - 29s - loss: 920830.0625 - accuracy: 0.7371 - val_loss: 920114.5000 - val_accuracy: 0.7108 - 29s/epoch - 753ms/step\n",
      "Epoch 12/60\n",
      "38/38 - 28s - loss: 919454.2500 - accuracy: 0.7550 - val_loss: 918739.1875 - val_accuracy: 0.7236 - 28s/epoch - 744ms/step\n",
      "Epoch 13/60\n",
      "38/38 - 28s - loss: 918079.8750 - accuracy: 0.7481 - val_loss: 917365.7500 - val_accuracy: 0.7428 - 28s/epoch - 741ms/step\n",
      "Epoch 14/60\n",
      "38/38 - 28s - loss: 916707.3125 - accuracy: 0.7489 - val_loss: 915994.3125 - val_accuracy: 0.7236 - 28s/epoch - 737ms/step\n",
      "Epoch 15/60\n",
      "38/38 - 30s - loss: 915336.5625 - accuracy: 0.7635 - val_loss: 914624.3125 - val_accuracy: 0.7353 - 30s/epoch - 784ms/step\n",
      "Epoch 16/60\n",
      "38/38 - 35s - loss: 913967.5625 - accuracy: 0.7630 - val_loss: 913256.3125 - val_accuracy: 0.7471 - 35s/epoch - 914ms/step\n",
      "Epoch 17/60\n",
      "38/38 - 32s - loss: 912600.1250 - accuracy: 0.7806 - val_loss: 911889.8750 - val_accuracy: 0.7545 - 32s/epoch - 833ms/step\n",
      "Epoch 18/60\n",
      "38/38 - 30s - loss: 911234.6875 - accuracy: 0.7748 - val_loss: 910525.6250 - val_accuracy: 0.7556 - 30s/epoch - 780ms/step\n",
      "Epoch 19/60\n",
      "38/38 - 35s - loss: 909871.7500 - accuracy: 0.7798 - val_loss: 909164.0625 - val_accuracy: 0.7375 - 35s/epoch - 917ms/step\n",
      "Epoch 20/60\n",
      "38/38 - 32s - loss: 908511.4375 - accuracy: 0.7812 - val_loss: 907804.9375 - val_accuracy: 0.7524 - 32s/epoch - 850ms/step\n",
      "Epoch 21/60\n",
      "38/38 - 33s - loss: 907153.7500 - accuracy: 0.7854 - val_loss: 906448.6875 - val_accuracy: 0.7481 - 33s/epoch - 879ms/step\n",
      "Epoch 22/60\n",
      "38/38 - 32s - loss: 905798.3125 - accuracy: 0.7948 - val_loss: 905094.3125 - val_accuracy: 0.7535 - 32s/epoch - 854ms/step\n",
      "Epoch 23/60\n",
      "38/38 - 35s - loss: 904444.9375 - accuracy: 0.7998 - val_loss: 903741.6250 - val_accuracy: 0.7588 - 35s/epoch - 927ms/step\n",
      "Epoch 24/60\n",
      "38/38 - 31s - loss: 903093.1875 - accuracy: 0.7953 - val_loss: 902391.0625 - val_accuracy: 0.7620 - 31s/epoch - 804ms/step\n",
      "Epoch 25/60\n",
      "38/38 - 32s - loss: 901743.3125 - accuracy: 0.7910 - val_loss: 901042.0000 - val_accuracy: 0.7588 - 32s/epoch - 841ms/step\n",
      "Epoch 26/60\n",
      "38/38 - 29s - loss: 900395.2500 - accuracy: 0.8038 - val_loss: 899694.8750 - val_accuracy: 0.7588 - 29s/epoch - 772ms/step\n",
      "Epoch 27/60\n",
      "38/38 - 29s - loss: 899049.1250 - accuracy: 0.7985 - val_loss: 898349.5625 - val_accuracy: 0.7556 - 29s/epoch - 774ms/step\n",
      "Epoch 28/60\n",
      "38/38 - 29s - loss: 897704.4375 - accuracy: 0.8081 - val_loss: 897006.0625 - val_accuracy: 0.7556 - 29s/epoch - 761ms/step\n",
      "Epoch 29/60\n",
      "38/38 - 29s - loss: 896361.5625 - accuracy: 0.8028 - val_loss: 895663.8750 - val_accuracy: 0.7663 - 29s/epoch - 770ms/step\n",
      "Epoch 30/60\n",
      "38/38 - 29s - loss: 895020.1250 - accuracy: 0.8044 - val_loss: 894323.2500 - val_accuracy: 0.7620 - 29s/epoch - 766ms/step\n",
      "Epoch 31/60\n",
      "38/38 - 29s - loss: 893680.3125 - accuracy: 0.8025 - val_loss: 892984.3750 - val_accuracy: 0.7716 - 29s/epoch - 762ms/step\n",
      "Epoch 32/60\n",
      "38/38 - 29s - loss: 892342.1250 - accuracy: 0.8100 - val_loss: 891647.0000 - val_accuracy: 0.7609 - 29s/epoch - 760ms/step\n",
      "Epoch 33/60\n",
      "38/38 - 29s - loss: 891005.6875 - accuracy: 0.8092 - val_loss: 890311.5000 - val_accuracy: 0.7716 - 29s/epoch - 768ms/step\n",
      "Epoch 34/60\n",
      "38/38 - 29s - loss: 889671.0000 - accuracy: 0.8076 - val_loss: 888977.5625 - val_accuracy: 0.7641 - 29s/epoch - 768ms/step\n",
      "Epoch 35/60\n",
      "38/38 - 29s - loss: 888337.6875 - accuracy: 0.8110 - val_loss: 887645.1250 - val_accuracy: 0.7769 - 29s/epoch - 765ms/step\n",
      "Epoch 36/60\n",
      "38/38 - 29s - loss: 887006.0625 - accuracy: 0.8289 - val_loss: 886314.2500 - val_accuracy: 0.7716 - 29s/epoch - 763ms/step\n",
      "Epoch 37/60\n",
      "38/38 - 30s - loss: 885676.1875 - accuracy: 0.8108 - val_loss: 884985.2500 - val_accuracy: 0.7620 - 30s/epoch - 778ms/step\n",
      "Epoch 38/60\n",
      "38/38 - 29s - loss: 884347.6875 - accuracy: 0.8233 - val_loss: 883657.6875 - val_accuracy: 0.7791 - 29s/epoch - 758ms/step\n",
      "Epoch 39/60\n",
      "38/38 - 29s - loss: 883021.0625 - accuracy: 0.8268 - val_loss: 882331.8125 - val_accuracy: 0.7705 - 29s/epoch - 763ms/step\n",
      "Epoch 40/60\n",
      "38/38 - 29s - loss: 881695.8750 - accuracy: 0.8268 - val_loss: 881007.5625 - val_accuracy: 0.7705 - 29s/epoch - 773ms/step\n",
      "Epoch 41/60\n",
      "38/38 - 29s - loss: 880372.3750 - accuracy: 0.8308 - val_loss: 879684.7500 - val_accuracy: 0.7759 - 29s/epoch - 766ms/step\n",
      "Epoch 42/60\n",
      "38/38 - 29s - loss: 879050.3125 - accuracy: 0.8359 - val_loss: 878363.6875 - val_accuracy: 0.7716 - 29s/epoch - 761ms/step\n",
      "Epoch 43/60\n",
      "38/38 - 29s - loss: 877729.9375 - accuracy: 0.8343 - val_loss: 877044.1250 - val_accuracy: 0.7609 - 29s/epoch - 761ms/step\n",
      "Epoch 44/60\n",
      "38/38 - 29s - loss: 876411.3125 - accuracy: 0.8351 - val_loss: 875726.3125 - val_accuracy: 0.7748 - 29s/epoch - 762ms/step\n",
      "Epoch 45/60\n",
      "38/38 - 29s - loss: 875094.0625 - accuracy: 0.8319 - val_loss: 874409.8750 - val_accuracy: 0.7834 - 29s/epoch - 768ms/step\n",
      "Epoch 46/60\n",
      "38/38 - 32s - loss: 873778.5625 - accuracy: 0.8457 - val_loss: 873095.3125 - val_accuracy: 0.7780 - 32s/epoch - 831ms/step\n",
      "Epoch 47/60\n",
      "38/38 - 29s - loss: 872464.6250 - accuracy: 0.8396 - val_loss: 871782.1875 - val_accuracy: 0.7513 - 29s/epoch - 764ms/step\n",
      "Epoch 48/60\n",
      "38/38 - 28s - loss: 871152.3750 - accuracy: 0.8337 - val_loss: 870470.7500 - val_accuracy: 0.7663 - 28s/epoch - 730ms/step\n",
      "Epoch 49/60\n",
      "38/38 - 27s - loss: 869841.5625 - accuracy: 0.8417 - val_loss: 869160.9375 - val_accuracy: 0.7599 - 27s/epoch - 723ms/step\n",
      "Epoch 50/60\n",
      "38/38 - 28s - loss: 868532.6875 - accuracy: 0.8388 - val_loss: 867852.4375 - val_accuracy: 0.7780 - 28s/epoch - 728ms/step\n",
      "Epoch 51/60\n",
      "38/38 - 28s - loss: 867225.0625 - accuracy: 0.8420 - val_loss: 866545.9375 - val_accuracy: 0.7663 - 28s/epoch - 735ms/step\n",
      "Epoch 52/60\n",
      "38/38 - 28s - loss: 865919.0000 - accuracy: 0.8396 - val_loss: 865240.5000 - val_accuracy: 0.7695 - 28s/epoch - 731ms/step\n",
      "Epoch 53/60\n",
      "38/38 - 28s - loss: 864614.5000 - accuracy: 0.8393 - val_loss: 863936.8750 - val_accuracy: 0.7705 - 28s/epoch - 737ms/step\n",
      "Epoch 54/60\n",
      "38/38 - 30s - loss: 863311.4375 - accuracy: 0.8471 - val_loss: 862634.6875 - val_accuracy: 0.7780 - 30s/epoch - 781ms/step\n",
      "Epoch 55/60\n",
      "38/38 - 28s - loss: 862009.9375 - accuracy: 0.8543 - val_loss: 861333.8750 - val_accuracy: 0.7791 - 28s/epoch - 736ms/step\n",
      "Epoch 56/60\n",
      "38/38 - 28s - loss: 860709.8125 - accuracy: 0.8508 - val_loss: 860034.6250 - val_accuracy: 0.7599 - 28s/epoch - 731ms/step\n",
      "Epoch 57/60\n",
      "38/38 - 28s - loss: 859411.2500 - accuracy: 0.8449 - val_loss: 858736.5625 - val_accuracy: 0.7673 - 28s/epoch - 730ms/step\n",
      "Epoch 58/60\n",
      "38/38 - 28s - loss: 858113.9375 - accuracy: 0.8564 - val_loss: 857440.3125 - val_accuracy: 0.7780 - 28s/epoch - 739ms/step\n",
      "Epoch 59/60\n",
      "38/38 - 28s - loss: 856818.2500 - accuracy: 0.8588 - val_loss: 856145.2500 - val_accuracy: 0.7631 - 28s/epoch - 732ms/step\n",
      "Epoch 60/60\n",
      "38/38 - 28s - loss: 855524.1250 - accuracy: 0.8489 - val_loss: 854851.8125 - val_accuracy: 0.7641 - 28s/epoch - 730ms/step\n",
      "Model: \"model_17\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      " input_22 (InputLayer)       [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_95 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_75 (MaxPoolin  (None, 49, 49, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_96 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_76 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_97 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_77 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_98 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " max_pooling2d_78 (MaxPoolin  (None, 4, 4, 40)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_99 (Conv2D)          (None, 2, 2, 40)          14440     \n",
      "                                                                 \n",
      " flatten_21 (Flatten)        (None, 160)               0         \n",
      "                                                                 \n",
      " dense_79 (Dense)            (None, 30)                4830      \n",
      "                                                                 \n",
      " dropout_42 (Dropout)        (None, 30)                0         \n",
      "                                                                 \n",
      " dense_80 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dropout_43 (Dropout)        (None, 30)                0         \n",
      "                                                                 \n",
      " dense_81 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dropout_44 (Dropout)        (None, 30)                0         \n",
      "                                                                 \n",
      " dense_82 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,943\n",
      "Trainable params: 64,943\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 854851.9375\n",
      "Test accuracy: 0.7952218651771545\n"
     ]
    }
   ],
   "source": [
    "train(60,100,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d8679dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "next time\n",
    "penalty 0.01\n",
    "penalty last 0.001\n",
    "reverse\n",
    "\"\"\"\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "    dataset, labels, test_size=0.2, random_state=42)\n",
    "    X_train=X_train.reshape(-1,100,100,1)\n",
    "    X_test=X_test.reshape(-1,100,100,1)\n",
    "    Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "    Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "    \n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        w=1/76.4\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation=\"relu\",kernel_regularizer=regularizers.L2(0.01),kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w,maxval=1/w, seed=None))(hidden)\n",
    "            hidden=layers.Dropout(0.2)(hidden)\n",
    "            w=w*30*0.8\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation=\"softmax\",kernel_regularizer=regularizers.L2(0.001),kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w, maxval=1/w, seed=None))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=[\"accuracy\"])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.2,epochs=epochs_num,batch_size=batch_len,verbose=2,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e8394f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "38/38 - 37s - loss: 95085.4766 - accuracy: 0.4598 - val_loss: 95011.6797 - val_accuracy: 0.4813 - 37s/epoch - 971ms/step\n",
      "Epoch 2/60\n",
      "38/38 - 29s - loss: 94943.5938 - accuracy: 0.5119 - val_loss: 94869.8047 - val_accuracy: 0.6073 - 29s/epoch - 763ms/step\n",
      "Epoch 3/60\n",
      "38/38 - 27s - loss: 94801.8594 - accuracy: 0.6418 - val_loss: 94728.2188 - val_accuracy: 0.6628 - 27s/epoch - 714ms/step\n",
      "Epoch 4/60\n",
      "38/38 - 27s - loss: 94660.4062 - accuracy: 0.6832 - val_loss: 94586.9297 - val_accuracy: 0.6756 - 27s/epoch - 718ms/step\n",
      "Epoch 5/60\n",
      "38/38 - 28s - loss: 94519.2188 - accuracy: 0.6923 - val_loss: 94445.8438 - val_accuracy: 0.6788 - 28s/epoch - 732ms/step\n",
      "Epoch 6/60\n",
      "38/38 - 27s - loss: 94378.2500 - accuracy: 0.7048 - val_loss: 94305.0078 - val_accuracy: 0.6905 - 27s/epoch - 713ms/step\n",
      "Epoch 7/60\n",
      "38/38 - 28s - loss: 94237.4688 - accuracy: 0.7182 - val_loss: 94164.4844 - val_accuracy: 0.6852 - 28s/epoch - 724ms/step\n",
      "Epoch 8/60\n",
      "38/38 - 27s - loss: 94097.0000 - accuracy: 0.7291 - val_loss: 94024.0625 - val_accuracy: 0.6980 - 27s/epoch - 715ms/step\n",
      "Epoch 9/60\n",
      "38/38 - 27s - loss: 93956.7656 - accuracy: 0.7337 - val_loss: 93883.9609 - val_accuracy: 0.7513 - 27s/epoch - 715ms/step\n",
      "Epoch 10/60\n",
      "38/38 - 28s - loss: 93816.7891 - accuracy: 0.7563 - val_loss: 93744.1328 - val_accuracy: 0.7503 - 28s/epoch - 748ms/step\n",
      "Epoch 11/60\n",
      "38/38 - 27s - loss: 93677.0703 - accuracy: 0.7627 - val_loss: 93604.5625 - val_accuracy: 0.7343 - 27s/epoch - 710ms/step\n",
      "Epoch 12/60\n",
      "38/38 - 27s - loss: 93537.5000 - accuracy: 0.7689 - val_loss: 93465.0938 - val_accuracy: 0.7215 - 27s/epoch - 715ms/step\n",
      "Epoch 13/60\n",
      "38/38 - 27s - loss: 93398.1328 - accuracy: 0.7697 - val_loss: 93325.8125 - val_accuracy: 0.7556 - 27s/epoch - 716ms/step\n",
      "Epoch 14/60\n",
      "38/38 - 27s - loss: 93258.9297 - accuracy: 0.7809 - val_loss: 93186.7344 - val_accuracy: 0.7620 - 27s/epoch - 715ms/step\n",
      "Epoch 15/60\n",
      "38/38 - 27s - loss: 93119.9844 - accuracy: 0.7940 - val_loss: 93047.8359 - val_accuracy: 0.7545 - 27s/epoch - 721ms/step\n",
      "Epoch 16/60\n",
      "38/38 - 27s - loss: 92981.1953 - accuracy: 0.7990 - val_loss: 92909.1875 - val_accuracy: 0.7631 - 27s/epoch - 718ms/step\n",
      "Epoch 17/60\n",
      "38/38 - 27s - loss: 92842.6094 - accuracy: 0.7990 - val_loss: 92770.6953 - val_accuracy: 0.7834 - 27s/epoch - 719ms/step\n",
      "Epoch 18/60\n",
      "38/38 - 27s - loss: 92704.2422 - accuracy: 0.7977 - val_loss: 92632.4375 - val_accuracy: 0.7716 - 27s/epoch - 714ms/step\n",
      "Epoch 19/60\n",
      "38/38 - 27s - loss: 92566.1094 - accuracy: 0.8006 - val_loss: 92494.5156 - val_accuracy: 0.7631 - 27s/epoch - 721ms/step\n",
      "Epoch 20/60\n",
      "38/38 - 27s - loss: 92428.2578 - accuracy: 0.8089 - val_loss: 92356.8047 - val_accuracy: 0.7769 - 27s/epoch - 712ms/step\n",
      "Epoch 21/60\n",
      "38/38 - 27s - loss: 92290.6875 - accuracy: 0.8078 - val_loss: 92219.4219 - val_accuracy: 0.7545 - 27s/epoch - 706ms/step\n",
      "Epoch 22/60\n",
      "38/38 - 27s - loss: 92153.3984 - accuracy: 0.8217 - val_loss: 92082.2266 - val_accuracy: 0.7652 - 27s/epoch - 722ms/step\n",
      "Epoch 23/60\n",
      "38/38 - 27s - loss: 92016.2969 - accuracy: 0.8108 - val_loss: 91945.2578 - val_accuracy: 0.7609 - 27s/epoch - 717ms/step\n",
      "Epoch 24/60\n",
      "38/38 - 27s - loss: 91879.3906 - accuracy: 0.8207 - val_loss: 91808.3906 - val_accuracy: 0.7769 - 27s/epoch - 712ms/step\n",
      "Epoch 25/60\n",
      "38/38 - 27s - loss: 91742.6875 - accuracy: 0.8228 - val_loss: 91671.8438 - val_accuracy: 0.7716 - 27s/epoch - 717ms/step\n",
      "Epoch 26/60\n",
      "38/38 - 27s - loss: 91606.1797 - accuracy: 0.8268 - val_loss: 91535.5234 - val_accuracy: 0.7609 - 27s/epoch - 719ms/step\n",
      "Epoch 27/60\n",
      "38/38 - 27s - loss: 91469.8750 - accuracy: 0.8231 - val_loss: 91399.2344 - val_accuracy: 0.7737 - 27s/epoch - 721ms/step\n",
      "Epoch 28/60\n",
      "38/38 - 27s - loss: 91333.7266 - accuracy: 0.8303 - val_loss: 91263.2422 - val_accuracy: 0.7716 - 27s/epoch - 720ms/step\n",
      "Epoch 29/60\n",
      "38/38 - 27s - loss: 91197.7656 - accuracy: 0.8439 - val_loss: 91127.4062 - val_accuracy: 0.7620 - 27s/epoch - 719ms/step\n",
      "Epoch 30/60\n",
      "38/38 - 27s - loss: 91062.0000 - accuracy: 0.8415 - val_loss: 90991.7656 - val_accuracy: 0.7545 - 27s/epoch - 714ms/step\n",
      "Epoch 31/60\n",
      "38/38 - 28s - loss: 90926.4062 - accuracy: 0.8337 - val_loss: 90856.1172 - val_accuracy: 0.7737 - 28s/epoch - 742ms/step\n",
      "Epoch 32/60\n",
      "38/38 - 28s - loss: 90790.9375 - accuracy: 0.8425 - val_loss: 90720.8281 - val_accuracy: 0.7631 - 28s/epoch - 742ms/step\n",
      "Epoch 33/60\n",
      "38/38 - 28s - loss: 90655.6719 - accuracy: 0.8463 - val_loss: 90585.6328 - val_accuracy: 0.7705 - 28s/epoch - 733ms/step\n",
      "Epoch 34/60\n",
      "38/38 - 28s - loss: 90520.5859 - accuracy: 0.8452 - val_loss: 90450.6953 - val_accuracy: 0.7695 - 28s/epoch - 736ms/step\n",
      "Epoch 35/60\n",
      "38/38 - 28s - loss: 90385.6875 - accuracy: 0.8532 - val_loss: 90315.9219 - val_accuracy: 0.7673 - 28s/epoch - 748ms/step\n",
      "Epoch 36/60\n",
      "38/38 - 29s - loss: 90250.9453 - accuracy: 0.8591 - val_loss: 90181.2422 - val_accuracy: 0.7652 - 29s/epoch - 764ms/step\n",
      "Epoch 37/60\n",
      "38/38 - 27s - loss: 90116.3828 - accuracy: 0.8575 - val_loss: 90046.7422 - val_accuracy: 0.7641 - 27s/epoch - 720ms/step\n",
      "Epoch 38/60\n",
      "38/38 - 27s - loss: 89981.9922 - accuracy: 0.8655 - val_loss: 89912.5000 - val_accuracy: 0.7652 - 27s/epoch - 716ms/step\n",
      "Epoch 39/60\n",
      "38/38 - 27s - loss: 89847.7656 - accuracy: 0.8668 - val_loss: 89778.3906 - val_accuracy: 0.7609 - 27s/epoch - 713ms/step\n",
      "Epoch 40/60\n",
      "38/38 - 27s - loss: 89713.7188 - accuracy: 0.8676 - val_loss: 89644.4297 - val_accuracy: 0.7599 - 27s/epoch - 720ms/step\n",
      "Epoch 41/60\n",
      "38/38 - 29s - loss: 89579.8516 - accuracy: 0.8610 - val_loss: 89510.6328 - val_accuracy: 0.7577 - 29s/epoch - 772ms/step\n",
      "Epoch 42/60\n",
      "38/38 - 29s - loss: 89446.1250 - accuracy: 0.8663 - val_loss: 89377.0000 - val_accuracy: 0.7577 - 29s/epoch - 774ms/step\n",
      "Epoch 43/60\n",
      "38/38 - 27s - loss: 89312.5703 - accuracy: 0.8698 - val_loss: 89243.5469 - val_accuracy: 0.7620 - 27s/epoch - 709ms/step\n",
      "Epoch 44/60\n",
      "38/38 - 27s - loss: 89179.1562 - accuracy: 0.8796 - val_loss: 89110.3281 - val_accuracy: 0.7567 - 27s/epoch - 717ms/step\n",
      "Epoch 45/60\n",
      "38/38 - 27s - loss: 89046.0000 - accuracy: 0.8807 - val_loss: 88977.2656 - val_accuracy: 0.7652 - 27s/epoch - 723ms/step\n",
      "Epoch 46/60\n",
      "38/38 - 27s - loss: 88912.9609 - accuracy: 0.8826 - val_loss: 88844.2812 - val_accuracy: 0.7684 - 27s/epoch - 714ms/step\n",
      "Epoch 47/60\n",
      "38/38 - 28s - loss: 88780.0938 - accuracy: 0.8911 - val_loss: 88711.5312 - val_accuracy: 0.7620 - 28s/epoch - 730ms/step\n",
      "Epoch 48/60\n",
      "38/38 - 28s - loss: 88647.3672 - accuracy: 0.8946 - val_loss: 88578.8828 - val_accuracy: 0.7481 - 28s/epoch - 737ms/step\n",
      "Epoch 49/60\n",
      "38/38 - 28s - loss: 88514.8672 - accuracy: 0.8855 - val_loss: 88446.4688 - val_accuracy: 0.7620 - 28s/epoch - 733ms/step\n",
      "Epoch 50/60\n",
      "38/38 - 29s - loss: 88382.4922 - accuracy: 0.8981 - val_loss: 88314.3203 - val_accuracy: 0.7417 - 29s/epoch - 756ms/step\n",
      "Epoch 51/60\n",
      "38/38 - 29s - loss: 88250.2969 - accuracy: 0.9039 - val_loss: 88182.0938 - val_accuracy: 0.7652 - 29s/epoch - 758ms/step\n",
      "Epoch 52/60\n",
      "38/38 - 27s - loss: 88118.2422 - accuracy: 0.9066 - val_loss: 88050.2812 - val_accuracy: 0.7503 - 27s/epoch - 723ms/step\n",
      "Epoch 53/60\n",
      "38/38 - 28s - loss: 87986.3359 - accuracy: 0.9119 - val_loss: 87918.3359 - val_accuracy: 0.7609 - 28s/epoch - 738ms/step\n",
      "Epoch 54/60\n",
      "38/38 - 29s - loss: 87854.6406 - accuracy: 0.9063 - val_loss: 87786.8750 - val_accuracy: 0.7492 - 29s/epoch - 753ms/step\n",
      "Epoch 55/60\n",
      "38/38 - 27s - loss: 87723.0625 - accuracy: 0.9047 - val_loss: 87655.2734 - val_accuracy: 0.7449 - 27s/epoch - 722ms/step\n",
      "Epoch 56/60\n",
      "38/38 - 28s - loss: 87591.6094 - accuracy: 0.9199 - val_loss: 87524.0625 - val_accuracy: 0.7407 - 28s/epoch - 729ms/step\n",
      "Epoch 57/60\n",
      "38/38 - 28s - loss: 87460.3828 - accuracy: 0.9005 - val_loss: 87392.7422 - val_accuracy: 0.7439 - 28s/epoch - 738ms/step\n",
      "Epoch 58/60\n",
      "38/38 - 28s - loss: 87329.1953 - accuracy: 0.9213 - val_loss: 87261.7969 - val_accuracy: 0.7471 - 28s/epoch - 724ms/step\n",
      "Epoch 59/60\n",
      "38/38 - 29s - loss: 87198.2344 - accuracy: 0.9175 - val_loss: 87130.8750 - val_accuracy: 0.7364 - 29s/epoch - 756ms/step\n",
      "Epoch 60/60\n",
      "38/38 - 28s - loss: 87067.4141 - accuracy: 0.9210 - val_loss: 87000.1016 - val_accuracy: 0.7609 - 28s/epoch - 736ms/step\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 100, 100, 1)]     0         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 49, 49, 40)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 23, 23, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 10, 10, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 4, 4, 40)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 2, 2, 40)          14440     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 160)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 30)                4830      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 30)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 30)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 30)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 64,943\n",
      "Trainable params: 64,943\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 87000.1015625\n",
      "Test accuracy: 0.7738907933235168\n"
     ]
    }
   ],
   "source": [
    "train(60,100,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a23020d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "next time\n",
    "penalty 0.01\n",
    "penalty last 0.001\n",
    "reverse\n",
    "\"\"\"\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers):\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "    dataset, labels, test_size=0.2, random_state=42)\n",
    "    X_train=X_train.reshape(-1,100,100,1)\n",
    "    X_test=X_test.reshape(-1,100,100,1)\n",
    "    Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "    Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "    \n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        w=1/76.4\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation=\"relu\",kernel_regularizer=regularizers.L2(0.01),kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w,maxval=1/w, seed=None))(hidden)\n",
    "            hidden=layers.Dropout(0.2)(hidden)\n",
    "            w=w*30*0.8\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation=\"softmax\",kernel_regularizer=regularizers.L2(0.01),kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w, maxval=1/w, seed=None))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=[\"accuracy\"])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4,mode='max')\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.2,epochs=epochs_num,batch_size=batch_len,verbose=2,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "390cf656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "75/75 - 35s - loss: 1493501.2500 - accuracy: 0.5033 - val_loss: 1491270.7500 - val_accuracy: 0.6403 - 35s/epoch - 470ms/step\n",
      "Epoch 2/60\n",
      "75/75 - 28s - loss: 1489105.8750 - accuracy: 0.6245 - val_loss: 1486881.2500 - val_accuracy: 0.6553 - 28s/epoch - 373ms/step\n",
      "Epoch 3/60\n",
      "75/75 - 28s - loss: 1484721.3750 - accuracy: 0.6469 - val_loss: 1482502.1250 - val_accuracy: 0.6724 - 28s/epoch - 379ms/step\n",
      "Epoch 4/60\n",
      "75/75 - 29s - loss: 1480349.1250 - accuracy: 0.6824 - val_loss: 1478136.6250 - val_accuracy: 0.6713 - 29s/epoch - 392ms/step\n",
      "Epoch 5/60\n",
      "75/75 - 28s - loss: 1475990.7500 - accuracy: 0.6811 - val_loss: 1473785.5000 - val_accuracy: 0.6905 - 28s/epoch - 378ms/step\n",
      "Epoch 6/60\n",
      "75/75 - 29s - loss: 1471645.2500 - accuracy: 0.7022 - val_loss: 1469445.5000 - val_accuracy: 0.7343 - 29s/epoch - 384ms/step\n",
      "Epoch 7/60\n",
      "75/75 - 28s - loss: 1467310.3750 - accuracy: 0.7203 - val_loss: 1465116.1250 - val_accuracy: 0.7375 - 28s/epoch - 374ms/step\n",
      "Epoch 8/60\n",
      "75/75 - 28s - loss: 1462986.3750 - accuracy: 0.7222 - val_loss: 1460797.5000 - val_accuracy: 0.7428 - 28s/epoch - 377ms/step\n",
      "Epoch 9/60\n",
      "75/75 - 28s - loss: 1458673.3750 - accuracy: 0.7232 - val_loss: 1456490.1250 - val_accuracy: 0.7364 - 28s/epoch - 374ms/step\n",
      "Epoch 10/60\n",
      "75/75 - 29s - loss: 1454372.8750 - accuracy: 0.7310 - val_loss: 1452198.2500 - val_accuracy: 0.7193 - 29s/epoch - 393ms/step\n",
      "Epoch 11/60\n",
      "75/75 - 28s - loss: 1450088.6250 - accuracy: 0.7446 - val_loss: 1447921.2500 - val_accuracy: 0.7567 - 28s/epoch - 377ms/step\n",
      "Epoch 12/60\n",
      "75/75 - 29s - loss: 1445817.8750 - accuracy: 0.7561 - val_loss: 1443656.2500 - val_accuracy: 0.7588 - 29s/epoch - 380ms/step\n",
      "Epoch 13/60\n",
      "75/75 - 28s - loss: 1441558.8750 - accuracy: 0.7569 - val_loss: 1439403.2500 - val_accuracy: 0.7332 - 28s/epoch - 376ms/step\n",
      "Epoch 14/60\n",
      "75/75 - 28s - loss: 1437311.2500 - accuracy: 0.7569 - val_loss: 1435160.7500 - val_accuracy: 0.7524 - 28s/epoch - 374ms/step\n",
      "Epoch 15/60\n",
      "75/75 - 28s - loss: 1433074.2500 - accuracy: 0.7638 - val_loss: 1430928.3750 - val_accuracy: 0.7609 - 28s/epoch - 376ms/step\n",
      "Epoch 16/60\n",
      "75/75 - 28s - loss: 1428845.8750 - accuracy: 0.7748 - val_loss: 1426705.8750 - val_accuracy: 0.7535 - 28s/epoch - 379ms/step\n",
      "Epoch 17/60\n",
      "75/75 - 28s - loss: 1424628.8750 - accuracy: 0.7796 - val_loss: 1422494.5000 - val_accuracy: 0.7545 - 28s/epoch - 374ms/step\n",
      "Epoch 18/60\n",
      "75/75 - 28s - loss: 1420421.8750 - accuracy: 0.7758 - val_loss: 1418291.7500 - val_accuracy: 0.7524 - 28s/epoch - 372ms/step\n",
      "Epoch 19/60\n",
      "75/75 - 28s - loss: 1416224.8750 - accuracy: 0.7812 - val_loss: 1414100.0000 - val_accuracy: 0.7609 - 28s/epoch - 374ms/step\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 49, 49, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 23, 23, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 10, 10, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 30)                76830     \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 30)                0         \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 30)                930       \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 30)                0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 30)                0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 1414100.0\n",
      "Test accuracy: 0.7909556031227112\n"
     ]
    }
   ],
   "source": [
    "train(60,50,3,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d903a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning_rate=0.00001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c7ace2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "next time\n",
    "penalty 0.01\n",
    "penalty last 0.001\n",
    "reverse\n",
    "\"\"\"\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers,learn=0.001):\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "    dataset, labels, test_size=0.2, random_state=42)\n",
    "    X_train=X_train.reshape(-1,100,100,1)\n",
    "    X_test=X_test.reshape(-1,100,100,1)\n",
    "    Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "    Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "    \n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(100,100,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        w=1/76.4\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation=\"relu\",kernel_regularizer=regularizers.L2(0.01),kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w,maxval=1/w, seed=None))(hidden)\n",
    "            hidden=layers.Dropout(0.2)(hidden)\n",
    "            w=w*30*0.8\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation=\"softmax\",kernel_regularizer=regularizers.L2(0.01),kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w, maxval=1/w, seed=None))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=learn),metrics=[\"accuracy\"])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4,mode='max')\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.2,epochs=epochs_num,batch_size=batch_len,verbose=2,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b25ddebf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "75/75 - 32s - loss: 1496704.0000 - accuracy: 0.4099 - val_loss: 1496681.1250 - val_accuracy: 0.4781 - 32s/epoch - 429ms/step\n",
      "Epoch 2/60\n",
      "75/75 - 30s - loss: 1496659.8750 - accuracy: 0.4163 - val_loss: 1496637.5000 - val_accuracy: 0.4920 - 30s/epoch - 398ms/step\n",
      "Epoch 3/60\n",
      "75/75 - 29s - loss: 1496615.8750 - accuracy: 0.4526 - val_loss: 1496593.6250 - val_accuracy: 0.5390 - 29s/epoch - 382ms/step\n",
      "Epoch 4/60\n",
      "75/75 - 28s - loss: 1496572.0000 - accuracy: 0.4969 - val_loss: 1496549.5000 - val_accuracy: 0.5667 - 28s/epoch - 379ms/step\n",
      "Epoch 5/60\n",
      "75/75 - 29s - loss: 1496528.0000 - accuracy: 0.5330 - val_loss: 1496505.3750 - val_accuracy: 0.5955 - 29s/epoch - 380ms/step\n",
      "Epoch 6/60\n",
      "75/75 - 28s - loss: 1496484.0000 - accuracy: 0.5535 - val_loss: 1496461.7500 - val_accuracy: 0.6105 - 28s/epoch - 375ms/step\n",
      "Epoch 7/60\n",
      "75/75 - 28s - loss: 1496440.0000 - accuracy: 0.5695 - val_loss: 1496417.5000 - val_accuracy: 0.6318 - 28s/epoch - 380ms/step\n",
      "Epoch 8/60\n",
      "75/75 - 28s - loss: 1496396.3750 - accuracy: 0.5839 - val_loss: 1496374.0000 - val_accuracy: 0.6339 - 28s/epoch - 378ms/step\n",
      "Epoch 9/60\n",
      "75/75 - 28s - loss: 1496352.1250 - accuracy: 0.5951 - val_loss: 1496330.1250 - val_accuracy: 0.6382 - 28s/epoch - 380ms/step\n",
      "Epoch 10/60\n",
      "75/75 - 28s - loss: 1496308.1250 - accuracy: 0.6184 - val_loss: 1496286.3750 - val_accuracy: 0.6553 - 28s/epoch - 376ms/step\n",
      "Epoch 11/60\n",
      "75/75 - 29s - loss: 1496264.3750 - accuracy: 0.6234 - val_loss: 1496242.0000 - val_accuracy: 0.6521 - 29s/epoch - 381ms/step\n",
      "Epoch 12/60\n",
      "75/75 - 29s - loss: 1496220.5000 - accuracy: 0.6234 - val_loss: 1496198.1250 - val_accuracy: 0.6596 - 29s/epoch - 381ms/step\n",
      "Epoch 13/60\n",
      "75/75 - 28s - loss: 1496176.3750 - accuracy: 0.6432 - val_loss: 1496153.8750 - val_accuracy: 0.6564 - 28s/epoch - 379ms/step\n",
      "Epoch 14/60\n",
      "75/75 - 28s - loss: 1496132.5000 - accuracy: 0.6429 - val_loss: 1496110.1250 - val_accuracy: 0.6596 - 28s/epoch - 376ms/step\n",
      "Epoch 15/60\n",
      "75/75 - 28s - loss: 1496088.8750 - accuracy: 0.6467 - val_loss: 1496066.5000 - val_accuracy: 0.6617 - 28s/epoch - 377ms/step\n",
      "Epoch 16/60\n",
      "75/75 - 29s - loss: 1496044.7500 - accuracy: 0.6523 - val_loss: 1496022.2500 - val_accuracy: 0.6660 - 29s/epoch - 380ms/step\n",
      "Epoch 17/60\n",
      "75/75 - 28s - loss: 1496000.6250 - accuracy: 0.6549 - val_loss: 1495978.5000 - val_accuracy: 0.6670 - 28s/epoch - 378ms/step\n",
      "Epoch 18/60\n",
      "75/75 - 28s - loss: 1495957.0000 - accuracy: 0.6627 - val_loss: 1495934.5000 - val_accuracy: 0.6724 - 28s/epoch - 379ms/step\n",
      "Epoch 19/60\n",
      "75/75 - 29s - loss: 1495913.0000 - accuracy: 0.6552 - val_loss: 1495890.7500 - val_accuracy: 0.6724 - 29s/epoch - 388ms/step\n",
      "Epoch 20/60\n",
      "75/75 - 28s - loss: 1495869.1250 - accuracy: 0.6659 - val_loss: 1495846.5000 - val_accuracy: 0.6745 - 28s/epoch - 379ms/step\n",
      "Epoch 21/60\n",
      "75/75 - 29s - loss: 1495825.1250 - accuracy: 0.6619 - val_loss: 1495802.7500 - val_accuracy: 0.6756 - 29s/epoch - 381ms/step\n",
      "Epoch 22/60\n",
      "75/75 - 29s - loss: 1495781.3750 - accuracy: 0.6712 - val_loss: 1495759.2500 - val_accuracy: 0.6702 - 29s/epoch - 382ms/step\n",
      "Epoch 23/60\n",
      "75/75 - 29s - loss: 1495737.2500 - accuracy: 0.6717 - val_loss: 1495715.1250 - val_accuracy: 0.6841 - 29s/epoch - 385ms/step\n",
      "Epoch 24/60\n",
      "75/75 - 29s - loss: 1495693.2500 - accuracy: 0.6779 - val_loss: 1495671.2500 - val_accuracy: 0.6884 - 29s/epoch - 387ms/step\n",
      "Epoch 25/60\n",
      "75/75 - 28s - loss: 1495649.6250 - accuracy: 0.6821 - val_loss: 1495627.3750 - val_accuracy: 0.6777 - 28s/epoch - 377ms/step\n",
      "Epoch 26/60\n",
      "75/75 - 29s - loss: 1495605.7500 - accuracy: 0.6816 - val_loss: 1495583.0000 - val_accuracy: 0.6820 - 29s/epoch - 382ms/step\n",
      "Epoch 27/60\n",
      "75/75 - 29s - loss: 1495561.6250 - accuracy: 0.6859 - val_loss: 1495539.2500 - val_accuracy: 0.6894 - 29s/epoch - 382ms/step\n",
      "Epoch 28/60\n",
      "75/75 - 29s - loss: 1495517.7500 - accuracy: 0.6813 - val_loss: 1495495.7500 - val_accuracy: 0.6948 - 29s/epoch - 381ms/step\n",
      "Epoch 29/60\n",
      "75/75 - 28s - loss: 1495474.0000 - accuracy: 0.6904 - val_loss: 1495452.0000 - val_accuracy: 0.6948 - 28s/epoch - 378ms/step\n",
      "Epoch 30/60\n",
      "75/75 - 29s - loss: 1495430.2500 - accuracy: 0.6931 - val_loss: 1495407.8750 - val_accuracy: 0.6969 - 29s/epoch - 380ms/step\n",
      "Epoch 31/60\n",
      "75/75 - 29s - loss: 1495386.1250 - accuracy: 0.6869 - val_loss: 1495364.0000 - val_accuracy: 0.6926 - 29s/epoch - 381ms/step\n",
      "Epoch 32/60\n",
      "75/75 - 29s - loss: 1495342.3750 - accuracy: 0.6867 - val_loss: 1495320.0000 - val_accuracy: 0.6980 - 29s/epoch - 382ms/step\n",
      "Epoch 33/60\n",
      "75/75 - 28s - loss: 1495298.2500 - accuracy: 0.6939 - val_loss: 1495275.7500 - val_accuracy: 0.6958 - 28s/epoch - 375ms/step\n",
      "Epoch 34/60\n",
      "75/75 - 28s - loss: 1495254.3750 - accuracy: 0.6955 - val_loss: 1495232.2500 - val_accuracy: 0.6916 - 28s/epoch - 377ms/step\n",
      "Epoch 35/60\n",
      "75/75 - 28s - loss: 1495210.5000 - accuracy: 0.6926 - val_loss: 1495188.3750 - val_accuracy: 0.6937 - 28s/epoch - 379ms/step\n",
      "Epoch 36/60\n",
      "75/75 - 28s - loss: 1495166.7500 - accuracy: 0.7064 - val_loss: 1495144.6250 - val_accuracy: 0.6969 - 28s/epoch - 380ms/step\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 100, 100, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 98, 98, 40)        400       \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 49, 49, 40)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 47, 47, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 30)                76830     \n",
      "                                                                 \n",
      " dropout_9 (Dropout)         (None, 30)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 30)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 30)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 122,503\n",
      "Trainable params: 122,503\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 1495144.125\n",
      "Test accuracy: 0.6988054513931274\n"
     ]
    }
   ],
   "source": [
    "train(60,50,3,3,0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e03d40ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset,labels=create_dataset('chest_xray_lower_dim200x200')\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras import utils\n",
    "import sklearn.metrics as metrics\n",
    "import numpy as np\n",
    "from tensorflow.keras import regularizers\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66eaf0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "next time\n",
    "penalty 0.01\n",
    "penalty last 0.001\n",
    "reverse\n",
    "\"\"\"\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers,learn=0.001):\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "    dataset, labels, test_size=0.2, random_state=42)\n",
    "    X_train=X_train.reshape(-1,200,200,1)\n",
    "    X_test=X_test.reshape(-1,200,200,1)\n",
    "    Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "    Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "    \n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(200,200,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        w=1/76.4\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(30,activation=\"relu\",kernel_regularizer=regularizers.L2(0.01),kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w,maxval=1/w, seed=None))(hidden)\n",
    "            hidden=layers.Dropout(0.2)(hidden)\n",
    "            w=w*30*0.8\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation=\"softmax\",kernel_regularizer=regularizers.L2(0.01),kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w, maxval=1/w, seed=None))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=learn),metrics=[\"accuracy\"])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4,mode='max')\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.2,epochs=epochs_num,batch_size=batch_len,verbose=2,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "718023a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "38/38 - 204s - loss: 1502188.7500 - accuracy: 0.4788 - val_loss: 1501025.1250 - val_accuracy: 0.6158 - 204s/epoch - 5s/step\n",
      "Epoch 2/60\n",
      "38/38 - 193s - loss: 1499951.7500 - accuracy: 0.5850 - val_loss: 1498789.0000 - val_accuracy: 0.6265 - 193s/epoch - 5s/step\n",
      "Epoch 3/60\n",
      "38/38 - 203s - loss: 1497716.5000 - accuracy: 0.6432 - val_loss: 1496555.6250 - val_accuracy: 0.6478 - 203s/epoch - 5s/step\n",
      "Epoch 4/60\n",
      "38/38 - 235s - loss: 1495484.8750 - accuracy: 0.6544 - val_loss: 1494325.1250 - val_accuracy: 0.6606 - 235s/epoch - 6s/step\n",
      "Epoch 5/60\n",
      "38/38 - 243s - loss: 1493255.7500 - accuracy: 0.6659 - val_loss: 1492097.2500 - val_accuracy: 0.6702 - 243s/epoch - 6s/step\n",
      "Epoch 6/60\n",
      "38/38 - 206s - loss: 1491029.3750 - accuracy: 0.6867 - val_loss: 1489872.7500 - val_accuracy: 0.6756 - 206s/epoch - 5s/step\n",
      "Epoch 7/60\n",
      "38/38 - 195s - loss: 1488806.5000 - accuracy: 0.6856 - val_loss: 1487651.6250 - val_accuracy: 0.6702 - 195s/epoch - 5s/step\n",
      "Epoch 8/60\n",
      "38/38 - 151s - loss: 1486587.0000 - accuracy: 0.6963 - val_loss: 1485433.7500 - val_accuracy: 0.6830 - 151s/epoch - 4s/step\n",
      "Epoch 9/60\n",
      "38/38 - 179s - loss: 1484371.2500 - accuracy: 0.6944 - val_loss: 1483220.2500 - val_accuracy: 0.6841 - 179s/epoch - 5s/step\n",
      "Epoch 10/60\n",
      "38/38 - 192s - loss: 1482159.1250 - accuracy: 0.7078 - val_loss: 1481009.8750 - val_accuracy: 0.6926 - 192s/epoch - 5s/step\n",
      "Epoch 11/60\n",
      "38/38 - 160s - loss: 1479950.1250 - accuracy: 0.7123 - val_loss: 1478802.5000 - val_accuracy: 0.6948 - 160s/epoch - 4s/step\n",
      "Epoch 12/60\n",
      "38/38 - 141s - loss: 1477743.7500 - accuracy: 0.7112 - val_loss: 1476597.2500 - val_accuracy: 0.6841 - 141s/epoch - 4s/step\n",
      "Epoch 13/60\n",
      "38/38 - 135s - loss: 1475539.8750 - accuracy: 0.7160 - val_loss: 1474394.8750 - val_accuracy: 0.6894 - 135s/epoch - 4s/step\n",
      "Epoch 14/60\n",
      "38/38 - 140s - loss: 1473339.0000 - accuracy: 0.7176 - val_loss: 1472195.3750 - val_accuracy: 0.6937 - 140s/epoch - 4s/step\n",
      "Epoch 15/60\n",
      "38/38 - 145s - loss: 1471140.6250 - accuracy: 0.7254 - val_loss: 1469998.5000 - val_accuracy: 0.7396 - 145s/epoch - 4s/step\n",
      "Epoch 16/60\n",
      "38/38 - 147s - loss: 1468945.1250 - accuracy: 0.7318 - val_loss: 1467804.5000 - val_accuracy: 0.7215 - 147s/epoch - 4s/step\n",
      "Epoch 17/60\n",
      "38/38 - 136s - loss: 1466752.6250 - accuracy: 0.7353 - val_loss: 1465613.6250 - val_accuracy: 0.7182 - 136s/epoch - 4s/step\n",
      "Epoch 18/60\n",
      "38/38 - 134s - loss: 1464563.1250 - accuracy: 0.7313 - val_loss: 1463425.7500 - val_accuracy: 0.7449 - 134s/epoch - 4s/step\n",
      "Epoch 19/60\n",
      "38/38 - 200s - loss: 1462377.2500 - accuracy: 0.7494 - val_loss: 1461242.0000 - val_accuracy: 0.7300 - 200s/epoch - 5s/step\n",
      "Epoch 20/60\n",
      "38/38 - 217s - loss: 1460195.6250 - accuracy: 0.7446 - val_loss: 1459062.2500 - val_accuracy: 0.7321 - 217s/epoch - 6s/step\n",
      "Epoch 21/60\n",
      "38/38 - 146s - loss: 1458018.3750 - accuracy: 0.7502 - val_loss: 1456887.1250 - val_accuracy: 0.7759 - 146s/epoch - 4s/step\n",
      "Epoch 22/60\n",
      "38/38 - 183s - loss: 1455844.3750 - accuracy: 0.7657 - val_loss: 1454715.5000 - val_accuracy: 0.7567 - 183s/epoch - 5s/step\n",
      "Epoch 23/60\n",
      "38/38 - 163s - loss: 1453673.6250 - accuracy: 0.7611 - val_loss: 1452546.0000 - val_accuracy: 0.7556 - 163s/epoch - 4s/step\n",
      "Epoch 24/60\n",
      "38/38 - 145s - loss: 1451505.8750 - accuracy: 0.7753 - val_loss: 1450379.6250 - val_accuracy: 0.7609 - 145s/epoch - 4s/step\n",
      "Epoch 25/60\n",
      "38/38 - 161s - loss: 1449341.1250 - accuracy: 0.7809 - val_loss: 1448216.3750 - val_accuracy: 0.7460 - 161s/epoch - 4s/step\n",
      "Model: \"model_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_6 (InputLayer)        [(None, 200, 200, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 198, 198, 40)      400       \n",
      "                                                                 \n",
      " max_pooling2d_15 (MaxPoolin  (None, 99, 99, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 97, 97, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 48, 48, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 46, 46, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 30)                76830     \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 30)                0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dropout_16 (Dropout)        (None, 30)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 30)                930       \n",
      "                                                                 \n",
      " dropout_17 (Dropout)        (None, 30)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 3)                 93        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 136,943\n",
      "Trainable params: 136,943\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 1448216.125\n",
      "Test accuracy: 0.7525597214698792\n"
     ]
    }
   ],
   "source": [
    "train(60,100,4,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d5a3f593",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "next time\n",
    "penalty 0.01\n",
    "penalty last 0.001\n",
    "reverse\n",
    "\"\"\"\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "def train(epochs_num,batch_len,conv_layers,neur_layers,learn=0.001):\n",
    "    X_train,X_test,Y_train,Y_test=train_test_split(\n",
    "    dataset, labels, test_size=0.2, random_state=42)\n",
    "    X_train=X_train.reshape(-1,200,200,1)\n",
    "    X_test=X_test.reshape(-1,200,200,1)\n",
    "    Y_train = keras.utils.to_categorical(Y_train,3)\n",
    "    Y_test = keras.utils.to_categorical(Y_test,3)\n",
    "    \n",
    "    \n",
    "    def mlp_model():\n",
    "        Inp=layers.Input(shape=(200,200,1))\n",
    "        hidden=Inp\n",
    "        for i in range(conv_layers):\n",
    "            hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "            hidden=layers.MaxPool2D(pool_size=(2,2),strides=(2,2))(hidden)\n",
    "        hidden=layers.Conv2D(40,kernel_size=(3,3),padding='valid',activation='relu')(hidden)\n",
    "        hidden=layers.Flatten()(hidden)\n",
    "        w=1/76.4\n",
    "        for i in range(neur_layers):\n",
    "            i2=i+1\n",
    "            hidden=layers.Dense(50,activation=\"relu\",kernel_regularizer=regularizers.L2(0.01),kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w,maxval=1/w, seed=None))(hidden)\n",
    "            hidden=layers.Dropout(0.2)(hidden)\n",
    "            w=w*50*0.8\n",
    "        nl=neur_layers+1\n",
    "        output=layers.Dense(3,activation=\"softmax\",kernel_regularizer=regularizers.L2(0.001),kernel_initializer=tf.keras.initializers.RandomUniform(minval=-1/w, maxval=1/w, seed=None))(hidden)\n",
    "        model=keras.Model(Inp,output)\n",
    "        model.compile(loss=\"categorical_crossentropy\",optimizer=tf.keras.optimizers.Adam(learning_rate=learn),metrics=[\"accuracy\"])\n",
    "        return model\n",
    "    \"\"\"\n",
    "    checkpoint = tf.keras.callbacks.ModelCheckpoint(\"weights.hdf5\",monitor='val_accuracy', verbose=1, \n",
    "    save_best_only=True, mode='max')\n",
    "    callbacks_list = [checkpoint]\n",
    "    estimator = KerasClassifier(build_fn=mlp_model, epochs=int(len(X_train)/dividor_epoch), batch_size=batch_len, verbose=2)\n",
    "    kfold = KFold(n_splits=8, shuffle=True, random_state=7)\n",
    "    results = cross_val_score(estimator, X_train, Y_train, cv=kfold)\n",
    "    print(\"MLP: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "    \"\"\"\n",
    "    callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=4,mode='max')\n",
    "    model=mlp_model()\n",
    "    model.fit(X_train,Y_train,validation_split=0.2,epochs=epochs_num,batch_size=batch_len,verbose=2,callbacks=[callback])\n",
    "    #model.load_weights(\"weights.hdf5\")\n",
    "    model.summary()\n",
    "    score= model.evaluate(X_test, Y_test,verbose=0)\n",
    "    print(\"Test loss:\", score[0])\n",
    "    print(\"Test accuracy:\",score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4d0e2f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "75/75 - 165s - loss: 2476171.7500 - accuracy: 0.4769 - val_loss: 2472468.2500 - val_accuracy: 0.4813 - 165s/epoch - 2s/step\n",
      "Epoch 2/60\n",
      "75/75 - 169s - loss: 2468874.0000 - accuracy: 0.4788 - val_loss: 2465180.0000 - val_accuracy: 0.4813 - 169s/epoch - 2s/step\n",
      "Epoch 3/60\n",
      "75/75 - 159s - loss: 2461594.5000 - accuracy: 0.5946 - val_loss: 2457909.5000 - val_accuracy: 0.6467 - 159s/epoch - 2s/step\n",
      "Epoch 4/60\n",
      "75/75 - 153s - loss: 2454335.0000 - accuracy: 0.6643 - val_loss: 2450662.0000 - val_accuracy: 0.6724 - 153s/epoch - 2s/step\n",
      "Epoch 5/60\n",
      "75/75 - 142s - loss: 2447099.0000 - accuracy: 0.6667 - val_loss: 2443437.7500 - val_accuracy: 0.6553 - 142s/epoch - 2s/step\n",
      "Epoch 6/60\n",
      "75/75 - 139s - loss: 2439884.7500 - accuracy: 0.6824 - val_loss: 2436232.2500 - val_accuracy: 0.6521 - 139s/epoch - 2s/step\n",
      "Epoch 7/60\n",
      "75/75 - 143s - loss: 2432688.5000 - accuracy: 0.6931 - val_loss: 2429045.5000 - val_accuracy: 0.6820 - 143s/epoch - 2s/step\n",
      "Epoch 8/60\n",
      "75/75 - 157s - loss: 2425509.7500 - accuracy: 0.7027 - val_loss: 2421875.5000 - val_accuracy: 0.6574 - 157s/epoch - 2s/step\n",
      "Epoch 9/60\n",
      "75/75 - 144s - loss: 2418349.2500 - accuracy: 0.7043 - val_loss: 2414725.2500 - val_accuracy: 0.6958 - 144s/epoch - 2s/step\n",
      "Epoch 10/60\n",
      "75/75 - 167s - loss: 2411210.2500 - accuracy: 0.7126 - val_loss: 2407600.0000 - val_accuracy: 0.7129 - 167s/epoch - 2s/step\n",
      "Epoch 11/60\n",
      "75/75 - 150s - loss: 2404098.5000 - accuracy: 0.7310 - val_loss: 2400499.7500 - val_accuracy: 0.7118 - 150s/epoch - 2s/step\n",
      "Epoch 12/60\n",
      "75/75 - 151s - loss: 2397008.5000 - accuracy: 0.7256 - val_loss: 2393420.5000 - val_accuracy: 0.7321 - 151s/epoch - 2s/step\n",
      "Epoch 13/60\n",
      "75/75 - 137s - loss: 2389938.0000 - accuracy: 0.7427 - val_loss: 2386359.7500 - val_accuracy: 0.7567 - 137s/epoch - 2s/step\n",
      "Epoch 14/60\n",
      "75/75 - 139s - loss: 2382886.5000 - accuracy: 0.7465 - val_loss: 2379317.2500 - val_accuracy: 0.7503 - 139s/epoch - 2s/step\n",
      "Epoch 15/60\n",
      "75/75 - 144s - loss: 2375852.7500 - accuracy: 0.7505 - val_loss: 2372291.0000 - val_accuracy: 0.7556 - 144s/epoch - 2s/step\n",
      "Epoch 16/60\n",
      "75/75 - 136s - loss: 2368834.7500 - accuracy: 0.7577 - val_loss: 2365281.5000 - val_accuracy: 0.7599 - 136s/epoch - 2s/step\n",
      "Epoch 17/60\n",
      "75/75 - 148s - loss: 2361834.0000 - accuracy: 0.7681 - val_loss: 2358290.0000 - val_accuracy: 0.7471 - 148s/epoch - 2s/step\n",
      "Epoch 18/60\n",
      "75/75 - 133s - loss: 2354850.0000 - accuracy: 0.7732 - val_loss: 2351314.2500 - val_accuracy: 0.7684 - 133s/epoch - 2s/step\n",
      "Epoch 19/60\n",
      "75/75 - 139s - loss: 2347883.2500 - accuracy: 0.7766 - val_loss: 2344356.0000 - val_accuracy: 0.7460 - 139s/epoch - 2s/step\n",
      "Epoch 20/60\n",
      "75/75 - 136s - loss: 2340932.5000 - accuracy: 0.7782 - val_loss: 2337414.2500 - val_accuracy: 0.7705 - 136s/epoch - 2s/step\n",
      "Epoch 21/60\n",
      "75/75 - 137s - loss: 2333999.0000 - accuracy: 0.7868 - val_loss: 2330488.2500 - val_accuracy: 0.7716 - 137s/epoch - 2s/step\n",
      "Epoch 22/60\n",
      "75/75 - 132s - loss: 2327082.0000 - accuracy: 0.7857 - val_loss: 2323579.5000 - val_accuracy: 0.7641 - 132s/epoch - 2s/step\n",
      "Epoch 23/60\n",
      "75/75 - 129s - loss: 2320181.2500 - accuracy: 0.8030 - val_loss: 2316687.7500 - val_accuracy: 0.7609 - 129s/epoch - 2s/step\n",
      "Epoch 24/60\n",
      "75/75 - 137s - loss: 2313297.5000 - accuracy: 0.7964 - val_loss: 2309812.7500 - val_accuracy: 0.7631 - 137s/epoch - 2s/step\n",
      "Epoch 25/60\n",
      "75/75 - 124s - loss: 2306430.0000 - accuracy: 0.8028 - val_loss: 2302953.2500 - val_accuracy: 0.7631 - 124s/epoch - 2s/step\n",
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_8 (InputLayer)        [(None, 200, 200, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_30 (Conv2D)          (None, 198, 198, 40)      400       \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPoolin  (None, 99, 99, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_31 (Conv2D)          (None, 97, 97, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 48, 48, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_32 (Conv2D)          (None, 46, 46, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 23, 23, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_33 (Conv2D)          (None, 21, 21, 40)        14440     \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 10, 10, 40)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_34 (Conv2D)          (None, 8, 8, 40)          14440     \n",
      "                                                                 \n",
      " flatten_7 (Flatten)         (None, 2560)              0         \n",
      "                                                                 \n",
      " dense_30 (Dense)            (None, 50)                128050    \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_24 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_25 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_26 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 50)                2550      \n",
      "                                                                 \n",
      " dropout_27 (Dropout)        (None, 50)                0         \n",
      "                                                                 \n",
      " dense_35 (Dense)            (None, 3)                 153       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 196,563\n",
      "Trainable params: 196,563\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Test loss: 2302952.75\n",
      "Test accuracy: 0.7841296792030334\n"
     ]
    }
   ],
   "source": [
    "train(60,50,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf000b50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
